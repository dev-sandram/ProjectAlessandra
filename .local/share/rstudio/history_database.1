1760386577870:# carico la libreria
1760386577874:library(data.table)
1760386615005:# carico la libreria
1760386615021:library(data.table)
1760386618337:# leggo i file
1760386618353:variants <- fread("project_oct25/variants.csv")
1760386677275:# carico la libreria
1760386677280:library(data.table)
1760386677757:# leggo i file
1760386677767:variants <- fread("project_oct25/variants.csv")
1760386694825:library(data.table) #carica il pacchetto data.table in R per farci delle operazioni
1760386694975:# 1 Import
1760386694977:counts <- fread("project_oct25/bulk_counts_long.csv") #legge i file e li salva come variabili counts e meta che sono matrici con dati, è la funzione ad alte prestazioni di data.table per leggere file e restituisce un oggetto di classe data.table
1760386695144:meta <- fread("project_oct25/sample_metadata.csv")  #definiamo il path così sa dove trovare i file
1760386695334:# 4 Faccio un join (merge) tra counts e metadata
1760386695340:#    -> Uso merge() di base per chiarezza
1760386695354:merged_data <- merge(
1760386695356:counts,
1760386695359:meta,
1760386695362:by = "sample_id",    #colonna comune, anello congiugente
1760386695366:) #vogliamo avere, per ogni misura di espressione genica (count), anche la condizione sperimentale (treated o control).
1760386696737:# 5️ Filtro solo i geni che iniziano con "GENE_00"
1760386696749:#    e solo i campioni con condizione "treated"
1760386696751:treated_data <- subset(
1760386696754:merged_data,
1760386696758:condition == "treated" & grepl("^GENE_00", gene)
1760386696759:)
1760386696931:# 6️ Calcolo la media e la mediana del count per ciascun gene
1760386696937:#    -> Uso aggregate(), più esplicita anche se più lenta
1760386696947:gene_summary <- aggregate(
1760386696951:count ~ gene,                  # formula: dipendente ~ raggruppamento
1760386696954:data = treated_data,          # tabella di partenza
1760386696956:FUN = function(x) c(mean = mean(x), median = median(x)) #crea un vettore
1760386696957:)
1760386697212:# 7️ Semplifico un po’ il formato della tabella risultante
1760386697216:gene_summary_df <- data.frame(
1760386697226:gene = gene_summary$gene,
1760386697229:mean_count = gene_summary$count[, "mean"],
1760386697231:median_count = gene_summary$count[, "median"]
1760386697233:)
1760386697484:gene_mean_pipeline <- aggregate(
1760386697489:count ~ gene,
1760386697490:data = subset(
1760386697492:merge(counts, meta, by = "sample_id", all.x = TRUE),
1760386697494:condition == "treated" & grepl("^GENE_00", gene)
1760386697497:),
1760386697499:FUN = mean
1760386697500:)
1760386698182:# 9️ Stampo i risultati
1760386698196:cat("\n--- Media e mediana dei conteggi (solo treated, GENE_00*) ---\n")
1760386698384:print(head(gene_summary_df, 5))
1760387446976:library(data.table) #carica il pacchetto data.table in R per farci delle operazioni
1760387448102:# 1 Import
1760387448110:counts <- fread("project_oct25/bulk_counts_long.csv") #legge i file e li salva come variabili counts e meta che sono matrici con dati, è la funzione ad alte prestazioni di data.table per leggere file e restituisce un oggetto di classe data.table
1760387465078:getwd
1760387487607:# 1 Import
1760387487638:counts <- fread("Alessandra/project_oct25/bulk_counts_long.csv") #legge i file e li salva come variabili counts e meta che sono matrici con dati, è la funzione ad alte prestazioni di data.table per leggere file e restituisce un oggetto di classe data.table
1760387500451:View(counts)
1760387566328:library(data.table) #carica il pacchetto data.table in R per farci delle operazioni
1760387569133:# 1 Import
1760387569137:counts <- fread("project_oct25/bulk_counts_long.csv") #legge i file e li salva come variabili counts e meta che sono matrici con dati, è la funzione ad alte prestazioni di data.table per leggere file e restituisce un oggetto di classe data.table
1760387572099:View(counts)
1760387595067:# carico la libreria
1760387595069:library(data.table)
1760387596017:# leggo i file
1760387596030:variants <- fread("project_oct25/variants.csv")
1760387596714:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760387691739:View(variants)
1760387692563:View(genes)
1760387693237:View(counts)
1760388807031:# carico la libreria
1760388807044:library(data.table)
1760388807857:# leggo i file
1760388807866:variants <- fread("project_oct25/variants.csv")
1760388826455:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760388828793:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1760388828797:#    (foverlaps lavora con intervalli start-end)
1760388828806:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1760388837205:View(variants)
1760388903733:# carico la libreria
1760388903747:library(data.table)
1760388905220:# leggo i file
1760388905227:variants <- fread("project_oct25/variants.csv")
1760388906427:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760388908308:View(genes)
1760388912723:View(variants)
1760388920614:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1760388920619:#    (foverlaps lavora con intervalli start-end)
1760388920620:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1760388922647:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1760388925277:View(variants)
1760388932182:# 5) imposto le chiavi per foverlaps: (chr, start, end), requisito per foverlaps utile per velocizzare
1760388932185:#    nei gene assumiamo colonne 'chr','start','end' e 'gene' per il nome
1760388932190:setkey(variants, chr, start, end)
1760388933570:setkey(genes,    chr, start, end)
1760388936768:# 6) eseguo l'overlap: trovo per ogni variante i geni che si sovrappongono
1760388936779:#    nomatch = 0L rimuove le varianti senza overlap, che non sovrappongono alcun gene
1760388936782:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1760388940674:View(overlaps)
1760388976752:# 7) filtro le varianti di alto impatto (impact == "HIGH")
1760388976776:#    normalizzo il valore di impact a maiuscole per sicurezza
1760388976791:overlaps[, impact_upper := toupper(impact)] #normalizzo il campo impact
1760388978641:View(variants)
1760388992295:high_overlaps <- overlaps[impact_upper == "HIGH"] #seleziono solo le varianti con impact HIGH
1760388995285:View(high_overlaps)
1760389042143:View(high_overlaps)
1760389056018:# 8) conto le varianti HIGH per gene e per sample_id
1760389056024:#conta quante varianti ci sono per coppia gene x sample_id
1760389056035:#.N è il conteggio delle righe del gruppo
1760389056039:high_counts_by_gene_sample <- high_overlaps[, .(
1760389056043:high_variant_count = .N
1760389056046:), by = .(gene, sample_id)]
1760389062725:View(high_counts_by_gene_sample)
1760389070257:# 9) conto le varianti HIGH per gene (tutte le sample aggregate)
1760389070258:high_counts_by_gene <- high_overlaps[, .(
1760389070260:total_high_variants = .N
1760389070261:), by = gene][order(-total_high_variants)]
1760389076880:View(high_counts_by_gene_sample)
1760389083722:# 10) lista dei geni che hanno almeno una variante HIGH (unique gene)
1760389083743:#Estrae i geni con almeno una variante HIGH
1760389083753:genes_with_high <- unique(high_counts_by_gene$gene)
1760389108121:View(variants)
1760389123358:# 11) (Opzionale) salvo i risultati su file CSV nella cartella project_oct25
1760389123364:fwrite(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv")
1760389125238:fwrite(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv")
1760389125951:fwrite(data.table(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv")
1760389138211:# carico la libreria
1760389138216:library(data.table)
1760389139115:# leggo i file
1760389139116:variants <- fread("project_oct25/variants.csv")
1760389139335:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760389139594:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1760389139596:#    (foverlaps lavora con intervalli start-end)
1760389139597:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1760389140595:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1760389141372:# 5) imposto le chiavi per foverlaps: (chr, start, end), requisito per foverlaps utile per velocizzare
1760389141374:#    nei gene assumiamo colonne 'chr','start','end' e 'gene' per il nome
1760389141375:setkey(variants, chr, start, end)
1760389141601:setkey(genes,    chr, start, end)
1760389141789:# 6) eseguo l'overlap: trovo per ogni variante i geni che si sovrappongono
1760389141793:#    nomatch = 0L rimuove le varianti senza overlap, che non sovrappongono alcun gene
1760389141795:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1760389142332:# 7) filtro le varianti di alto impatto (impact == "HIGH")
1760389142337:#    normalizzo il valore di impact a maiuscole per sicurezza
1760389142339:overlaps[, impact_upper := toupper(impact)] #normalizzo il campo impact
1760389143010:high_overlaps <- overlaps[impact_upper == "HIGH"] #seleziono solo le varianti con impact HIGH
1760389144066:# 8) conto le varianti HIGH per gene e per sample_id
1760389144086:#conta quante varianti ci sono per coppia gene x sample_id
1760389144091:#.N è il conteggio delle righe del gruppo
1760389144110:high_counts_by_gene_sample <- high_overlaps[, .(
1760389144114:high_variant_count = .N
1760389144115:), by = .(gene, sample_id)]
1760389147464:# 9) conto le varianti HIGH per gene (tutte le sample aggregate)
1760389147484:high_counts_by_gene <- high_overlaps[, .(
1760389147485:total_high_variants = .N
1760389147486:), by = gene][order(-total_high_variants)]
1760389155166:# 10) lista dei geni che hanno almeno una variante HIGH (unique gene)
1760389155170:#Estrae i geni con almeno una variante HIGH
1760389155171:genes_with_high <- unique(high_counts_by_gene$gene)
1760389244661:# carico la libreria
1760389244675:library(data.table)
1760389245166:# leggo i file
1760389245171:variants <- fread("project_oct25/variants.csv")
1760389245409:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760389245585:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1760389245598:#    (foverlaps lavora con intervalli start-end)
1760389245604:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1760389249327:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1760389249506:# 5) imposto le chiavi per foverlaps: (chr, start, end), requisito per foverlaps utile per velocizzare
1760389249516:#    nei gene assumiamo colonne 'chr','start','end' e 'gene' per il nome
1760389249519:setkey(variants, chr, start, end)
1760389249666:setkey(genes,    chr, start, end)
1760389252979:# 6) eseguo l'overlap: trovo per ogni variante i geni che si sovrappongono
1760389252982:#    nomatch = 0L rimuove le varianti senza overlap, che non sovrappongono alcun gene
1760389252984:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1760389253273:# 7) filtro le varianti di alto impatto (impact == "HIGH")
1760389253277:#    normalizzo il valore di impact a maiuscole per sicurezza
1760389253279:overlaps[, impact_upper := toupper(impact)] #normalizzo il campo impact
1760389256397:high_overlaps <- overlaps[impact_upper == "HIGH"] #seleziono solo le varianti con impact HIGH
1760389256999:# 8) conto le varianti HIGH per gene e per sample_id
1760389257004:#conta quante varianti ci sono per coppia gene x sample_id
1760389257006:#.N è il conteggio delle righe del gruppo
1760389257014:high_counts_by_gene_sample <- high_overlaps[, .(
1760389257016:high_variant_count = .N
1760389257017:), by = .(gene, sample_id)]
1760389257692:# 9) conto le varianti HIGH per gene (tutte le sample aggregate)
1760389257695:high_counts_by_gene <- high_overlaps[, .(
1760389257697:total_high_variants = .N
1760389257699:), by = gene][order(-total_high_variants)]
1760389261055:# 10) lista dei geni che hanno almeno una variante HIGH (unique gene)
1760389261072:#Estrae i geni con almeno una variante HIGH
1760389261073:genes_with_high <- unique(high_counts_by_gene$gene)
1760389263119:print(head(high_counts_by_gene))
1760390112473:# Carichiamo la libreria
1760390112477:library(data.table)
1760390113461:# Leggiamo i file, specificando i percorsi
1760390113471:cohortA <- fread("project_oct25/cohortA_samples.csv")
1760390114378:cohortB <- fread("project_oct25/cohortB_samples.csv")
1760390116694:View(cohortA)
1760390128972:counts  <- fread("project_oct25/bulk_counts_long.csv")
1760390130961:View(cohortB)
1760390139894:View(cohortB)
1760390142674:View(cohortA)
1760390146522:# Aggiungiamo una colonna 'cohort' per tenere traccia della provenienza
1760390146533:cohortA[, cohort := "A"]
1760390149080:cohortB[, cohort := "B"]
1760390151299:View(cohortB)
1760390154216:View(cohortA)
1760390155587:View(counts)
1760390175475:cohortB[,
1760390176677:cohortB[,
1760390293556:# Aggiungiamo una colonna 'cohort' per tenere traccia della provenienza #HA SENSO???
1760390293560:cohortA[, cohort := "A"]
1760390294454:cohortB[, cohort := "B"]
1760390308015:# Carichiamo la libreria
1760390308019:library(data.table)
1760390308554:# Leggiamo i file, specificando i percorsi
1760390308560:cohortA <- fread("project_oct25/cohortA_samples.csv")
1760390309133:cohortB <- fread("project_oct25/cohortB_samples.csv")
1760390309660:counts  <- fread("project_oct25/bulk_counts_long.csv")
1760390310166:# Aggiungiamo una colonna 'cohort' per tenere traccia della provenienza #HA SENSO???
1760390310171:cohortA[, cohort := "A"]
1760390310875:cohortB[, cohort := "B"]
1760390312649:# Uniamo le due coorti
1760390312660:# use.names = TRUE --> allinea le colonne con lo stesso nome  #HA SENSO?
1760390312671:# fill = TRUE      --> se mancano colonne in uno dei due file, le crea e le riempie con NA #HA SENSO?
1760390312674:combined_cohorts <- rbindlist(list(cohortA, cohortB), use.names = TRUE, fill = TRUE)
1760390315624:View(combined_cohorts)
1760390323496:# 7️⃣ Ordiniamo per coorte, condizione e sample_id
1760390323510:setorder(combined_cohorts, cohort, condition, sample_id)
1760390326083:View(combined_cohorts)
1760390333566:# -----------------------------------------------------
1760390333581:# PARTE 2: Uniamo la tabella combinata ai conteggi
1760390333584:# -----------------------------------------------------
1760390333585:# Uniamo per sample_id
1760390333586:merged_per_sampleid <- merge(counts, combined_cohorts, by = "sample_id", all.x = TRUE)
1760390334868:View(merged_per_sampleid)
1760390370143:# -----------------------------------------------------
1760390370149:# PARTE 3: Troviamo i 100 geni più variabili
1760390370159:# -----------------------------------------------------
1760390370161:# Calcoliamo la varianza dei conteggi per ciascun gene
1760390370163:gene_variance <- merged[, .(variance = var(count, na.rm = TRUE)), by = gene]
1760390630909:# -----------------------------------------------------
1760390630916:# PARTE 3: Troviamo i 100 geni più variabili
1760390630919:# -----------------------------------------------------
1760390630921:# Calcoliamo la varianza dei conteggi per ciascun gene
1760390630922:gene_variance <- merged_per_sampleid[, .(variance = var(count, na.rm = TRUE)), by = gene]
1760390636140:View(merged_per_sampleid)
1760390646999:# Ordiniamo per varianza decrescente e prendiamo i primi 100
1760390647015:top100_genes <- gene_variance[order(-variance)][1:100, gene]
1760390657731:View(merged_per_sampleid)
1760390695528:# Ordiniamo per varianza decrescente e prendiamo i primi 100
1760390695551:top100_genes <- gene_variance[order(-variance)][1:100, gene]
1760390696225:print(head(top100_genes, 5))
1760390705079:# -----------------------------------------------------
1760390705099:# PARTE 4: Calcoliamo la media dei conteggi per coorte e condizione
1760390705103:#           solo per i top 100 geni
1760390705104:# -----------------------------------------------------
1760390705105:top100_data <- merged[gene %in% top100_genes]
1760390717434:# -----------------------------------------------------
1760390717455:# PARTE 4: Calcoliamo la media dei conteggi per coorte e condizione
1760390717456:#           solo per i top 100 geni
1760390717457:# -----------------------------------------------------
1760390717457:top100_data <- merged_per_sampleid[gene %in% top100_genes]
1760390724525:View(top100_data)
1760390748923:mean_counts <- top100_data[, .(
1760390748954:mean_count = mean(count, na.rm = TRUE)
1760390748956:), by = .(gene, cohort, condition)]
1760390750636:View(mean_counts)
1760390772798:# Carichiamo la libreria
1760390772814:library(data.table)
1760390772971:# Leggiamo i file, specificando i percorsi
1760390772980:cohortA <- fread("project_oct25/cohortA_samples.csv")
1760390773164:cohortB <- fread("project_oct25/cohortB_samples.csv")
1760390773337:counts  <- fread("project_oct25/bulk_counts_long.csv")
1760390797331:# Carichiamo la libreria
1760390797345:library(data.table)
1760391000725:# Carichiamo la libreria
1760391000742:library(data.table)
1760391025120:# Carichiamo la libreria
1760391025126:Session → Restart R
1760391095786:# Carichiamo la libreria
1760391095799:library(data.table)
1760391113141:# Carichiamo la libreria
1760391113152:library(data.table)
1760391180619:# Carichiamo la libreria
1760391180621:library(data.table)
1760391191513:# carico la libreria
1760391191518:library(data.table)
1760391199498:# 1) Carichiamo la libreria data.table (veloce e semplice per i gruppi)
1760391199516:library(data.table)
1760391685949:# 1) Carichiamo la libreria data.table (veloce e semplice per i gruppi)
1760391685960:library(data.table)
1760391699295:library(data.table) #carica il pacchetto data.table in R per farci delle operazioni
1760391773074:library(data.table) #carica il pacchetto data.table in R per farci delle operazioni
1760391850436:?getDTthreads
1760391859179:library(data.table) #carica il pacchetto data.table in R per farci delle operazioni
1760391862542:# 1 Import
1760391862547:counts <- fread("project_oct25/bulk_counts_long.csv") #legge i file e li salva come variabili counts e meta che sono matrici con dati, è la funzione ad alte prestazioni di data.table per leggere file e restituisce un oggetto di classe data.table
1760391863776:meta <- fread("project_oct25/sample_metadata.csv")  #definiamo il path così sa dove trovare i file
1760391888681:# Leggiamo i file
1760391888686:counts <- fread("project_oct25/bulk_counts_long.csv")
1760391895274:# 1) Carichiamo la libreria data.table (veloce e semplice per i gruppi)
1760391895286:library(data.table)
1760391895928:# Leggiamo i file
1760391895943:counts <- fread("project_oct25/bulk_counts_long.csv")
1760391930805:# 1) Carichiamo la libreria data.table (veloce e semplice per i gruppi)
1760391930816:library(data.table)
1760391939102:# Leggiamo i file
1760391939109:counts <- fread("project_oct25/bulk_counts_long.csv")
1760434081319:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760434081326:#SETUP PACCHETTI E PERCORSI
1760434081332:# Setup iniziale
1760434081334:library(data.table)   # lavoro tabellare semplice e veloce
1760434082543:library(ggplot2)      # per il plot richiesto
1760434084542:# Percorsi input/output (assumo cartella project_oct25/)
1760434084549:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760434085641:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760434128209:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760434131033:out_prefix <- "project_oct25/final_revision"  # prefix per i file di output
1760434315551:#TASK 1.1
1760434315555:#provide a new file where cell type, cells and integration clusters are combined
1760434315557:#Leggi i due file
1760434315560:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760434317771:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760434319171:View(clustering_dt)
1760434321808:View(integration_dt)
1760434404323:#Unione (join) sui cell id
1760434404328:combined <- merge(integration_dt, clustering_dt, by = "cell", all = FALSE) #all FALSE evita duplicazioni indesiderate
1760434406107:View(combined)
1760434415762:# 4. Salvo il file risultante
1760434415765:out1 <- paste0(out_prefix, "_cells_clusters_celltypes.csv")
1760434418755:fwrite(combined, out1)
1760434420272:View(combined)
1760434441308:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760434441310:#SETUP PACCHETTI E PERCORSI
1760434441312:# Setup iniziale
1760434441314:library(data.table)   # lavoro tabellare semplice e veloce
1760434441858:library(ggplot2)      # per il plot richiesto
1760434442499:# Percorsi input
1760434442501:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760434443966:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760434445329:#TASK 1.1
1760434445331:#provide a new file where cell type, cells and integration clusters are combined
1760434445334:#Leggi i due file
1760434445336:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760434450821:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760434463663:#Unione (join) sui cell id
1760434463665:combined <- merge(integration_dt, clustering_dt, by = "cell") #all FALSE evita duplicazioni indesiderate
1760434486078:# 4. Salvo il file risultante
1760434486090:out1 <- paste0(out_prefix, "_cells_clusters_celltypes.csv")
1760434487462:fwrite(combined, out1)
1760434488608:# 5. Mostro un riepilogo leggero
1760434488613:cat("Combined rows:", nrow(combined), "\nColumns:", paste(names(combined), collapse=", "), "\nSaved to:", out1, "\n")
1760434490114:print(head(combined, 8))
1760434491818:View(combined)
1760434508218:#TASK 1.1
1760434508221:#provide a new file where cell type, cells and integration clusters are combined
1760434508222:#Leggi i due file
1760434508224:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760434508698:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760434509187:#Unione (join) sui cell id
1760434509191:combined <- merge(integration_dt, clustering_dt, by = cell, all=FALSE) #all FALSE evita duplicazioni indesiderate
1760434509752:# 4. Salvo il file risultante
1760434509756:out1 <- paste0(out_prefix, "_cells_clusters_celltypes.csv")
1760434524639:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760434524645:#SETUP PACCHETTI E PERCORSI
1760434524648:# Setup iniziale
1760434524652:library(data.table)   # lavoro tabellare semplice e veloce
1760434525021:library(ggplot2)      # per il plot richiesto
1760434529687:# Percorsi input #NECESSARIO?
1760434529690:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760434530813:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760434531345:#TASK 1.1
1760434531349:#provide a new file where cell type, cells and integration clusters are combined
1760434531351:#Leggi i due file
1760434531353:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760434533254:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760434537138:#Unione (join) sui cell id
1760434537141:combined <- merge(integration_dt, clustering_dt, by = cell, all=FALSE) #all FALSE evita duplicazioni indesiderate
1760434547752:View(clustering_dt)
1760434549879:View(integration_dt)
1760434559307:#Unione (join) sui cell id
1760434559311:combined <- merge(integration_dt, clustering_dt, by = "cell", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760434686221:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760434686224:#SETUP PACCHETTI E PERCORSI
1760434686226:# Setup iniziale
1760434686227:library(data.table)   # lavoro tabellare semplice e veloce
1760434686911:library(ggplot2)      # per il plot richiesto
1760434687429:# Percorsi input #NECESSARIO?
1760434687431:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760434688202:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760434688896:#TASK 1.1
1760434688899:#provide a new file where cell type, cells and integration clusters are combined
1760434688900:#Leggi i due file
1760434688901:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760434690749:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760434691603:# 2. Controllo veloce che la colonna 'cell' esista in entrambi
1760434691613:if(!"cell" %in% names(int_dt)) stop("annotated file lacks 'cell' column")
1760434706002:# 2. Controllo veloce che la colonna 'cell' esista in entrambi
1760434706005:if(!"cell" %in% names(integration_dt)) stop("annotated file lacks 'cell' column")
1760434709534:if(!"cell" %in% names(clustering_dt)) stop("clustering file lacks 'cell' column")
1760434710970:#Unione (join) sui cell id
1760434710973:combined <- merge(integration_dt, clustering_dt, by = "cell", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760434723339:View(clustering_dt)
1760434726580:View(combined)
1760434728604:View(integration_dt)
1760435048686:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760435052461:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760435052464:# Funzione per pulire i nomi (estrae solo la parte utile finale)
1760435052467:clean_cell_id <- function(x) {
1760435052468:# 1. rimuove eventuali prefissi tipo "X12345_"
1760435052470:x <- sub("^X[0-9]+_X?_?", "", x)
1760435052472:# 2. rimuove doppie X o caratteri strani tipo "_."
1760435052473:x <- gsub("_\\.", ".", x)
1760435052475:# 3. rimuove spazi e tutto minuscolo
1760435052476:x <- tolower(trimws(x))
1760435052477:return(x)
1760435052478:}
1760435071470:View(integration_dt)
1760435078098:# Applichiamo la funzione a entrambe le tabelle
1760435078103:integration_dt[, cell_clean := clean_cell_id(Cell)]   # in quel file la colonna si chiama "Cell"
1760435101101:# Applichiamo la funzione a entrambe le tabelle
1760435101104:integration_dt[, cell_clean := clean_cell_id("cell")]   # in quel file la colonna si chiama "Cell"
1760435103943:clustering_dt[, cell_clean := clean_cell_id("cell")] # in quell'altro "cell"
1760435105950:View(integration_dt)
1760435109753:combined <- merge(integration_dt, clustering_dt, by = "cell", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760435111402:View(combined)
1760435122735:# Applichiamo la funzione a entrambe le tabelle
1760435122739:integration_dt[, cell_clean := clean_cell_id("Cell")]   # in quel file la colonna si chiama "Cell"
1760435124535:clustering_dt[, cell_clean := clean_cell_id("cell")] # in quell'altro "cell"
1760435125854:combined <- merge(integration_dt, clustering_dt, by = "cell", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760435304368:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760435304373:# ---- Normalizzazione robusta dei cell id ----
1760435304375:# Funzione di pulizia: rimuove prefissi X o Y (singoli o X+digits_), rimuove underscore doppi, spazi, e rende uniforme
1760435304376:clean_cell_id <- function(x) {
1760435304378:x <- as.character(x)
1760435304379:x <- trimws(x)                       # elimina spazi iniziali/finali
1760435304381:# rimuovi prefisso tipo "X12345_" (X seguito da cifre e underscore)
1760435304382:x <- sub("^X[0-9]+_", "", x)
1760435304383:x <- sub("^Y[0-9]+_", "", x)
1760435304386:# se ancora inizia per X o Y singolo, rimuovilo
1760435304389:x <- sub("^[XY]", "", x)
1760435304391:# rimuovi pattern interni "_X_" o "_Y_" residui
1760435304394:x <- gsub("_X_", "_", x)
1760435304396:x <- gsub("_Y_", "_", x)
1760435304398:# rimuovi eventuali doppie underscore
1760435304400:x <- gsub("__+", "_", x)
1760435304407:# rimuovi underscore all'inizio o alla fine
1760435304410:x <- sub("^_+", "", x)
1760435304413:x <- sub("_+$", "", x)
1760435304415:# opzionale: rendi tutto minuscolo per uniformità (se vuoi case-insensitive)
1760435304418:x <- tolower(x)
1760435304420:return(x)
1760435304422:}
1760435306780:# Applica la funzione creando nuove colonne "cell_clean"
1760435306785:# Gestiamo nomi diversi: "Cell" o "cell"
1760435306787:if ("Cell" %in% names(int_dt) && !"cell" %in% names(int_dt)) {
1760435306788:setnames(int_dt, "Cell", "cell")   # se esiste 'Cell' rinomina in 'cell'
1760435306792:}
1760435307879:int_dt[, cell_clean := clean_cell_id(cell)]
1760435309121:clust_dt[, cell_clean := clean_cell_id(cell)]
1760435310399:combined <- merge(integration_dt, clustering_dt, by = "cell", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760435362252:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760435362257:combined <- merge(integration_dt, clustering_dt, by = "cell", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760435363392:View(combined)
1760435386565:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760435386570:#SETUP PACCHETTI E PERCORSI
1760435386571:# Setup iniziale
1760435386574:library(data.table)   # lavoro tabellare semplice e veloce
1760435387033:library(ggplot2)      # per il plot richiesto
1760435387522:# Percorsi input #NECESSARIO?
1760435387526:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760435388180:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760435388686:#TASK 1.1
1760435388690:#provide a new file where cell type, cells and integration clusters are combined
1760435388691:#Leggi i due file
1760435388692:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760435390143:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760435390904:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760435390908:combined <- merge(integration_dt, clustering_dt, by = "cell", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760435392758:# 4. Salvo il file risultante
1760435392761:out1 <- paste0(out_prefix, "_cells_clusters_celltypes.csv")
1760435393589:fwrite(combined, out1)
1760435394472:# 5. Mostro un riepilogo leggero
1760435394477:cat("Combined rows:", nrow(combined), "\nColumns:", paste(names(combined), collapse=", "), "\nSaved to:", out1, "\n")
1760435395550:print(head(combined, 8))
1760435636812:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760435636814:#SETUP PACCHETTI E PERCORSI
1760435636816:# Setup iniziale
1760435636816:library(data.table)   # lavoro tabellare semplice e veloce
1760435637202:library(ggplot2)      # per il plot richiesto
1760435637767:# Percorsi input #NECESSARIO?
1760435637771:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760435638602:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760435639927:#TASK 1.1
1760435639930:#provide a new file where cell type, cells and integration clusters are combined
1760435639932:#Leggi i due file
1760435639934:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760435642313:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760435645016:# 3️⃣ Controlliamo i nomi delle colonne
1760435645019:cat("Colonne in file integrazione:", names(int_dt), "\n")
1760435662315:View(integration_dt)
1760435664268:View(clustering_dt)
1760435688384:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760435688389:#SETUP PACCHETTI E PERCORSI
1760435688395:# Setup iniziale
1760435688397:library(data.table)   # lavoro tabellare semplice e veloce
1760435688863:library(ggplot2)      # per il plot richiesto
1760435689577:# Percorsi input #NECESSARIO?
1760435689580:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760435690525:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760435691881:#TASK 1.1
1760435691885:#provide a new file where cell type, cells and integration clusters are combined
1760435691887:#Leggi i due file
1760435691889:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760435694151:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760435699427:# 3️⃣ Controlliamo i nomi delle colonne
1760435699429:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760435703995:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760435712522:# 5️⃣ Normalizziamo i nomi delle celle per rimuovere prefissi/suffissi tipo X, Y, underscore vari
1760435712524:normalize_cell_id <- function(x) {
1760435712526:x <- as.character(x)
1760435712528:x <- trimws(x)                    # toglie spazi
1760435712529:x <- gsub("^X+", "", x)           # rimuove eventuali X iniziali
1760435712530:x <- gsub("^Y+", "", x)           # rimuove eventuali Y iniziali
1760435712532:x <- gsub("_+", "_", x)           # comprime underscore multipli
1760435712534:x <- gsub("_$", "", x)            # toglie underscore finale
1760435712536:x <- tolower(x)                   # mette tutto minuscolo (per uniformità)
1760435712537:return(x)
1760435712539:}
1760435721659:# Applichiamo la funzione di normalizzazione
1760435721663:int_dt[, cell_clean := normalize_cell_id(cell)]
1760435731778:# Applichiamo la funzione di normalizzazione
1760435731781:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760435735275:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760435737748:View(clustering_dt)
1760435739392:View(integration_dt)
1760435743207:View(clustering_dt)
1760435745352:View(integration_dt)
1760435889498:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760435889502:#SETUP PACCHETTI E PERCORSI
1760435889503:# Setup iniziale
1760435889505:library(data.table)   # lavoro tabellare semplice e veloce
1760435889982:library(ggplot2)      # per il plot richiesto
1760435890532:# Percorsi input #NECESSARIO?
1760435890535:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760435891576:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760435893043:#TASK 1.1
1760435893046:#provide a new file where cell type, cells and integration clusters are combined
1760435893047:#Leggi i due file
1760435893049:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760435895039:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760435897766:# 3️⃣ Controlliamo i nomi delle colonne
1760435897772:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760435898720:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760435900128:# Nuova versione: rimuove anche _X_ o _Y_ in mezzo agli ID
1760435900132:normalize_cell_id <- function(x) {
1760435900134:x <- as.character(x)
1760435900136:x <- trimws(x)                     # toglie spazi iniziali/finali
1760435900137:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760435900139:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760435900141:x <- gsub("_+$", "", x)            # rimuove underscore finali
1760435900142:x <- gsub("^_+", "", x)            # rimuove underscore iniziali
1760435900144:x <- gsub("__+", "_", x)           # comprime doppi underscore
1760435900145:x <- tolower(x)                    # mette tutto minuscolo
1760435900147:return(x)
1760435900149:}
1760435904905:# Applichiamo la funzione di normalizzazione
1760435904908:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760435906264:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760435908805:View(clustering_dt)
1760435911332:View(integration_dt)
1760435915151:View(clustering_dt)
1760435925570:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760435925574:combined <- merge(integration_dt, clustering_dt, by = "cell", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760435949312:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760435949318:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760435955902:# Applichiamo la funzione di normalizzazione
1760435955904:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760435956744:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760435957471:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760435957477:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760435963793:View(combined)
1760436005304:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760436005309:#SETUP PACCHETTI E PERCORSI
1760436005311:# Setup iniziale
1760436005312:library(data.table)   # lavoro tabellare semplice e veloce
1760436005643:library(ggplot2)      # per il plot richiesto
1760436006122:# Percorsi input #NECESSARIO?
1760436006123:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760436006773:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760436007323:#TASK 1.1
1760436007324:#provide a new file where cell type, cells and integration clusters are combined
1760436007326:#Leggi i due file
1760436007327:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760436008012:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760436008827:# 3️⃣ Controlliamo i nomi delle colonne
1760436008830:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760436009599:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760436011942:# Nuova versione: rimuove anche _X_ o _Y_ in mezzo agli ID
1760436011947:normalize_cell_id <- function(x) {
1760436011951:x <- as.character(x)
1760436011952:x <- trimws(x)                     # toglie spazi iniziali/finali
1760436011954:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760436011955:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760436011957:x <- gsub("_+$", "", x)            # rimuove underscore finali
1760436011958:x <- gsub("^_+", "", x)            # rimuove underscore iniziali
1760436011960:x <- gsub("__+", "_", x)           # comprime doppi underscore
1760436011961:x <- tolower(x)                    # mette tutto minuscolo
1760436011964:return(x)
1760436011966:}
1760436019077:View(normalize_cell_id)
1760436022054:function(x) {
1760436022057:x <- as.character(x)
1760436022059:x <- trimws(x)                     # toglie spazi iniziali/finali
1760436022060:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760436022063:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760436022064:x <- gsub("_+$", "", x)            # rimuove underscore finali
1760436022066:x <- gsub("^_+", "", x)            # rimuove underscore iniziali
1760436022068:x <- gsub("__+", "_", x)           # comprime doppi underscore
1760436022070:x <- tolower(x)                    # mette tutto minuscolo
1760436022071:return(x)
1760436022074:}
1760436030609:# Applichiamo la funzione di normalizzazione
1760436030611:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760436034415:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760436035931:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760436035933:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760436230893:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760436230897:#SETUP PACCHETTI E PERCORSI
1760436230901:# Setup iniziale
1760436230902:library(data.table)   # lavoro tabellare semplice e veloce
1760436231282:library(ggplot2)      # per il plot richiesto
1760436231702:# Percorsi input #NECESSARIO?
1760436231705:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760436232419:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760436232867:#TASK 1.1
1760436232884:#provide a new file where cell type, cells and integration clusters are combined
1760436232887:#Leggi i due file
1760436232890:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760436233787:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760436234771:# 3️⃣ Controlliamo i nomi delle colonne
1760436234774:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760436235653:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760436236226:# Nuova versione: rimuove anche _X_ o _Y_ in mezzo agli ID
1760436236229:normalize_cell_id <- function(x) {
1760436236231:x <- as.character(x)
1760436236233:x <- trimws(x)                     # toglie spazi iniziali/finali
1760436236235:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760436236236:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760436236239:x <- gsub("_+$", "", x)            # rimuove underscore finali
1760436236243:x <- gsub("^_+", "", x)            # rimuove underscore iniziali
1760436236245:x <- gsub("__+", "_", x)           # comprime doppi underscore
1760436236247:x <- tolower(x)                    # mette tutto minuscolo
1760436236249:return(x)
1760436236253:}
1760436239388:# Applichiamo la funzione di normalizzazione
1760436239392:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760436240324:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760436241529:# --- Diagnosi: controlliamo i nomi normalizzati ---
1760436241533:cat("Numero di celle (integration):", length(unique(integration_dt$cell_clean)), "\n")
1760436243633:cat("Numero di celle (clustering): ", length(unique(clustering_dt$cell_clean)), "\n")
1760436244938:# Quante celle coincidono davvero
1760436244940:same_ids <- intersect(integration_dt$cell_clean, clustering_dt$cell_clean)
1760436254567:cat("Celle in comune:", length(same_ids), "\n")
1760436256338:# Mostriamo i primi 10 ID di ciascun file per capire la differenza
1760436256341:cat("\nEsempi di integration_dt$cell_clean:\n")
1760436257474:print(head(unique(integration_dt$cell_clean), 10))
1760436260357:cat("\nEsempi di clustering_dt$cell_clean:\n")
1760436262637:print(head(unique(clustering_dt$cell_clean), 10))
1760436263484:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760436263500:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760436264739:# 4. Salvo il file risultante
1760436264742:out1 <- paste0(out_prefix, "_cells_clusters_celltypes.csv")
1760436402405:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760436402409:#SETUP PACCHETTI E PERCORSI
1760436402411:# Setup iniziale
1760436402412:library(data.table)   # lavoro tabellare semplice e veloce
1760436402987:library(ggplot2)      # per il plot richiesto
1760436403439:# Percorsi input #NECESSARIO?
1760436403443:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760436404213:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760436404739:#TASK 1.1
1760436404742:#provide a new file where cell type, cells and integration clusters are combined
1760436404743:#Leggi i due file
1760436404744:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760436405476:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760436406221:# 3️⃣ Controlliamo i nomi delle colonne
1760436406226:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760436406713:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760436407581:# Nuova versione: rimuove anche _X_ o _Y_ in mezzo agli ID
1760436407585:normalize_cell_id <- function(x) {
1760436407586:x <- as.character(x)
1760436407588:x <- trimws(x)                     # toglie spazi iniziali/finali
1760436407589:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760436407590:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760436407592:x <- gsub("_+$", "", x)            # rimuove underscore finali
1760436407593:x <- gsub("^_+", "", x)            # rimuove underscore iniziali
1760436407595:x <- gsub("__+", "_", x)           # comprime doppi underscore
1760436407597:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760436407599:x <- tolower(x)                    # mette tutto minuscolo
1760436407601:return(x)
1760436407604:}
1760436410838:# Applichiamo la funzione di normalizzazione
1760436410841:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760436411672:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760436412293:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760436412295:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760436435203:# 4. Salvo il file risultante
1760436435205:out1 <- paste0(out_prefix, "_cells_clusters_celltypes.csv")
1760436452048:# 4. Salvo il file risultante
1760436452050:fwrite(combined, out1)
1760436458151:# 4. Salvo il file risultante
1760436458155:fwrite(combined)
1760436462825:View(combined)
1760436584140:View(clustering_dt)
1760436589892:View(combined)
1760436925202:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760436925205:#SETUP PACCHETTI E PERCORSI
1760436925208:# Setup iniziale
1760436925209:library(data.table)   # lavoro tabellare semplice e veloce
1760436925391:library(ggplot2)      # per il plot richiesto
1760436925548:# Percorsi input #NECESSARIO?
1760436925551:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760436925702:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760436926368:#TASK 1.1
1760436926376:#provide a new file where cell type, cells and integration clusters are combined
1760436926381:#Leggi i due file
1760436926386:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760436927014:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760436927661:# 3️⃣ Controlliamo i nomi delle colonne
1760436927666:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760436928834:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760436929467:# Nuova versione: rimuove anche _X_ o _Y_ in mezzo agli ID
1760436929472:normalize_cell_id <- function(x) {
1760436929474:x <- as.character(x)
1760436929476:x <- trimws(x)                     # toglie spazi iniziali/finali
1760436929477:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760436929478:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760436929480:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760436929481:return(x)
1760436929483:}
1760436931284:# Applichiamo la funzione di normalizzazione
1760436931287:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760436958119:library(data.table)   # lavoro tabellare semplice e veloce
1760436958123:library(ggplot2)      # per il plot richiesto
1760436958125:# Percorsi input #NECESSARIO?
1760436958126:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760436958127:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760436958128:#TASK 1.1
1760436958130:#provide a new file where cell type, cells and integration clusters are combined
1760436958131:#Leggi i due file
1760436958132:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760436958140:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760436958149:# 3️⃣ Controlliamo i nomi delle colonne
1760436958149:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760436958151:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760436958153:# Nuova versione: rimuove anche _X_ o _Y_ in mezzo agli ID
1760436958154:normalize_cell_id <- function(x) {
1760436958155:x <- as.character(x)
1760436958156:x <- trimws(x)                     # toglie spazi iniziali/finali
1760436958157:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760436958158:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760436958159:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760436958160:return(x)
1760436958161:}
1760436958163:# Applichiamo la funzione di normalizzazione
1760436958164:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760436958192:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760436958235:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760436958235:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760436958277:# 4. Salvo il file risultante
1760436958278:fwrite(combined)
1760436960481:View(combined)
1760436978651:#Final revision
1760436978654:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760436978657:#Data:
1760436978660:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760436978662:#• cell = cell id
1760436978663:#• integration_cluster = integration cluster
1760436978665:#nt_combined_clustering.output.csv contains the following columns:
1760436978666:#• cell = cell id
1760436978670:#• cell_type = predicted cell type
1760436978671:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760436978672:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760436978673:#SETUP PACCHETTI E PERCORSI
1760436978675:# Setup iniziale
1760436978676:library(data.table)   # lavoro tabellare semplice e veloce
1760436978677:library(ggplot2)      # per il plot richiesto
1760436978679:# Percorsi input #NECESSARIO?
1760436978680:integration_file   <- "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv"
1760436978680:clustering_file <- "project_oct25/nt_combined_clustering.output.csv"
1760436978682:#TASK 1.1
1760436978682:#provide a new file where cell type, cells and integration clusters are combined
1760436978683:#Leggi i due file
1760436978684:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760436978690:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760436978698:# 3️⃣ Controlliamo i nomi delle colonne
1760436978699:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760436978700:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760436978701:# Nuova versione: rimuove anche _X_ o _Y_ in mezzo agli ID
1760436978702:normalize_cell_id <- function(x) {
1760436978702:x <- as.character(x)
1760436978703:x <- trimws(x)                     # toglie spazi iniziali/finali
1760436978704:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760436978704:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760436978705:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760436978706:return(x)
1760436978707:}
1760436978709:# Applichiamo la funzione di normalizzazione
1760436978709:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760436978737:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760436978767:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760436978768:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760436978805:# 4. Salvo il file risultante
1760436978807:fwrite(combined)
1760437062144:#Final revision
1760437062152:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760437062156:#Data:
1760437062157:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760437062159:#• cell = cell id
1760437062160:#• integration_cluster = integration cluster
1760437062161:#nt_combined_clustering.output.csv contains the following columns:
1760437062161:#• cell = cell id
1760437062163:#• cell_type = predicted cell type
1760437062165:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760437062167:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760437062168:#SETUP PACCHETTI E PERCORSI
1760437062170:# Setup iniziale
1760437062172:library(data.table)   # lavoro tabellare semplice e veloce
1760437062173:library(ggplot2)      # per il plot richiesto
1760437062175:#TASK 1.1
1760437062176:#provide a new file where cell type, cells and integration clusters are combined
1760437062177:#Leggi i due file
1760437062178:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760437062184:clustering_dt <- fread(clustering_file) # colonne attese: cell, cell_type, sample_type
1760437062193:# 3️⃣ Controlliamo i nomi delle colonne
1760437062194:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760437062195:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760437062198:# Nuova versione: rimuove anche _X_ o _Y_ in mezzo agli ID
1760437062198:normalize_cell_id <- function(x) {
1760437062199:x <- as.character(x)
1760437062201:x <- trimws(x)                     # toglie spazi iniziali/finali
1760437062202:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760437062203:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760437062204:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760437062205:return(x)
1760437062205:}
1760437062207:# Applichiamo la funzione di normalizzazione
1760437062208:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760437062239:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760437062275:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760437062275:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760437062313:# 4. Salvo il file risultante
1760437062315:fwrite(combined)
1760437475418:#Final revision
1760437475424:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760437475428:#Data:
1760437475428:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760437475430:#• cell = cell id
1760437475431:#• integration_cluster = integration cluster
1760437475433:#nt_combined_clustering.output.csv contains the following columns:
1760437475435:#• cell = cell id
1760437475436:#• cell_type = predicted cell type
1760437475438:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760437475440:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760437475441:#SETUP PACCHETTI E PERCORSI
1760437475442:# Setup iniziale
1760437475443:library(data.table)   # lavoro tabellare semplice e veloce
1760437475445:library(ggplot2)      # per il plot richiesto
1760437475448:#TASK: provide a file where the number of each cell type is indicated for each cluster
1760437475449:# 1. Assicuriamoci di usare la tabella combinata
1760437475450:dt <- copy(combined)
1760437475453:# 2. Conta per cluster x cell_type
1760437475453:counts_cluster_celltype <- dt[, .N, by = .(integration_cluster, cell_type)]
1760437475457:setnames(counts_cluster_celltype, "N", "cell_count")
1760437475459:# 3. Salvo la tabella (cluster x cell_type counts)
1760437475460:out2 <- paste0(out_prefix, "_counts_per_cluster_celltype.csv")
1760437478300:View(counts_cluster_celltype)
1760437538042:#Final revision
1760437538047:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760437538048:#Data:
1760437538050:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760437538052:#• cell = cell id
1760437538053:#• integration_cluster = integration cluster
1760437538053:#nt_combined_clustering.output.csv contains the following columns:
1760437538054:#• cell = cell id
1760437538055:#• cell_type = predicted cell type
1760437538056:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760437538058:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760437538059:#SETUP PACCHETTI E PERCORSI
1760437538059:# Setup iniziale
1760437538060:library(data.table)   # lavoro tabellare semplice e veloce
1760437538061:library(ggplot2)      # per il plot richiesto
1760437538062:#TASK: provide a file where the number of each cell type is indicated for each cluster
1760437538063:# 1. Assicuriamoci di usare la tabella combinata
1760437538064:dt <- copy(combined)
1760437629510:#Final revision
1760437629513:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760437629514:#Data:
1760437629516:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760437629517:#• cell = cell id
1760437629518:#• integration_cluster = integration cluster
1760437629519:#nt_combined_clustering.output.csv contains the following columns:
1760437629523:#• cell = cell id
1760437629525:#• cell_type = predicted cell type
1760437629526:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760437629530:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760437629531:#SETUP PACCHETTI E PERCORSI
1760437629532:# Setup iniziale
1760437629532:library(data.table)   # lavoro tabellare semplice e veloce
1760437629534:library(ggplot2)      # per il plot richiesto
1760437629537:#TASK 1.1
1760437629539:#provide a new file where cell type, cells and integration clusters are combined
1760437629540:#Leggi i due file
1760437629541:integration_dt   <- fread(integration_file)   # colonne attese: cell, integration_cluster
1760437727740:#Final revision
1760437727742:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760437727743:#Data:
1760437727744:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760437727745:#• cell = cell id
1760437727745:#• integration_cluster = integration cluster
1760437727746:#nt_combined_clustering.output.csv contains the following columns:
1760437727747:#• cell = cell id
1760437727748:#• cell_type = predicted cell type
1760437727749:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760437727751:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760437727753:#SETUP PACCHETTI E PERCORSI
1760437727755:# Setup iniziale
1760437727756:library(data.table)   # lavoro tabellare semplice e veloce
1760437727757:library(ggplot2)      # per il plot richiesto
1760437727760:#TASK 1.1
1760437727761:#provide a new file where cell type, cells and integration clusters are combined
1760437727762:#Leggi i due file
1760437727762:integration_dt   <- fread("annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760437789285:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760437789288:#SETUP PACCHETTI E PERCORSI
1760437789290:# Setup iniziale
1760437789292:library(data.table)   # lavoro tabellare semplice e veloce
1760437789725:library(ggplot2)      # per il plot richiesto
1760437790341:#TASK 1.1
1760437790343:#provide a new file where cell type, cells and integration clusters are combined
1760437790344:#Leggi i due file
1760437790345:integration_dt   <- fread("annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760437794286:clustering_dt <- fread("nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760437853995:#Final revision
1760437853998:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760437853999:#Data:
1760437854000:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760437854001:#• cell = cell id
1760437854003:#• integration_cluster = integration cluster
1760437854006:#nt_combined_clustering.output.csv contains the following columns:
1760437854008:#• cell = cell id
1760437854010:#• cell_type = predicted cell type
1760437854012:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760437854013:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760437854014:#SETUP PACCHETTI E PERCORSI
1760437854015:# Setup iniziale
1760437854016:library(data.table)   # lavoro tabellare semplice e veloce
1760437854017:library(ggplot2)      # per il plot richiesto
1760437854019:#TASK 1.1
1760437854021:#provide a new file where cell type, cells and integration clusters are combined
1760437854022:#Leggi i due file
1760437854023:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760437854029:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760437854037:#Controlliamo i nomi delle colonne
1760437854038:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760437854039:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760437854041:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760437854042:normalize_cell_id <- function(x) {
1760437854042:x <- as.character(x)
1760437854043:x <- trimws(x)                     # toglie spazi iniziali/finali
1760437854044:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760437854045:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760437854045:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760437854046:return(x)
1760437854047:}
1760437854048:# Applichiamo la funzione di normalizzazione
1760437854049:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760437854078:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760437854119:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760437854120:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760437854147:#Salvo il file risultante
1760437854147:fwrite(combined)
1760437854174:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760437854175:# 1. Assicuriamoci di usare la tabella combinata
1760437854175:dt <- copy(combined)
1760437854177:# 2. Conta per cluster x cell_type
1760437854178:counts_cluster_celltype <- dt[, .N, by = .(integration_cluster, cell_type)]
1760437854182:setnames(counts_cluster_celltype, "N", "cell_count")
1760437854183:fwrite(counts_cluster_celltype)
1760437936273:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760437936275:# 1. Assicuriamoci di usare la tabella combinata
1760437936278:start_from_combined <- copy(combined)
1760437944212:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760437944217:# 1. Assicuriamoci di usare la tabella combinata
1760437944219:start_from_combined <- copy(combined)
1760437951530:#Salvo il file risultante
1760437951535:fwrite(combined)
1760437958096:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760437958101:#SETUP PACCHETTI E PERCORSI
1760437958103:# Setup iniziale
1760437958105:library(data.table)   # lavoro tabellare semplice e veloce
1760437958455:library(ggplot2)      # per il plot richiesto
1760437958935:#TASK 1.1
1760437958938:#provide a new file where cell type, cells and integration clusters are combined
1760437958939:#Leggi i due file
1760437958941:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760437960199:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760437960595:#Controlliamo i nomi delle colonne
1760437960598:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760437961140:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760437962147:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760437962150:normalize_cell_id <- function(x) {
1760437962153:x <- as.character(x)
1760437962154:x <- trimws(x)                     # toglie spazi iniziali/finali
1760437962156:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760437962157:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760437962158:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760437962160:return(x)
1760437962161:}
1760437963634:# Applichiamo la funzione di normalizzazione
1760437963637:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760437964479:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760437965303:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760437965307:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760437969259:#Salvo il file risultante
1760437969268:fwrite(combined)
1760437978015:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760437978019:# 1. Assicuriamoci di usare la tabella combinata
1760437978021:start_from_combined <- copy(combined)
1760437982923:# 2. Conta per cluster x cell_type
1760437982926:counts_cluster_celltype <- start_from_combined[, .N, by = .(integration_cluster, cell_type)]
1760438011624:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760438011629:# 1. Assicuriamoci di usare la tabella combinata
1760438011634:start_point <- copy(combined)
1760438012704:# 2. Conta per cluster x cell_type
1760438012707:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760438015858:setnames(counts_cluster_celltype, "N", "cell_count")
1760438017359:fwrite(counts_cluster_celltype)
1760438019214:View(start_point)
1760438482774:# 1. Ripartiamo da combined
1760438482778:start_point <- copy(combined)
1760438484113:# 2. Conta righe per (cluster, cell_type, sample_type)
1760438484116:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760438488272:setnames(tab_ct_st, "N", "cell_count")
1760438489944:View(tab_ct_st)
1760438496635:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760438496639:totals_cluster <- start_point[, .N, by = integration_cluster]
1760438498427:setnames(totals_cluster, "N", "cluster_total_cells")
1760438499615:View(totals_cluster)
1760438506860:# 4. Unisci il totale per cluster
1760438506863:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760438509137:View(tab_ct_st)
1760438514856:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760438514859:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760438521268:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760438521274:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760438521275:totals_cluster_celltype <- dt[, .N, by = .(integration_cluster, cell_type)]
1760438523245:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760438535345:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760438535350:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760438535352:totals_cluster_celltype <- dt[, .N, by = (integration_cluster, cell_type)]
1760438582157:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760438582161:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760438582163:totals_cluster_celltype <- dt[, .N, by = .(integration_cluster, cell_type)]
1760438603667:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760438620122:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760438620126:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760438620127:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760438621075:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760438622674:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760438622676:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760438624047:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760438626136:# 8. Riordino colonne per chiarezza e salvo
1760438626141:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760438626143:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760438626146:"cluster_total_cells", "pct_within_cluster"))
1760438627868:out3 <- paste0(out_prefix, "_summary_cluster_celltype_sampletype.csv")
1760438629239:fwrite(tab_ct_st, out3)
1760438664397:# 8. Riordino colonne per chiarezza e salvo
1760438664400:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760438664402:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760438664405:"cluster_total_cells", "pct_within_cluster"))
1760438665515:fwrite(tab_ct_st, out3)
1760438672013:fwrite(tab_ct_st)
1760463285684:library(data.table) #carica il pacchetto data.table in R per farci delle operazioni
1760463287474:# 1 Import
1760463287476:counts <- fread("project_oct25/bulk_counts_long.csv") #legge i file e li salva come variabili counts e meta che sono matrici con dati, è la funzione ad alte prestazioni di data.table per leggere file e restituisce un oggetto di classe data.table
1760463293427:meta <- fread("project_oct25/sample_metadata.csv")  #definiamo il path così sa dove trovare i file
1760463295513:View(counts)
1760463298917:View(meta)
1760463317448:# 4 Faccio un join (merge) tra counts e metadata
1760463317452:#    -> Uso merge() di base per chiarezza
1760463317453:merged_data <- merge(
1760463317454:counts,
1760463317455:meta,
1760463317456:by = "sample_id",    #colonna comune, anello congiugente
1760463317459:) #vogliamo avere, per ogni misura di espressione genica (count), anche la condizione sperimentale (treated o control).
1760463320455:View(merged_data)
1760469211001:# 1. Preparazione dati per plotting: calcolo proporzioni per cluster x sample_type
1760469211006:plot_celltype <- start_point[, .N, by = .(integration_cluster, sample_type, cell_type)]
1760469237297:#Final revision
1760469237301:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760469237303:#Data:
1760469237305:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760469237307:#• cell = cell id
1760469237309:#• integration_cluster = integration cluster
1760469237311:#nt_combined_clustering.output.csv contains the following columns:
1760469237312:#• cell = cell id
1760469237313:#• cell_type = predicted cell type
1760469237315:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760469237317:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760469237318:#SETUP PACCHETTI E PERCORSI
1760469237319:# Setup iniziale
1760469237320:library(data.table)   # lavoro tabellare semplice e veloce
1760469237323:library(ggplot2)      # per il plot richiesto
1760469237326:#TASK 1.1
1760469237327:#provide a new file where cell type, cells and integration clusters are combined
1760469237328:#Leggi i due file
1760469237328:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760469237358:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760469237379:#Controlliamo i nomi delle colonne
1760469237380:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760469237381:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760469237382:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760469237383:normalize_cell_id <- function(x) {
1760469237384:x <- as.character(x)
1760469237384:x <- trimws(x)                     # toglie spazi iniziali/finali
1760469237385:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760469237385:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760469237386:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760469237387:return(x)
1760469237388:}
1760469237390:# Applichiamo la funzione di normalizzazione
1760469237391:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760469237454:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760469237496:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760469237497:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760469237540:#Salvo il file risultante
1760469237541:fwrite(combined)
1760469237557:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760469237558:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760469237559:#(tabella cluster × cell_type con conti).
1760469237559:# 1. Assicuriamoci di usare la tabella combinata
1760469237560:start_point <- copy(combined)
1760469237563:# 2. Conta per cluster x cell_type
1760469237565:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760469237570:setnames(counts_cluster_celltype, "N", "cell_count")
1760469237571:fwrite(counts_cluster_celltype)
1760469237574:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760469237575:#and also their association to normal and tumor tissue
1760469237576:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760469237577:#cell_count (numero di celle),
1760469237577:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760469237578:#(cioè cell_count / total_cells_in_cluster * 100),
1760469237579:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760469237581:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760469237583:# 1. Ripartiamo da combined
1760469237584:start_point <- copy(combined)
1760469237586:# 2. Conta righe per (cluster, cell_type, sample_type)
1760469237587:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760469237589:setnames(tab_ct_st, "N", "cell_count")
1760469237591:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760469237592:totals_cluster <- start_point[, .N, by = integration_cluster]
1760469237594:setnames(totals_cluster, "N", "cluster_total_cells")
1760469237596:# 4. Unisci il totale per cluster
1760469237597:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760469237603:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760469237603:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760469237606:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760469237607:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760469237608:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760469237610:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760469237612:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760469237613:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760469237619:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760469237629:# 8. Riordino colonne per chiarezza e salvo
1760469237633:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760469237634:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760469237636:"cluster_total_cells", "pct_within_cluster"))
1760469237640:fwrite(tab_ct_st)
1760469250133:# 1. Preparazione dati per plotting: calcolo proporzioni per cluster x sample_type
1760469250137:plot_celltype <- start_point[, .N, by = .(integration_cluster, sample_type, cell_type)]
1760469255754:View(plot_celltype)
1760469276194:setnames(plot_celltype, "N", "count")
1760469279639:View(plot_celltype)
1760469287848:# calcola totale per cluster x sample_type
1760469287851:tot_cluster <- plot_celltype[, .(total = sum(count)), by = .(integration_cluster, sample_type)]
1760469300625:View(tot_cluster)
1760469306879:plot_cluster <- merge(plot_cluster, tot_cluster, by = c("integration_cluster", "sample_type"))
1760469317950:plot_cluster <- merge(plot_cluster, tot_cluster, by = c("integration_cluster", "sample_type"))
1760469321455:# calcola totale per cluster x sample_type
1760469321466:tot_cluster <- plot_celltype[, .(total = sum(count)), by = .(integration_cluster, sample_type)]
1760469324051:plot_cluster <- merge(plot_cluster, tot_cluster, by = c("integration_cluster", "sample_type"))
1760469340451:plot_cluster <- merge(plot_celltype, tot_cluster, by = c("integration_cluster", "sample_type"))
1760469346126:View(plot_cluster)
1760469377420:plot_cluster[, prop := count / total]  # proporzione (0..1)
1760469403263:# 2. Plot: per cluster sull'asse x, fill = cell_type, faceted per sample_type (N,T)
1760469403267:plot <- ggplot(plot_celltype, aes(x = factor(integration_cluster), y = prop, fill = cell_type)) +
1760469403269:geom_bar(stat = "identity", position = "stack") +
1760469403272:facet_wrap(~ sample_type, nrow = 1) +
1760469403274:labs(x = "Integration cluster", y = "Proportion of cells (within cluster & sample type)",
1760469403276:title = "Distribution of cell types per integration cluster (Normal vs Tumor)") +
1760469403277:theme_bw() +
1760469403279:theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
1760469407520:# 3. Salvo il plot come PNG
1760469407524:out_plot <- paste0(out_prefix, "_celltype_distribution_by_cluster_and_sampletype.png")
1760469417334:# 3. Salvo il plot come PNG
1760469417336:out_plot <- paste0("_celltype_distribution_by_cluster_and_sampletype.png")
1760469418552:ggsave(out_plot, p, width = 12, height = 5, dpi = 150)
1760469429203:ggsave(out_plot, plot, width = 12, height = 5, dpi = 150)
1760469456335:`rlang::last_trace()
1760469467036:# 2. Plot: per cluster sull'asse x, fill = cell_type, faceted per sample_type (N,T)
1760469467039:plot <- ggplot(plot_celltype, aes(x = factor(integration_cluster), y = prop, fill = cell_type)) +
1760469467041:geom_bar(stat = "identity", position = "stack") +
1760469467042:facet_wrap(~ sample_type, nrow = 1) +
1760469467045:labs(x = "Integration cluster", y = "Proportion of cells (within cluster & sample type)",
1760469467047:title = "Distribution of cell types per integration cluster (Normal vs Tumor)") +
1760469467050:theme_bw() +
1760469467056:theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
1760469469072:# 3. Salvo il plot come PNG
1760469469076:out_plot <- paste0("_celltype_distribution_by_cluster_and_sampletype.png")
1760469469989:ggsave(out_plot, plot, width = 12, height = 5, dpi = 150)
1760469473211:cat("Saved plot to:", out_plot, "\n")
1760469645020:# 1. partiamo da plot_dt (ha count, total, prop)
1760469645023:plot[, pct := (count / total) * 100]  # percentuale %
1760469653494:# 2. Salvo CSV con percentuali
1760469653496:out5 <- paste0(out_prefix, "_percentages_celltype_by_cluster_sampletype.csv")
1760469655981:fwrite(plot_dt[, .(integration_cluster, sample_type, cell_type, count, total, pct)], out5)
1760469658226:cat("Saved normalized percentages to:", out5, "\n")
1760469658722:print(head(plot_dt[, .(integration_cluster, sample_type, cell_type, pct)], 20))
1760469661913:View(plot)
1760469663030:View(plot)
1760469664343:View(plot)
1760469723265:# 1.
1760469723269:plot_cluster[, pct := (count / total) * 100]  # percentuale %
1760469725272:# 2. Salvo CSV con percentuali
1760469725276:out5 <- paste0(out_prefix, "_percentages_celltype_by_cluster_sampletype.csv")
1760469727653:fwrite(plot_dt[, .(integration_cluster, sample_type, cell_type, count, total, pct)], out5)
1760469740469:# 2. Salvo CSV con percentuali
1760469740475:out5 <- paste0(out_prefix, "_percentages_celltype_by_cluster_sampletype.csv")
1760469741076:fwrite(plot_cluster[, .(integration_cluster, sample_type, cell_type, count, total, pct)], out5)
1760469744276:cat("Saved normalized percentages to:", out5, "\n")
1760469744787:print(head(plot_dt[, .(integration_cluster, sample_type, cell_type, pct)], 20))
1760469823311:# 1.
1760469823316:plot_celltype[, pct := (count / total) * 100]  # percentuale %
1760469827053:# 2. Salvo CSV con percentuali
1760469827057:out5 <- paste0(out_prefix, "_percentages_celltype_by_cluster_sampletype.csv")
1760469828049:fwrite(plot_cluster[, .(integration_cluster, sample_type, cell_type, count, total, pct)], out5)
1760469828841:cat("Saved normalized percentages to:", out5, "\n")
1760469829868:print(head(plot_dt[, .(integration_cluster, sample_type, cell_type, pct)], 20))
1760469856443:# 1.
1760469856445:plot_celltype[, pct := (count / total) * 100]  # percentuale %
1760469866441:#Final revision
1760469866444:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760469866446:#Data:
1760469866447:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760469866448:#• cell = cell id
1760469866449:#• integration_cluster = integration cluster
1760469866452:#nt_combined_clustering.output.csv contains the following columns:
1760469866453:#• cell = cell id
1760469866455:#• cell_type = predicted cell type
1760469866457:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760469866459:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760469866460:#SETUP PACCHETTI E PERCORSI
1760469866461:# Setup iniziale
1760469866462:library(data.table)   # lavoro tabellare semplice e veloce
1760469866462:library(ggplot2)      # per il plot richiesto
1760469866464:#TASK 1.1
1760469866465:#provide a new file where cell type, cells and integration clusters are combined
1760469866466:#Leggi i due file
1760469866467:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760469866468:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760469866470:#Controlliamo i nomi delle colonne
1760469866471:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760469866472:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760469866474:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760469866475:normalize_cell_id <- function(x) {
1760469866475:x <- as.character(x)
1760469866476:x <- trimws(x)                     # toglie spazi iniziali/finali
1760469866477:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760469866478:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760469866478:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760469866479:return(x)
1760469866480:}
1760469866481:# Applichiamo la funzione di normalizzazione
1760469866482:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760469866483:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760469866484:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760469866485:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760469866486:#Salvo il file risultante
1760469866487:fwrite(combined)
1760469866488:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760469866488:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760469866489:#(tabella cluster × cell_type con conti).
1760469866490:# 1. Assicuriamoci di usare la tabella combinata
1760469866490:start_point <- copy(combined)
1760469866491:# 2. Conta per cluster x cell_type
1760469866492:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760469866493:setnames(counts_cluster_celltype, "N", "cell_count")
1760469866493:fwrite(counts_cluster_celltype)
1760469866494:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760469866495:#and also their association to normal and tumor tissue
1760469866496:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760469866497:#cell_count (numero di celle),
1760469866497:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760469866498:#(cioè cell_count / total_cells_in_cluster * 100),
1760469866499:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760469866499:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760469866501:# 1. Ripartiamo da combined
1760469866501:start_point <- copy(combined)
1760469866502:# 2. Conta righe per (cluster, cell_type, sample_type)
1760469866503:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760469866504:setnames(tab_ct_st, "N", "cell_count")
1760469866505:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760469866506:totals_cluster <- start_point[, .N, by = integration_cluster]
1760469866506:setnames(totals_cluster, "N", "cluster_total_cells")
1760469866507:# 4. Unisci il totale per cluster
1760469866508:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760469866509:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760469866510:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760469866511:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760469866512:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760469866512:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760469866513:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760469866515:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760469866515:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760469866516:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760469866517:# 8. Riordino colonne per chiarezza e salvo
1760469866518:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760469866519:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760469866519:"cluster_total_cells", "pct_within_cluster"))
1760469866521:fwrite(tab_ct_st)
1760469866522:#TASK4.1
1760469866523:#Provide a plot describing the distribution of the cell type in normal/tumor tissue given the
1760469866524:#integration clusters
1760469866525:# 1. Preparazione dati per plotting: calcolo proporzioni per cluster x sample_type
1760469866526:plot_celltype <- start_point[, .N, by = .(integration_cluster, sample_type, cell_type)]
1760469866526:setnames(plot_celltype, "N", "count")
1760469866528:# calcola totale per cluster x sample_type
1760469866528:tot_cluster <- plot_celltype[, .(total = sum(count)), by = .(integration_cluster, sample_type)]
1760469866529:plot_cluster <- merge(plot_celltype, tot_cluster, by = c("integration_cluster", "sample_type"))
1760469866530:plot_cluster[, prop := count / total]  # proporzione (0..1)
1760469866531:# 2. Plot: per cluster sull'asse x, fill = cell_type, faceted per sample_type (N,T)
1760469866532:plot <- ggplot(plot_celltype, aes(x = factor(integration_cluster), y = prop, fill = cell_type)) +
1760469866532:geom_bar(stat = "identity", position = "stack") +
1760469866533:facet_wrap(~ sample_type, nrow = 1) +
1760469866534:labs(x = "Integration cluster", y = "Proportion of cells (within cluster & sample type)",
1760469866535:title = "Distribution of cell types per integration cluster (Normal vs Tumor)") +
1760469866535:theme_bw() +
1760469866536:theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
1760469866537:# 3. Salvo il plot come PNG
1760469866538:out_plot <- paste0("_celltype_distribution_by_cluster_and_sampletype.png")
1760469866539:ggsave(out_plot, plot, width = 12, height = 5, dpi = 150)
1760469866540:cat("Saved plot to:", out_plot, "\n")
1760469888927:#Final revision
1760469888929:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760469888930:#Data:
1760469888930:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760469888931:#• cell = cell id
1760469888931:#• integration_cluster = integration cluster
1760469888932:#nt_combined_clustering.output.csv contains the following columns:
1760469888933:#• cell = cell id
1760469888933:#• cell_type = predicted cell type
1760469888934:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760469888935:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760469888935:#SETUP PACCHETTI E PERCORSI
1760469888936:# Setup iniziale
1760469888938:library(data.table)   # lavoro tabellare semplice e veloce
1760469889222:library(ggplot2)      # per il plot richiesto
1760469890154:#TASK 1.1
1760469890154:#provide a new file where cell type, cells and integration clusters are combined
1760469890155:#Leggi i due file
1760469890155:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760469890163:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760469890170:#Controlliamo i nomi delle colonne
1760469890170:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760469890171:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760469890173:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760469890174:normalize_cell_id <- function(x) {
1760469890174:x <- as.character(x)
1760469890175:x <- trimws(x)                     # toglie spazi iniziali/finali
1760469890177:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760469890178:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760469890179:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760469890179:return(x)
1760469890180:}
1760469890182:# Applichiamo la funzione di normalizzazione
1760469890183:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760469890222:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760469890257:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760469890258:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760469890299:#Salvo il file risultante
1760469890301:fwrite(combined)
1760469890317:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760469890317:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760469890318:#(tabella cluster × cell_type con conti).
1760469890319:# 1. Assicuriamoci di usare la tabella combinata
1760469890320:start_point <- copy(combined)
1760469890322:# 2. Conta per cluster x cell_type
1760469890323:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760469890326:setnames(counts_cluster_celltype, "N", "cell_count")
1760469890327:fwrite(counts_cluster_celltype)
1760469890329:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760469890329:#and also their association to normal and tumor tissue
1760469890330:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760469890330:#cell_count (numero di celle),
1760469890331:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760469890332:#(cioè cell_count / total_cells_in_cluster * 100),
1760469890332:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760469890333:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760469890334:# 1. Ripartiamo da combined
1760469890334:start_point <- copy(combined)
1760469890336:# 2. Conta righe per (cluster, cell_type, sample_type)
1760469890336:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760469890339:setnames(tab_ct_st, "N", "cell_count")
1760469890340:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760469890340:totals_cluster <- start_point[, .N, by = integration_cluster]
1760469890342:setnames(totals_cluster, "N", "cluster_total_cells")
1760469890344:# 4. Unisci il totale per cluster
1760469890344:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760469890357:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760469890358:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760469890360:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760469890361:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760469890361:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760469890363:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760469890365:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760469890365:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760469890368:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760469890370:# 8. Riordino colonne per chiarezza e salvo
1760469890371:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760469890371:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760469890372:"cluster_total_cells", "pct_within_cluster"))
1760469890373:fwrite(tab_ct_st)
1760469890374:#TASK4.1
1760469890375:#Provide a plot describing the distribution of the cell type in normal/tumor tissue given the
1760469890376:#integration clusters
1760469890377:# 1. Preparazione dati per plotting: calcolo proporzioni per cluster x sample_type
1760469890378:plot_celltype <- start_point[, .N, by = .(integration_cluster, sample_type, cell_type)]
1760469890381:setnames(plot_celltype, "N", "count")
1760469890382:# calcola totale per cluster x sample_type
1760469890383:tot_cluster <- plot_celltype[, .(total = sum(count)), by = .(integration_cluster, sample_type)]
1760469890385:plot_cluster <- merge(plot_celltype, tot_cluster, by = c("integration_cluster", "sample_type"))
1760469890388:plot_cluster[, prop := count / total]  # proporzione (0..1)
1760469890391:# 2. Plot: per cluster sull'asse x, fill = cell_type, faceted per sample_type (N,T)
1760469890391:plot <- ggplot(plot_celltype, aes(x = factor(integration_cluster), y = prop, fill = cell_type)) +
1760469890392:geom_bar(stat = "identity", position = "stack") +
1760469890393:facet_wrap(~ sample_type, nrow = 1) +
1760469890394:labs(x = "Integration cluster", y = "Proportion of cells (within cluster & sample type)",
1760469890395:title = "Distribution of cell types per integration cluster (Normal vs Tumor)") +
1760469890395:theme_bw() +
1760469890396:theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
1760469890421:# 3. Salvo il plot come PNG
1760469890422:out_plot <- paste0("_celltype_distribution_by_cluster_and_sampletype.png")
1760469890423:ggsave(out_plot, plot, width = 12, height = 5, dpi = 150)
1760469941615:#Final revision
1760469941620:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760469941622:#Data:
1760469941623:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760469941624:#• cell = cell id
1760469941625:#• integration_cluster = integration cluster
1760469941626:#nt_combined_clustering.output.csv contains the following columns:
1760469941627:#• cell = cell id
1760469941628:#• cell_type = predicted cell type
1760469941629:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760469941631:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760469941631:#SETUP PACCHETTI E PERCORSI
1760469941632:# Setup iniziale
1760469941633:library(data.table)   # lavoro tabellare semplice e veloce
1760469941634:library(ggplot2)      # per il plot richiesto
1760469941636:#TASK 1.1
1760469941637:#provide a new file where cell type, cells and integration clusters are combined
1760469941638:#Leggi i due file
1760469941640:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760469941645:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760469941651:#Controlliamo i nomi delle colonne
1760469941651:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760469941652:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760469941654:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760469941654:normalize_cell_id <- function(x) {
1760469941655:x <- as.character(x)
1760469941656:x <- trimws(x)                     # toglie spazi iniziali/finali
1760469941657:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760469941658:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760469941658:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760469941659:return(x)
1760469941660:}
1760469941661:# Applichiamo la funzione di normalizzazione
1760469941662:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760469941689:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760469941722:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760469941725:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760469941770:#Salvo il file risultante
1760469941772:fwrite(combined)
1760469941784:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760469941785:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760469941785:#(tabella cluster × cell_type con conti).
1760469941786:# 1. Assicuriamoci di usare la tabella combinata
1760469941787:start_point <- copy(combined)
1760469941789:# 2. Conta per cluster x cell_type
1760469941789:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760469941792:setnames(counts_cluster_celltype, "N", "cell_count")
1760469941793:fwrite(counts_cluster_celltype)
1760469941795:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760469941796:#and also their association to normal and tumor tissue
1760469941796:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760469941797:#cell_count (numero di celle),
1760469941798:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760469941798:#(cioè cell_count / total_cells_in_cluster * 100),
1760469941799:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760469941800:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760469941801:# 1. Ripartiamo da combined
1760469941801:start_point <- copy(combined)
1760469941803:# 2. Conta righe per (cluster, cell_type, sample_type)
1760469941804:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760469941807:setnames(tab_ct_st, "N", "cell_count")
1760469941809:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760469941809:totals_cluster <- start_point[, .N, by = integration_cluster]
1760469941811:setnames(totals_cluster, "N", "cluster_total_cells")
1760469941813:# 4. Unisci il totale per cluster
1760469941813:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760469941817:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760469941818:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760469941820:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760469941820:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760469941821:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760469941823:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760469941825:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760469941826:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760469941829:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760469941831:# 8. Riordino colonne per chiarezza e salvo
1760469941832:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760469941833:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760469941833:"cluster_total_cells", "pct_within_cluster"))
1760469941835:fwrite(tab_ct_st)
1760469941837:#TASK4.1
1760469941838:#Provide a plot describing the distribution of the cell type in normal/tumor tissue given the
1760469941839:#integration clusters
1760469941840:# 1. Preparazione dati per plotting: calcolo proporzioni per cluster x sample_type
1760469941840:plot_dt <- dt[, .N, by = .(integration_cluster, sample_type, cell_type)]
1760469973926:#Final revision
1760469973928:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760469973929:#Data:
1760469973929:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760469973930:#• cell = cell id
1760469973931:#• integration_cluster = integration cluster
1760469973932:#nt_combined_clustering.output.csv contains the following columns:
1760469973933:#• cell = cell id
1760469973933:#• cell_type = predicted cell type
1760469973934:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760469973936:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760469973936:#SETUP PACCHETTI E PERCORSI
1760469973937:# Setup iniziale
1760469973939:library(data.table)   # lavoro tabellare semplice e veloce
1760469973942:library(ggplot2)      # per il plot richiesto
1760469973945:#TASK 1.1
1760469973946:#provide a new file where cell type, cells and integration clusters are combined
1760469973947:#Leggi i due file
1760469973948:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760469973954:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760469973961:#Controlliamo i nomi delle colonne
1760469973962:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760469973963:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760469973965:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760469973966:normalize_cell_id <- function(x) {
1760469973966:x <- as.character(x)
1760469973967:x <- trimws(x)                     # toglie spazi iniziali/finali
1760469973968:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760469973969:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760469973970:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760469973971:return(x)
1760469973972:}
1760469973973:# Applichiamo la funzione di normalizzazione
1760469973974:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760469974001:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760469974035:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760469974036:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760469974062:#Salvo il file risultante
1760469974064:fwrite(combined)
1760469974079:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760469974080:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760469974081:#(tabella cluster × cell_type con conti).
1760469974081:# 1. Assicuriamoci di usare la tabella combinata
1760469974082:start_point <- copy(combined)
1760469974083:# 2. Conta per cluster x cell_type
1760469974084:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760469974086:setnames(counts_cluster_celltype, "N", "cell_count")
1760469974087:fwrite(counts_cluster_celltype)
1760469974089:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760469974090:#and also their association to normal and tumor tissue
1760469974090:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760469974091:#cell_count (numero di celle),
1760469974092:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760469974093:#(cioè cell_count / total_cells_in_cluster * 100),
1760469974095:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760469974096:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760469974097:# 1. Ripartiamo da combined
1760469974098:start_point <- copy(combined)
1760469974099:# 2. Conta righe per (cluster, cell_type, sample_type)
1760469974100:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760469974102:setnames(tab_ct_st, "N", "cell_count")
1760469974103:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760469974104:totals_cluster <- start_point[, .N, by = integration_cluster]
1760469974107:setnames(totals_cluster, "N", "cluster_total_cells")
1760469974109:# 4. Unisci il totale per cluster
1760469974109:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760469974113:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760469974113:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760469974116:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760469974117:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760469974117:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760469974119:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760469974121:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760469974121:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760469974125:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760469974128:# 8. Riordino colonne per chiarezza e salvo
1760469974129:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760469974129:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760469974130:"cluster_total_cells", "pct_within_cluster"))
1760469974131:fwrite(tab_ct_st)
1760469974133:#TASK4.1
1760469974134:#Provide a plot describing the distribution of the cell type in normal/tumor tissue given the
1760469974135:#integration clusters
1760469974136:# 1. Preparazione dati per plotting: calcolo proporzioni per cluster x sample_type
1760469974136:plot_dt <- start_point[, .N, by = .(integration_cluster, sample_type, cell_type)]
1760469974139:setnames(plot_dt, "N", "count")
1760469974141:# calcola totale per cluster x sample_type
1760469974142:tot_cs <- plot_dt[, .(total = sum(count)), by = .(integration_cluster, sample_type)]
1760469974143:plot_dt <- merge(plot_dt, tot_cs, by = c("integration_cluster", "sample_type"))
1760469974146:plot_dt[, prop := count / total]  # proporzione (0..1)
1760469974148:# 2. Plot: per cluster sull'asse x, fill = cell_type, faceted per sample_type (N,T)
1760469974149:p <- ggplot(plot_dt, aes(x = factor(integration_cluster), y = prop, fill = cell_type)) +
1760469974150:geom_bar(stat = "identity", position = "stack") +
1760469974150:facet_wrap(~ sample_type, nrow = 1) +
1760469974151:labs(x = "Integration cluster", y = "Proportion of cells (within cluster & sample type)",
1760469974152:title = "Distribution of cell types per integration cluster (Normal vs Tumor)") +
1760469974152:theme_bw() +
1760469974153:theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
1760469974163:# 3. Salvo il plot come PNG
1760469974163:out_plot <- paste0(out_prefix, "_celltype_distribution_by_cluster_and_sampletype.png")
1760470010515:#Final revision
1760470010518:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760470010520:#Data:
1760470010521:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760470010523:#• cell = cell id
1760470010524:#• integration_cluster = integration cluster
1760470010525:#nt_combined_clustering.output.csv contains the following columns:
1760470010526:#• cell = cell id
1760470010527:#• cell_type = predicted cell type
1760470010528:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760470010530:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760470010531:#SETUP PACCHETTI E PERCORSI
1760470010532:# Setup iniziale
1760470010533:library(data.table)   # lavoro tabellare semplice e veloce
1760470010535:library(ggplot2)      # per il plot richiesto
1760470010537:#TASK 1.1
1760470010537:#provide a new file where cell type, cells and integration clusters are combined
1760470010538:#Leggi i due file
1760470010539:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760470010544:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760470010550:#Controlliamo i nomi delle colonne
1760470010551:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760470010552:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760470010554:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760470010554:normalize_cell_id <- function(x) {
1760470010555:x <- as.character(x)
1760470010556:x <- trimws(x)                     # toglie spazi iniziali/finali
1760470010556:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760470010557:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760470010558:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760470010559:return(x)
1760470010559:}
1760470010561:# Applichiamo la funzione di normalizzazione
1760470010562:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760470010589:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760470010622:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760470010622:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760470010656:#Salvo il file risultante
1760470010657:fwrite(combined)
1760470010666:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760470010667:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760470010668:#(tabella cluster × cell_type con conti).
1760470010668:# 1. Assicuriamoci di usare la tabella combinata
1760470010669:start_point <- copy(combined)
1760470010670:# 2. Conta per cluster x cell_type
1760470010671:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760470010673:setnames(counts_cluster_celltype, "N", "cell_count")
1760470010674:fwrite(counts_cluster_celltype)
1760470010675:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760470010676:#and also their association to normal and tumor tissue
1760470010677:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760470010678:#cell_count (numero di celle),
1760470010682:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760470010683:#(cioè cell_count / total_cells_in_cluster * 100),
1760470010684:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760470010685:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760470010686:# 1. Ripartiamo da combined
1760470010687:start_point <- copy(combined)
1760470010689:# 2. Conta righe per (cluster, cell_type, sample_type)
1760470010689:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760470010692:setnames(tab_ct_st, "N", "cell_count")
1760470010693:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760470010694:totals_cluster <- start_point[, .N, by = integration_cluster]
1760470010696:setnames(totals_cluster, "N", "cluster_total_cells")
1760470010698:# 4. Unisci il totale per cluster
1760470010699:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760470010703:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760470010704:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760470010706:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760470010707:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760470010708:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760470010710:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760470010711:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760470010712:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760470010716:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760470010718:# 8. Riordino colonne per chiarezza e salvo
1760470010720:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760470010721:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760470010722:"cluster_total_cells", "pct_within_cluster"))
1760470010727:fwrite(tab_ct_st)
1760470010730:#TASK4.1
1760470010731:#Provide a plot describing the distribution of the cell type in normal/tumor tissue given the
1760470010731:#integration clusters
1760470010732:# 1. Preparazione dati per plotting: calcolo proporzioni per cluster x sample_type
1760470010733:plot_dt <- start_point[, .N, by = .(integration_cluster, sample_type, cell_type)]
1760470010735:setnames(plot_dt, "N", "count")
1760470010737:# calcola totale per cluster x sample_type
1760470010737:tot_cs <- plot_dt[, .(total = sum(count)), by = .(integration_cluster, sample_type)]
1760470010739:plot_dt <- merge(plot_dt, tot_cs, by = c("integration_cluster", "sample_type"))
1760470010742:plot_dt[, prop := count / total]  # proporzione (0..1)
1760470010745:# 2. Plot: per cluster sull'asse x, fill = cell_type, faceted per sample_type (N,T)
1760470010746:p <- ggplot(plot_dt, aes(x = factor(integration_cluster), y = prop, fill = cell_type)) +
1760470010747:geom_bar(stat = "identity", position = "stack") +
1760470010747:facet_wrap(~ sample_type, nrow = 1) +
1760470010748:labs(x = "Integration cluster", y = "Proportion of cells (within cluster & sample type)",
1760470010749:title = "Distribution of cell types per integration cluster (Normal vs Tumor)") +
1760470010750:theme_bw() +
1760470010750:theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
1760470010760:# 3. Salvo il plot come PNG
1760470010760:out_plot <- paste0("_celltype_distribution_by_cluster_and_sampletype.png")
1760470010761:ggsave(out_plot, p, width = 12, height = 5, dpi = 150)
1760470012251:cat("Saved plot to:", out_plot, "\n")
1760470054997:#Final revision
1760470055000:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760470055001:#Data:
1760470055002:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760470055003:#• cell = cell id
1760470055004:#• integration_cluster = integration cluster
1760470055005:#nt_combined_clustering.output.csv contains the following columns:
1760470055006:#• cell = cell id
1760470055007:#• cell_type = predicted cell type
1760470055008:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760470055009:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760470055010:#SETUP PACCHETTI E PERCORSI
1760470055011:# Setup iniziale
1760470055012:library(data.table)   # lavoro tabellare semplice e veloce
1760470055014:library(ggplot2)      # per il plot richiesto
1760470055017:#TASK 1.1
1760470055019:#provide a new file where cell type, cells and integration clusters are combined
1760470055021:#Leggi i due file
1760470055023:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760470055028:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760470055035:#Controlliamo i nomi delle colonne
1760470055036:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760470055038:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760470055040:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760470055041:normalize_cell_id <- function(x) {
1760470055042:x <- as.character(x)
1760470055044:x <- trimws(x)                     # toglie spazi iniziali/finali
1760470055044:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760470055046:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760470055046:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760470055047:return(x)
1760470055048:}
1760470055049:# Applichiamo la funzione di normalizzazione
1760470055050:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760470055077:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760470055105:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760470055106:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760470055152:#Salvo il file risultante
1760470055155:fwrite(combined)
1760470055168:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760470055169:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760470055170:#(tabella cluster × cell_type con conti).
1760470055171:# 1. Assicuriamoci di usare la tabella combinata
1760470055172:start_point <- copy(combined)
1760470055174:# 2. Conta per cluster x cell_type
1760470055175:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760470055178:setnames(counts_cluster_celltype, "N", "cell_count")
1760470055179:fwrite(counts_cluster_celltype)
1760470055183:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760470055184:#and also their association to normal and tumor tissue
1760470055185:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760470055186:#cell_count (numero di celle),
1760470055187:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760470055189:#(cioè cell_count / total_cells_in_cluster * 100),
1760470055190:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760470055191:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760470055193:# 1. Ripartiamo da combined
1760470055194:start_point <- copy(combined)
1760470055197:# 2. Conta righe per (cluster, cell_type, sample_type)
1760470055199:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760470055202:setnames(tab_ct_st, "N", "cell_count")
1760470055205:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760470055206:totals_cluster <- start_point[, .N, by = integration_cluster]
1760470055209:setnames(totals_cluster, "N", "cluster_total_cells")
1760470055211:# 4. Unisci il totale per cluster
1760470055212:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760470055216:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760470055217:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760470055220:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760470055220:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760470055221:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760470055224:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760470055226:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760470055226:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760470055231:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760470055233:# 8. Riordino colonne per chiarezza e salvo
1760470055234:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760470055235:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760470055236:"cluster_total_cells", "pct_within_cluster"))
1760470055238:fwrite(tab_ct_st)
1760470055241:#TASK4.1
1760470055242:#Provide a plot describing the distribution of the cell type in normal/tumor tissue given the
1760470055243:#integration clusters
1760470055245:# 1. Preparazione dati per plotting: calcolo proporzioni per cluster x sample_type
1760470055246:plot_dt <- start_point[, .N, by = .(integration_cluster, sample_type, cell_type)]
1760470055249:setnames(plot_dt, "N", "count")
1760470055251:# calcola totale per cluster x sample_type
1760470055251:tot_cs <- plot_dt[, .(total = sum(count)), by = .(integration_cluster, sample_type)]
1760470055254:plot_dt <- merge(plot_dt, tot_cs, by = c("integration_cluster", "sample_type"))
1760470055257:plot_dt[, prop := count / total]  # proporzione (0..1)
1760470055260:# 2. Plot: per cluster sull'asse x, fill = cell_type, faceted per sample_type (N,T)
1760470055261:p <- ggplot(plot_dt, aes(x = factor(integration_cluster), y = prop, fill = cell_type)) +
1760470055262:geom_bar(stat = "identity", position = "stack") +
1760470055263:facet_wrap(~ sample_type, nrow = 1) +
1760470055264:labs(x = "Integration cluster", y = "Proportion of cells (within cluster & sample type)",
1760470055265:title = "Distribution of cell types per integration cluster (Normal vs Tumor)") +
1760470055266:theme_bw() +
1760470055267:theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
1760470055282:# 3. Salvo il plot come PNG
1760470055284:out_plot <- paste0("_celltype_distribution_by_cluster_and_sampletype.png")
1760470055285:ggsave(out_plot, p, width = 12, height = 5, dpi = 150)
1760470056464:cat("Saved plot to:", out_plot, "\n")
1760470056466:#TASK5.1
1760470056467:#Provide a normalized % for the cell types in each of the integration clusters
1760470056467:#for normal and tumor specimen.
1760470056468:# 1. partiamo da plot_dt (ha count, total, prop)
1760470056469:# Se plot_dt non esiste (se non hai eseguito la sezione plot), ricrealo:
1760470056470:plot_dt <- dt[, .N, by = .(integration_cluster, sample_type, cell_type)]
1760470089132:#Final revision
1760470089133:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760470089135:#Data:
1760470089136:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760470089139:#• cell = cell id
1760470089144:#• integration_cluster = integration cluster
1760470089146:#nt_combined_clustering.output.csv contains the following columns:
1760470089147:#• cell = cell id
1760470089148:#• cell_type = predicted cell type
1760470089148:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760470089150:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760470089151:#SETUP PACCHETTI E PERCORSI
1760470089151:# Setup iniziale
1760470089152:library(data.table)   # lavoro tabellare semplice e veloce
1760470089154:library(ggplot2)      # per il plot richiesto
1760470089156:#TASK 1.1
1760470089157:#provide a new file where cell type, cells and integration clusters are combined
1760470089158:#Leggi i due file
1760470089159:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760470089164:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760470089171:#Controlliamo i nomi delle colonne
1760470089172:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760470089173:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760470089175:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760470089176:normalize_cell_id <- function(x) {
1760470089176:x <- as.character(x)
1760470089177:x <- trimws(x)                     # toglie spazi iniziali/finali
1760470089178:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760470089179:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760470089179:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760470089180:return(x)
1760470089181:}
1760470089182:# Applichiamo la funzione di normalizzazione
1760470089183:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760470089224:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760470089253:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760470089254:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760470089294:#Salvo il file risultante
1760470089295:fwrite(combined)
1760470089308:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760470089309:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760470089309:#(tabella cluster × cell_type con conti).
1760470089310:# 1. Assicuriamoci di usare la tabella combinata
1760470089311:start_point <- copy(combined)
1760470089312:# 2. Conta per cluster x cell_type
1760470089313:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760470089321:setnames(counts_cluster_celltype, "N", "cell_count")
1760470089322:fwrite(counts_cluster_celltype)
1760470089324:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760470089326:#and also their association to normal and tumor tissue
1760470089326:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760470089327:#cell_count (numero di celle),
1760470089328:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760470089329:#(cioè cell_count / total_cells_in_cluster * 100),
1760470089330:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760470089330:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760470089332:# 1. Ripartiamo da combined
1760470089335:start_point <- copy(combined)
1760470089336:# 2. Conta righe per (cluster, cell_type, sample_type)
1760470089337:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760470089340:setnames(tab_ct_st, "N", "cell_count")
1760470089341:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760470089342:totals_cluster <- start_point[, .N, by = integration_cluster]
1760470089344:setnames(totals_cluster, "N", "cluster_total_cells")
1760470089346:# 4. Unisci il totale per cluster
1760470089348:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760470089352:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760470089353:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760470089355:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760470089356:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760470089357:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760470089359:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760470089361:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760470089362:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760470089365:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760470089368:# 8. Riordino colonne per chiarezza e salvo
1760470089368:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760470089369:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760470089370:"cluster_total_cells", "pct_within_cluster"))
1760470089371:fwrite(tab_ct_st)
1760470089374:#TASK4.1
1760470089375:#Provide a plot describing the distribution of the cell type in normal/tumor tissue given the
1760470089376:#integration clusters
1760470089377:# 1. Preparazione dati per plotting: calcolo proporzioni per cluster x sample_type
1760470089378:plot_dt <- start_point[, .N, by = .(integration_cluster, sample_type, cell_type)]
1760470089381:setnames(plot_dt, "N", "count")
1760470089382:# calcola totale per cluster x sample_type
1760470089383:tot_cs <- plot_dt[, .(total = sum(count)), by = .(integration_cluster, sample_type)]
1760470089386:plot_dt <- merge(plot_dt, tot_cs, by = c("integration_cluster", "sample_type"))
1760470089390:plot_dt[, prop := count / total]  # proporzione (0..1)
1760470089394:# 2. Plot: per cluster sull'asse x, fill = cell_type, faceted per sample_type (N,T)
1760470089395:p <- ggplot(plot_dt, aes(x = factor(integration_cluster), y = prop, fill = cell_type)) +
1760470089397:geom_bar(stat = "identity", position = "stack") +
1760470089399:facet_wrap(~ sample_type, nrow = 1) +
1760470089400:labs(x = "Integration cluster", y = "Proportion of cells (within cluster & sample type)",
1760470089401:title = "Distribution of cell types per integration cluster (Normal vs Tumor)") +
1760470089403:theme_bw() +
1760470089404:theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
1760470089421:# 3. Salvo il plot come PNG
1760470089422:out_plot <- paste0("_celltype_distribution_by_cluster_and_sampletype.png")
1760470089422:ggsave(out_plot, p, width = 12, height = 5, dpi = 150)
1760470091125:cat("Saved plot to:", out_plot, "\n")
1760470091127:#TASK5.1
1760470091128:#Provide a normalized % for the cell types in each of the integration clusters
1760470091129:#for normal and tumor specimen.
1760470091130:# 1. partiamo da plot_dt (ha count, total, prop)
1760470091131:# Se plot_dt non esiste (se non hai eseguito la sezione plot), ricrealo:
1760470091132:plot_dt[, pct := (count / total) * 100]  # percentuale %
1760470091135:# 2. Salvo CSV con percentuali
1760470091136:out5 <- paste0(out_prefix, "_percentages_celltype_by_cluster_sampletype.csv")
1760470100772:#Final revision
1760470100775:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760470100775:#Data:
1760470100777:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760470100779:#• cell = cell id
1760470100787:#• integration_cluster = integration cluster
1760470100789:#nt_combined_clustering.output.csv contains the following columns:
1760470100793:#• cell = cell id
1760470100803:#• cell_type = predicted cell type
1760470100805:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760470100807:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760470100809:#SETUP PACCHETTI E PERCORSI
1760470100810:# Setup iniziale
1760470100811:library(data.table)   # lavoro tabellare semplice e veloce
1760470100812:library(ggplot2)      # per il plot richiesto
1760470100815:#TASK 1.1
1760470100816:#provide a new file where cell type, cells and integration clusters are combined
1760470100817:#Leggi i due file
1760470100818:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760470100823:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760470100829:#Controlliamo i nomi delle colonne
1760470100830:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760470100831:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760470100833:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760470100834:normalize_cell_id <- function(x) {
1760470100834:x <- as.character(x)
1760470100835:x <- trimws(x)                     # toglie spazi iniziali/finali
1760470100836:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760470100836:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760470100837:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760470100838:return(x)
1760470100838:}
1760470100839:# Applichiamo la funzione di normalizzazione
1760470100840:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760470100868:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760470100896:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760470100897:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760470100945:#Salvo il file risultante
1760470100948:fwrite(combined)
1760470100958:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760470100959:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760470100960:#(tabella cluster × cell_type con conti).
1760470100961:# 1. Assicuriamoci di usare la tabella combinata
1760470100961:start_point <- copy(combined)
1760470100963:# 2. Conta per cluster x cell_type
1760470100964:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760470100967:setnames(counts_cluster_celltype, "N", "cell_count")
1760470100968:fwrite(counts_cluster_celltype)
1760470100969:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760470100970:#and also their association to normal and tumor tissue
1760470100971:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760470100971:#cell_count (numero di celle),
1760470100972:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760470100973:#(cioè cell_count / total_cells_in_cluster * 100),
1760470100973:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760470100974:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760470100975:# 1. Ripartiamo da combined
1760470100976:start_point <- copy(combined)
1760470100977:# 2. Conta righe per (cluster, cell_type, sample_type)
1760470100978:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760470100980:setnames(tab_ct_st, "N", "cell_count")
1760470100982:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760470100982:totals_cluster <- start_point[, .N, by = integration_cluster]
1760470100984:setnames(totals_cluster, "N", "cluster_total_cells")
1760470100986:# 4. Unisci il totale per cluster
1760470100986:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760470100989:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760470100990:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760470100992:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760470100993:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760470100994:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760470100996:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760470100997:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760470100998:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760470101001:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760470101003:# 8. Riordino colonne per chiarezza e salvo
1760470101004:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760470101004:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760470101005:"cluster_total_cells", "pct_within_cluster"))
1760470101006:fwrite(tab_ct_st)
1760470101008:#TASK4.1
1760470101009:#Provide a plot describing the distribution of the cell type in normal/tumor tissue given the
1760470101009:#integration clusters
1760470101011:# 1. Preparazione dati per plotting: calcolo proporzioni per cluster x sample_type
1760470101011:plot_dt <- start_point[, .N, by = .(integration_cluster, sample_type, cell_type)]
1760470101013:setnames(plot_dt, "N", "count")
1760470101015:# calcola totale per cluster x sample_type
1760470101015:tot_cs <- plot_dt[, .(total = sum(count)), by = .(integration_cluster, sample_type)]
1760470101018:plot_dt <- merge(plot_dt, tot_cs, by = c("integration_cluster", "sample_type"))
1760470101023:plot_dt[, prop := count / total]  # proporzione (0..1)
1760470101026:# 2. Plot: per cluster sull'asse x, fill = cell_type, faceted per sample_type (N,T)
1760470101027:p <- ggplot(plot_dt, aes(x = factor(integration_cluster), y = prop, fill = cell_type)) +
1760470101028:geom_bar(stat = "identity", position = "stack") +
1760470101029:facet_wrap(~ sample_type, nrow = 1) +
1760470101030:labs(x = "Integration cluster", y = "Proportion of cells (within cluster & sample type)",
1760470101031:title = "Distribution of cell types per integration cluster (Normal vs Tumor)") +
1760470101032:theme_bw() +
1760470101033:theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
1760470101046:# 3. Salvo il plot come PNG
1760470101047:out_plot <- paste0("_celltype_distribution_by_cluster_and_sampletype.png")
1760470101048:ggsave(out_plot, p, width = 12, height = 5, dpi = 150)
1760470102360:cat("Saved plot to:", out_plot, "\n")
1760470102362:#TASK5.1
1760470102363:#Provide a normalized % for the cell types in each of the integration clusters
1760470102363:#for normal and tumor specimen.
1760470102364:# 1. partiamo da plot_dt (ha count, total, prop)
1760470102365:# Se plot_dt non esiste (se non hai eseguito la sezione plot), ricrealo:
1760470102366:plot_dt[, pct := (count / total) * 100]  # percentuale %
1760470102368:# 2. Salvo CSV con percentuali
1760470102369:out5 <- paste0("_percentages_celltype_by_cluster_sampletype.csv")
1760470102370:fwrite(plot_dt[, .(integration_cluster, sample_type, cell_type, count, total, pct)], out5)
1760470102374:cat("Saved normalized percentages to:", out5, "\n")
1760470102375:print(head(plot_dt[, .(integration_cluster, sample_type, cell_type, pct)], 20))
1760470147722:View(normalize_cell_id)
1760470168194:View(plot_dt)
1760471063714:#Final revision
1760471063719:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760471063722:#Data:
1760471063724:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760471063726:#• cell = cell id
1760471063727:#• integration_cluster = integration cluster
1760471063730:#nt_combined_clustering.output.csv contains the following columns:
1760471063732:#• cell = cell id
1760471063733:#• cell_type = predicted cell type
1760471063734:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760471063735:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760471063737:#SETUP PACCHETTI E PERCORSI
1760471063737:# Setup iniziale
1760471063738:library(data.table)   # lavoro tabellare semplice e veloce
1760471063741:library(ggplot2)      # per il plot richiesto
1760471063743:#TASK 1.1
1760471063743:#provide a new file where cell type, cells and integration clusters are combined
1760471063744:#Leggi i due file
1760471063745:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760471063753:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760471063761:#Controlliamo i nomi delle colonne
1760471063762:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760471063763:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760471063764:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760471063765:normalize_cell_id <- function(x) {
1760471063767:x <- as.character(x)
1760471063768:x <- trimws(x)                     # toglie spazi iniziali/finali
1760471063769:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760471063770:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760471063770:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760471063771:return(x)
1760471063772:}
1760471063774:# Applichiamo la funzione di normalizzazione
1760471063774:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760471063811:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760471063839:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760471063840:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760471063945:#Salvo il file risultante
1760471063948:fwrite(combined)
1760471063971:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760471063971:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760471063972:#(tabella cluster × cell_type con conti).
1760471063973:# 1. Assicuriamoci di usare la tabella combinata
1760471063973:start_point <- copy(combined)
1760471063975:# 2. Conta per cluster x cell_type
1760471063975:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760471063980:setnames(counts_cluster_celltype, "N", "cell_count")
1760471063981:fwrite(counts_cluster_celltype)
1760471063983:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760471063984:#and also their association to normal and tumor tissue
1760471063984:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760471063985:#cell_count (numero di celle),
1760471063985:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760471063986:#(cioè cell_count / total_cells_in_cluster * 100),
1760471063987:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760471063987:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760471063988:# 1. Ripartiamo da combined
1760471063989:start_point <- copy(combined)
1760471063991:# 2. Conta righe per (cluster, cell_type, sample_type)
1760471063991:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760471063994:setnames(tab_ct_st, "N", "cell_count")
1760471063998:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760471063998:totals_cluster <- dt[, .N, by = integration_cluster]
1760471089304:#Final revision
1760471089307:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760471089309:#Data:
1760471089310:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760471089311:#• cell = cell id
1760471089313:#• integration_cluster = integration cluster
1760471089315:#nt_combined_clustering.output.csv contains the following columns:
1760471089315:#• cell = cell id
1760471089317:#• cell_type = predicted cell type
1760471089318:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760471089320:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760471089322:#SETUP PACCHETTI E PERCORSI
1760471089326:# Setup iniziale
1760471089328:library(data.table)   # lavoro tabellare semplice e veloce
1760471089329:library(ggplot2)      # per il plot richiesto
1760471089331:#TASK 1.1
1760471089332:#provide a new file where cell type, cells and integration clusters are combined
1760471089333:#Leggi i due file
1760471089334:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760471089339:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760471089348:#Controlliamo i nomi delle colonne
1760471089349:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760471089350:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760471089351:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760471089352:normalize_cell_id <- function(x) {
1760471089353:x <- as.character(x)
1760471089354:x <- trimws(x)                     # toglie spazi iniziali/finali
1760471089354:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760471089355:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760471089356:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760471089357:return(x)
1760471089357:}
1760471089359:# Applichiamo la funzione di normalizzazione
1760471089360:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760471089395:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760471089434:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760471089435:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760471089468:#Salvo il file risultante
1760471089469:fwrite(combined)
1760471089483:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760471089485:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760471089487:#(tabella cluster × cell_type con conti).
1760471089487:# 1. Assicuriamoci di usare la tabella combinata
1760471089489:start_point <- copy(combined)
1760471089490:# 2. Conta per cluster x cell_type
1760471089491:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760471089493:setnames(counts_cluster_celltype, "N", "cell_count")
1760471089494:fwrite(counts_cluster_celltype)
1760471089495:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760471089496:#and also their association to normal and tumor tissue
1760471089496:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760471089497:#cell_count (numero di celle),
1760471089498:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760471089498:#(cioè cell_count / total_cells_in_cluster * 100),
1760471089499:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760471089499:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760471089501:# 1. Ripartiamo da combined
1760471089501:start_point <- copy(combined)
1760471089503:# 2. Conta righe per (cluster, cell_type, sample_type)
1760471089503:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760471089506:setnames(tab_ct_st, "N", "cell_count")
1760471089508:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760471089508:totals_cluster <- dt[, .N, by = "integration_cluster"]
1760471113813:#Final revision
1760471113815:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760471113817:#Data:
1760471113817:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760471113819:#• cell = cell id
1760471113819:#• integration_cluster = integration cluster
1760471113820:#nt_combined_clustering.output.csv contains the following columns:
1760471113822:#• cell = cell id
1760471113823:#• cell_type = predicted cell type
1760471113824:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760471113827:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760471113830:#SETUP PACCHETTI E PERCORSI
1760471113831:# Setup iniziale
1760471113831:library(data.table)   # lavoro tabellare semplice e veloce
1760471113832:library(ggplot2)      # per il plot richiesto
1760471113834:#TASK 1.1
1760471113835:#provide a new file where cell type, cells and integration clusters are combined
1760471113835:#Leggi i due file
1760471113836:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760471113843:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760471113859:#Controlliamo i nomi delle colonne
1760471113860:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760471113861:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760471113862:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760471113863:normalize_cell_id <- function(x) {
1760471113864:x <- as.character(x)
1760471113864:x <- trimws(x)                     # toglie spazi iniziali/finali
1760471113865:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760471113866:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760471113867:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760471113867:return(x)
1760471113868:}
1760471113870:# Applichiamo la funzione di normalizzazione
1760471113870:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760471113904:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760471113940:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760471113940:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760471113970:#Salvo il file risultante
1760471113971:fwrite(combined)
1760471113981:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760471113981:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760471113982:#(tabella cluster × cell_type con conti).
1760471113983:# 1. Assicuriamoci di usare la tabella combinata
1760471113983:start_point <- copy(combined)
1760471113984:# 2. Conta per cluster x cell_type
1760471113985:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760471113987:setnames(counts_cluster_celltype, "N", "cell_count")
1760471113989:fwrite(counts_cluster_celltype)
1760471113991:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760471113992:#and also their association to normal and tumor tissue
1760471113992:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760471113993:#cell_count (numero di celle),
1760471113994:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760471113995:#(cioè cell_count / total_cells_in_cluster * 100),
1760471113995:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760471113997:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760471113998:# 1. Ripartiamo da combined
1760471113999:start_point <- copy(combined)
1760471114000:# 2. Conta righe per (cluster, cell_type, sample_type)
1760471114001:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760471114003:setnames(tab_ct_st, "N", "cell_count")
1760471114005:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760471114005:totals_cluster <- dt[, .N, by = integration_cluster]
1760471155047:#Final revision
1760471155050:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760471155054:#Data:
1760471155057:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760471155060:#• cell = cell id
1760471155061:#• integration_cluster = integration cluster
1760471155062:#nt_combined_clustering.output.csv contains the following columns:
1760471155063:#• cell = cell id
1760471155064:#• cell_type = predicted cell type
1760471155065:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760471155066:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760471155067:#SETUP PACCHETTI E PERCORSI
1760471155068:# Setup iniziale
1760471155069:library(data.table)   # lavoro tabellare semplice e veloce
1760471155070:library(ggplot2)      # per il plot richiesto
1760471155072:#TASK 1.1
1760471155073:#provide a new file where cell type, cells and integration clusters are combined
1760471155075:#Leggi i due file
1760471155076:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760471155082:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760471155090:#Controlliamo i nomi delle colonne
1760471155091:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760471155093:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760471155095:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760471155095:normalize_cell_id <- function(x) {
1760471155096:x <- as.character(x)
1760471155097:x <- trimws(x)                     # toglie spazi iniziali/finali
1760471155097:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760471155098:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760471155099:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760471155099:return(x)
1760471155100:}
1760471155101:# Applichiamo la funzione di normalizzazione
1760471155102:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760471155133:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760471155174:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760471155175:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760471155212:#Salvo il file risultante
1760471155213:fwrite(combined)
1760471155224:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760471155225:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760471155226:#(tabella cluster × cell_type con conti).
1760471155226:# 1. Assicuriamoci di usare la tabella combinata
1760471155227:start_point <- copy(combined)
1760471155229:# 2. Conta per cluster x cell_type
1760471155229:counts_cluster_celltype <- start_point[, .N, by = .(integration_dt, cell_type)]
1760471191026:#Final revision
1760471191029:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760471191030:#Data:
1760471191032:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760471191033:#• cell = cell id
1760471191034:#• integration_cluster = integration cluster
1760471191036:#nt_combined_clustering.output.csv contains the following columns:
1760471191038:#• cell = cell id
1760471191041:#• cell_type = predicted cell type
1760471191044:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760471191048:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760471191049:#SETUP PACCHETTI E PERCORSI
1760471191050:# Setup iniziale
1760471191050:library(data.table)   # lavoro tabellare semplice e veloce
1760471191051:library(ggplot2)      # per il plot richiesto
1760471191054:#TASK 1.1
1760471191054:#provide a new file where cell type, cells and integration clusters are combined
1760471191055:#Leggi i due file
1760471191056:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760471191062:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760471191071:#Controlliamo i nomi delle colonne
1760471191072:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760471191074:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760471191075:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760471191076:normalize_cell_id <- function(x) {
1760471191077:x <- as.character(x)
1760471191077:x <- trimws(x)                     # toglie spazi iniziali/finali
1760471191078:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760471191079:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760471191079:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760471191080:return(x)
1760471191081:}
1760471191082:# Applichiamo la funzione di normalizzazione
1760471191083:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760471191114:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760471191143:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760471191143:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760471191175:#Salvo il file risultante
1760471191175:fwrite(combined)
1760471191187:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760471191187:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760471191188:#(tabella cluster × cell_type con conti).
1760471191189:# 1. Assicuriamoci di usare la tabella combinata
1760471191190:start_point <- copy(combined)
1760471191191:# 2. Conta per cluster x cell_type
1760471191192:counts_cluster_celltype <- start_point[, .N, by = .(integration, cell_type)]
1760471246664:#Final revision
1760471246668:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760471246669:#Data:
1760471246671:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760471246673:#• cell = cell id
1760471246673:#• integration_cluster = integration cluster
1760471246674:#nt_combined_clustering.output.csv contains the following columns:
1760471246675:#• cell = cell id
1760471246676:#• cell_type = predicted cell type
1760471246676:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760471246678:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760471246679:#SETUP PACCHETTI E PERCORSI
1760471246679:# Setup iniziale
1760471246680:library(data.table)   # lavoro tabellare semplice e veloce
1760471246957:library(ggplot2)      # per il plot richiesto
1760471247800:#TASK 1.1
1760471247801:#provide a new file where cell type, cells and integration clusters are combined
1760471247802:#Leggi i due file
1760471247803:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760471247812:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760471247819:#Controlliamo i nomi delle colonne
1760471247820:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760471247821:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760471247822:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760471247823:normalize_cell_id <- function(x) {
1760471247824:x <- as.character(x)
1760471247824:x <- trimws(x)                     # toglie spazi iniziali/finali
1760471247825:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760471247826:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760471247826:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760471247827:return(x)
1760471247827:}
1760471247829:# Applichiamo la funzione di normalizzazione
1760471247829:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760471247878:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760471247907:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760471247909:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760471247952:#Salvo il file risultante
1760471247953:fwrite(combined)
1760471247965:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760471247967:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760471247969:#(tabella cluster × cell_type con conti).
1760471247970:# 1. Assicuriamoci di usare la tabella combinata
1760471247971:start_point <- copy(combined)
1760471247973:# 2. Conta per cluster x cell_type
1760471247973:counts_cluster_celltype <- start_point[, .N, by = .(integration, cell_type)]
1760471291561:#Final revision
1760471291564:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760471291568:#Data:
1760471291572:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760471291574:#• cell = cell id
1760471291576:#• integration_cluster = integration cluster
1760471291577:#nt_combined_clustering.output.csv contains the following columns:
1760471291578:#• cell = cell id
1760471291579:#• cell_type = predicted cell type
1760471291580:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760471291582:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760471291583:#SETUP PACCHETTI E PERCORSI
1760471291583:# Setup iniziale
1760471291584:library(data.table)   # lavoro tabellare semplice e veloce
1760471291585:library(ggplot2)      # per il plot richiesto
1760471291587:#TASK 1.1
1760471291588:#provide a new file where cell type, cells and integration clusters are combined
1760471291588:#Leggi i due file
1760471291589:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760471291594:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760471291601:#Controlliamo i nomi delle colonne
1760471291602:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760471291603:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760471291604:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760471291605:normalize_cell_id <- function(x) {
1760471291606:x <- as.character(x)
1760471291607:x <- trimws(x)                     # toglie spazi iniziali/finali
1760471291608:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760471291608:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760471291609:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760471291610:return(x)
1760471291611:}
1760471291612:# Applichiamo la funzione di normalizzazione
1760471291613:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760471291661:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760471291710:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760471291711:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760471291749:#Salvo il file risultante
1760471291750:fwrite(combined)
1760471291766:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760471291767:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760471291767:#(tabella cluster × cell_type con conti).
1760471291768:# 1. Assicuriamoci di usare la tabella combinata
1760471291769:start_point <- copy(combined)
1760471291770:# 2. Conta per cluster x cell_type
1760471291771:counts_cluster_celltype <- start_point[, .N, by = .(integration_dt, cell_type)]
1760471503608:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760471503612:#SETUP PACCHETTI E PERCORSI
1760471503613:# Setup iniziale
1760471503614:library(data.table)   # lavoro tabellare semplice e veloce
1760471504078:library(ggplot2)      # per il plot richiesto
1760471504608:#TASK 1.1
1760471504610:#provide a new file where cell type, cells and integration clusters are combined
1760471504612:#Leggi i due file
1760471504613:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760471505289:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760471505903:#Controlliamo i nomi delle colonne
1760471505908:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760471507029:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760471507855:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760471507859:normalize_cell_id <- function(x) {
1760471507861:x <- as.character(x)
1760471507863:x <- trimws(x)                     # toglie spazi iniziali/finali
1760471507865:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760471507867:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760471507869:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760471507872:return(x)
1760471507874:}
1760471509341:# Applichiamo la funzione di normalizzazione
1760471509344:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760471509959:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760471510459:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760471510464:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760471512108:#Salvo il file risultante
1760471512110:fwrite(combined)
1760471547023:# 2. Conta per cluster x cell_type
1760471547026:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760471548416:setnames(counts_cluster_celltype, "N", "cell_count")
1760471549505:fwrite(counts_cluster_celltype)
1760471555067:# 1. Ripartiamo da combined
1760471555070:start_point <- copy(combined)
1760471557293:# 2. Conta righe per (cluster, cell_type, sample_type)
1760471557297:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760471559306:setnames(tab_ct_st, "N", "cell_count")
1760471560171:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760471560182:totals_cluster <- dt[, .N, by = integration_cluster]
1760471599905:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760471599908:totals_cluster <- dt[, .N, by = integration_dt]
1760471631558:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760471631566:totals_cluster <- start_point[, .N, by = integration_cluster]
1760471633201:setnames(totals_cluster, "N", "cluster_total_cells")
1760471635931:# 4. Unisci il totale per cluster
1760471635935:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760471639101:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760471639104:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760471641316:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760471641321:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760471641327:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760471642369:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760471643740:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760471643741:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760471644547:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760471646352:# 8. Riordino colonne per chiarezza e salvo
1760471646356:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760471646358:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760471646360:"cluster_total_cells", "pct_within_cluster"))
1760471647361:out3 <- paste0("_summary_cluster_celltype_sampletype.csv")
1760471647787:fwrite(tab_ct_st, out3)
1760471821231:#Final revision
1760471821233:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760471821235:#Data:
1760471821235:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760471821236:#• cell = cell id
1760471821237:#• integration_cluster = integration cluster
1760471821237:#nt_combined_clustering.output.csv contains the following columns:
1760471821238:#• cell = cell id
1760471821238:#• cell_type = predicted cell type
1760471821239:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760471821240:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760471821241:#SETUP PACCHETTI E PERCORSI
1760471821242:# Setup iniziale
1760471821243:library(data.table)   # lavoro tabellare semplice e veloce
1760471821248:library(ggplot2)      # per il plot richiesto
1760471821253:#TASK 1.1
1760471821260:#provide a new file where cell type, cells and integration clusters are combined
1760471821269:#Leggi i due file
1760471821270:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760471821275:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760471821282:#Controlliamo i nomi delle colonne
1760471821283:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760471821284:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760471821285:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760471821286:normalize_cell_id <- function(x) {
1760471821287:x <- as.character(x)
1760471821287:x <- trimws(x)                     # toglie spazi iniziali/finali
1760471821288:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760471821288:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760471821289:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760471821290:return(x)
1760471821291:}
1760471821292:# Applichiamo la funzione di normalizzazione
1760471821293:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760471821322:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760471821356:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760471821361:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760471821401:#Salvo il file risultante
1760471821402:fwrite(combined)
1760471821417:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760471821418:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760471821419:#(tabella cluster × cell_type con conti).
1760471821420:# 1. Assicuriamoci di usare la tabella combinata
1760471821421:start_point <- copy(combined)
1760471821423:# 2. Conta per cluster x cell_type
1760471821424:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760471821427:setnames(counts_cluster_celltype, "N", "cell_count")
1760471821428:fwrite(counts_cluster_celltype)
1760471821432:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760471821433:#and also their association to normal and tumor tissue
1760471821434:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760471821436:#cell_count (numero di celle),
1760471821437:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760471821438:#(cioè cell_count / total_cells_in_cluster * 100),
1760471821439:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760471821441:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760471821443:# 1. Ripartiamo da combined
1760471821444:start_point <- copy(combined)
1760471821447:# 2. Conta righe per (cluster, cell_type, sample_type)
1760471821449:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760471821452:setnames(tab_ct_st, "N", "cell_count")
1760471821454:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760471821455:totals_cluster <- start_point[, .N, by = integration_cluster]
1760471821458:setnames(totals_cluster, "N", "cluster_total_cells")
1760471821460:# 4. Unisci il totale per cluster
1760471821461:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760471821466:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760471821467:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760471821471:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760471821472:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760471821474:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760471821477:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760471821479:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760471821481:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760471821485:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760471821488:# 8. Riordino colonne per chiarezza e salvo
1760471821489:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760471821490:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760471821491:"cluster_total_cells", "pct_within_cluster"))
1760471821493:out3 <- paste0("_summary_cluster_celltype_sampletype.csv")
1760471821494:fwrite(tab_ct_st, out3)
1760471821497:#TASK4.1
1760471821498:#Provide a plot describing the distribution of the cell type in normal/tumor tissue
1760471821499:#given the integration clusters.
1760471821500:# Usiamo il file che hai già creato nel Task 1
1760471821501:# (quello con le colonne: cell_type, integration_cluster, sample_type)
1760471821502:data <- combined
1760471821503:# Contiamo quante celle ci sono per combinazione di cluster, tipo di cellula e tipo di tessuto
1760471821504:counts <- as.data.frame(table(data$integration_cluster, data$cell_type, data$sample_type))
1760471821509:names(counts) <- c("cluster", "cell_type", "tissue", "count")
1760471821510:# Calcoliamo la percentuale di ogni cell_type dentro ciascun cluster e tessuto
1760471821511:# Per farlo, prima troviamo il totale per cluster e tessuto
1760471821512:totals <- aggregate(count ~ cluster + tissue, data = counts, sum)
1760471821523:names(totals)[3] <- "total"
1760471821524:# Ora uniamo le due tabelle
1760471821525:counts2 <- merge(counts, totals, by = c("cluster", "tissue"))
1760471821535:# Calcoliamo la percentuale
1760471821536:counts2$percent <- (counts2$count / counts2$total) * 100
1760471821538:# Facciamo il grafico
1760471821538:ggplot(counts2, aes(x = cluster, y = percent, fill = cell_type)) +
1760471821539:geom_bar(stat = "identity") +
1760471821540:facet_wrap(~ tissue) +
1760471821541:labs(title = "Distribuzione dei tipi cellulari nei cluster",
1760471821541:x = "Integration cluster",
1760471821542:y = "Percentuale di celle (%)") +
1760471821543:theme_minimal() +
1760471821544:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1760625383013:# =====================================================
1760625383018:# Goal: Nearest-time matching of vitals to lab draws. Data: clinical_labs.csv, vitals_time_series.csv Tasks:
1760625383022:#• For each lab measurement, attach the nearest HR and SBP reading using a rolling join on (patient_id, time) and report the time lag in minutes.
1760625383025:#• Summarize correlation between CRP and nearest HR/SBP by patient.
1760625383030:#TASK 6: Nearest-time matching of vitals to lab draws
1760625383032:# =====================================================
1760625383033:library(data.table)
1760625383039:# 1. Carico i dati
1760625383041:labs <- fread("project_oct25/clinical_labs.csv")
1760625383054:vitals <- fread("project_oct25/vitals_time_series.csv")
1760625383058:# 2. Preparo le tabelle
1760625383059:labs[, time_iso := as.POSIXct(time_iso)]
1760625383076:vitals[, time_iso := as.POSIXct(time_iso)]
1760625383080:setorder(labs, patient_id, time_iso)
1760625383084:setorder(vitals, patient_id, time_iso)
1760625383088:# Salvo il tempo del lab in una nuova colonna PRIMA del join
1760625383089:labs[, lab_time := time_iso]
1760625383092:setkey(labs, patient_id, time_iso)
1760625383107:setkey(vitals, patient_id, time_iso)
1760625383109:# 3. Trovo l'HR più vicino
1760625383110:vitals_hr <- vitals[vital == "HR", .(patient_id, time_iso, value)]
1760625383120:setnames(vitals_hr, "value", "nearest_HR")
1760625383122:# SALVO IL TEMPO DELL'HR PRIMA DEL JOIN!
1760625383123:vitals_hr[, hr_time := time_iso]
1760625383125:setkey(vitals_hr, patient_id, time_iso)
1760625383126:labs_with_hr <- vitals_hr[labs, roll = "nearest"]
1760625383129:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1760625383132:# 4. Trovo l'SBP più vicino
1760625383133:vitals_sbp <- vitals[vital == "SBP", .(patient_id, time_iso, value)]
1760625383137:setnames(vitals_sbp, "value", "nearest_SBP")
1760625383138:# SALVO IL TEMPO DELL'SBP PRIMA DEL JOIN!
1760625383139:vitals_sbp[, sbp_time := time_iso]
1760625383140:setkey(vitals_sbp, patient_id, time_iso)
1760625383142:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1760625383157:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1760625383160:# 5. Mostro i risultati
1760625383161:cat("\n--- Primi risultati: lab con vitals più vicini ---\n")
1760625383162:print(head(labs_with_vitals[, .(patient_id, lab, lab_time, nearest_HR, hr_time, hr_lag_minutes, nearest_SBP, sbp_time, sbp_lag_minutes)], 20))
1760625383177:# 6. Analisi CRP
1760625383178:crp_data <- labs_with_vitals[lab == "CRP"]
1760625383182:cor_crp_hr <- crp_data[!is.na(nearest_HR), .(
1760625383183:correlation_CRP_HR = cor(value, nearest_HR, use = "complete.obs")
1760625383184:), by = patient_id]
1760625383193:cor_crp_sbp <- crp_data[!is.na(nearest_SBP), .(
1760625383194:correlation_CRP_SBP = cor(value, nearest_SBP, use = "complete.obs")
1760625383194:), by = patient_id]
1760625383198:cat("\n--- Correlazione CRP-HR per paziente ---\n")
1760625383199:print(cor_crp_hr)
1760625383202:cat("\n--- Correlazione CRP-SBP per paziente ---\n")
1760625383203:print(cor_crp_sbp)
1760625394162:View(cor_crp_sbp)
1760625394933:View(cor_crp_hr)
1760636576063:library(data.table)
1760636576482:# 1. Import
1760636576485:counts <- fread("project_oct25/bulk_counts_long.csv")
1760636576941:meta   <- fread("project_oct25/sample_metadata.csv")
1760636577364:# 2. Join counts + metadata by sample_id
1760636577369:setkey(counts, sample_id)
1760636577576:setkey(meta, sample_id)
1760636577762:merged_data <- counts[meta, nomatch = 0]
1760636577995:# 3. Filter for treated samples and GENE_00* genes
1760636577999:treated_data <- merged_data[condition == "treated" & grepl("^GENE_00", gene)]
1760636578201:# 4. Compute mean and median per gene
1760636578204:gene_summary <- treated_data[, .(
1760636578206:mean_count   = mean(count),
1760636578208:median_count = median(count)
1760636578209:), by = gene]
1760636578431:# 5. Pipeline version: join + filter + summarise in one line
1760636578434:gene_mean_pipeline <- counts[meta, on = "sample_id"][
1760636578435:condition == "treated" & grepl("^GENE_00", gene),
1760636578437:.(mean_count = mean(count)),
1760636578438:by = gene
1760636578439:]
1760636579441:# 6. Output (prime 5 righe)
1760636579445:cat("\n--- Media e mediana dei conteggi (solo treated, GENE_00*) ---\n")
1760636580070:print(head(gene_summary, 5))
1760636580891:cat("\n--- Media dei conteggi per gene (pipeline unica) ---\n")
1760636581572:print(head(gene_mean_pipeline, 5))
1760636614123:# 1. Import
1760636614126:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760636615261:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760636615462:# 2. Join counts + metadata by sample_id
1760636615465:merged_data <- merge(counts, meta, by = "sample_id")
1760636615687:# 3. Filter for treated samples and GENE_00* genes
1760636615689:treated_data <- subset(merged_data,
1760636615692:condition == "treated" & grepl("^GENE_00", gene))
1760636615874:# 4. Compute mean and median per gene
1760636615877:gene_summary <- aggregate(
1760636615879:count ~ gene,
1760636615880:data = treated_data,
1760636615882:FUN  = function(x) c(mean = mean(x), median = median(x))
1760636615884:)
1760636616072:# 5. Simplify format
1760636616075:gene_summary_df <- data.frame(
1760636616076:gene = gene_summary$gene,
1760636616077:mean_count   = gene_summary$count[, "mean"],
1760636616080:median_count = gene_summary$count[, "median"]
1760636616083:)
1760636616264:# 6. Pipeline version: merge + filter + summarise in one expression
1760636616268:gene_mean_pipeline <- aggregate(
1760636616270:count ~ gene,
1760636616272:data = subset(
1760636616273:merge(counts, meta, by = "sample_id", all.x = TRUE),
1760636616274:condition == "treated" & grepl("^GENE_00", gene)
1760636616276:),
1760636616277:FUN = mean
1760636616278:)
1760636616750:# 7. Output
1760636616752:cat("\n--- Media e mediana dei conteggi (solo treated, GENE_00*) ---\n")
1760636617242:print(head(gene_summary_df, 5))
1760636618895:cat("\n--- Media dei conteggi per gene (pipeline unica) ---\n")
1760636619583:print(head(gene_mean_pipeline, 5))
1760636700080:# ==========================================================
1760636700082:# TASK 2 – data.table version
1760636700085:# Goal:
1760636700086:# - Add a log2(count) column
1760636700089:# - Add a binary 'high' flag (count > 100)
1760636700090:# - Overwrite 'high' to be gene-wise (count > median(count), by=gene)
1760636700090:# ==========================================================
1760636700092:library(data.table)
1760636700094:# 1. Import
1760636700095:counts <- fread("project_oct25/bulk_counts_long.csv")
1760636700101:# 2. Add log2(count + 1) column (avoid log2(0))
1760636700102:counts[, log2_count := log2(count + 1)]
1760636700107:# 3. Add binary flag 'high' (count > 100)
1760636700108:counts[, high := count > 100]
1760636700111:# 4. Overwrite 'high' using a gene-wise threshold
1760636700111:#    For each gene, mark TRUE if count > median(count)
1760636700112:counts[, high := count > median(count), by = gene]
1760636700144:# 5. Display first rows
1760636700146:cat("\n--- Prime righe dopo le modifiche (data.table) ---\n")
1760636700149:print(head(counts, 5))
1760636723359:# ==========================================================
1760636723362:# TASK 2 – data.frame version
1760636723367:# Stesso obiettivo ma con funzioni base R
1760636723368:# ==========================================================
1760636723372:# 1. Import
1760636723373:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760636723389:# 2. Add log2(count + 1) column
1760636723390:counts$log2_count <- log2(counts$count + 1)
1760636723393:# 3. Add binary flag 'high' (count > 100)
1760636723395:counts$high <- counts$count > 100
1760636723398:# 4. Overwrite 'high' using gene-wise median threshold
1760636723399:#    Qui usiamo tapply() per calcolare la mediana per gene,
1760636723400:#    poi combiniamo i risultati in un vettore logico della stessa lunghezza
1760636723401:medians_by_gene <- tapply(counts$count, counts$gene, median)
1760636723440:counts$high <- counts$count > medians_by_gene[counts$gene]
1760636723449:# 5. Display first rows
1760636723450:cat("\n--- Prime righe dopo le modifiche (data.frame) ---\n")
1760636723451:print(head(counts, 5))
1760636860908:# ==========================================================
1760636860911:# TASK 3 – data.table version
1760636860912:# Goal:
1760636860915:# - Speed up joins and lookups using keys and indexes
1760636860918:# - Compare query times before and after indexing
1760636860919:# ==========================================================
1760636860921:library(data.table)
1760636860923:# 1. Import
1760636860925:counts <- fread("project_oct25/bulk_counts_long.csv")
1760636860933:meta   <- fread("project_oct25/sample_metadata.csv")
1760636860937:# 2. Set key on sample_metadata for fast join
1760636860938:setkey(meta, sample_id)
1760636860954:# 3. Join metadata and counts (equi-join)
1760636860955:joined_data <- meta[counts, on = "sample_id"]
1760636860966:# 4. Add secondary index on (gene, sample_id)
1760636860967:setindex(counts, gene, sample_id)
1760636860971:# 5. Benchmark: query before and after index
1760636860972:gene_name     <- "GENE_0051"
1760636860973:sample_chosen <- "S20"
1760636860975:# (a) Before using index
1760636860985:system.time({
1760636860992:subset_no_index <- counts[gene == gene_name & sample_id == sample_chosen]
1760636860998:})
1760636861256:# (b) After index creation (index used automatically)
1760636861257:system.time({
1760636861258:subset_with_index <- counts[gene == gene_name & sample_id == sample_chosen]
1760636861259:})
1760636861485:# 6. Optional: verify they are identical
1760636861486:stopifnot(identical(subset_no_index, subset_with_index))
1760636861488:cat("\n--- Join e lookup completati (data.table) ---\n")
1760636861489:print(head(joined_data, 5))
1760636886291:# ==========================================================
1760636886295:# TASK 3 – data.frame version
1760636886297:# Stesso obiettivo ma con funzioni base R
1760636886298:# ==========================================================
1760636886300:# 1. Import
1760636886301:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760636886317:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760636886320:# 2. Join metadata and counts
1760636886321:joined_data <- merge(counts, meta, by = "sample_id")
1760636886365:# 3. Query performance test without indexes
1760636886366:gene_name     <- "GENE_0051"
1760636886367:sample_chosen <- "S20"
1760636886369:system.time({
1760636886369:subset_no_index <- subset(counts, gene == gene_name & sample_id == sample_chosen)
1760636886370:})
1760636886580:# In base R non esiste un vero indice persistente sulle colonne.
1760636886581:# Possiamo solo simulare una "cache" creando un vettore logico o usando subset ripetutamente.
1760636886582:# Il tempo resterà pressoché uguale.
1760636886583:system.time({
1760636886584:subset_with_index <- subset(counts, gene == gene_name & sample_id == sample_chosen)
1760636886585:})
1760636886823:# 4. Verify equality
1760636886824:stopifnot(identical(subset_no_index, subset_with_index))
1760636886826:cat("\n--- Join e lookup completati (data.frame) ---\n")
1760636886828:print(head(joined_data, 5))
1760638238510:# ==========================================================
1760638238514:# TASK 4 – data.table version
1760638238516:# ==========================================================
1760638238520:library(data.table)
1760638238524:# 1. Import
1760638238525:counts <- fread("project_oct25/bulk_counts_long.csv")
1760638238530:meta   <- fread("project_oct25/sample_metadata.csv")
1760638238533:# 2. Join counts + metadata
1760638238534:setkey(counts, sample_id)
1760638238537:setkey(meta, sample_id)
1760638238538:merged_data <- counts[meta, nomatch = 0]
1760638238542:# 3. Total counts per patient
1760638238543:patient_totals <- merged_data[, .(total_count = sum(count)), by = patient_id]
1760638238546:# 4. Mean count per gene and condition
1760638238547:gene_means <- merged_data[, .(mean_count = mean(count)), by = .(gene, condition)]
1760638238550:# 5. Top 10 genes (highest mean) within each condition
1760638238551:top10_by_condition <- gene_means[
1760638238551:order(condition, -mean_count)
1760638238552:][, head(.SD, 10), by = condition]
1760638238555:# 6. Output
1760638238556:cat("\n--- Totale conteggi per paziente ---\n")
1760638238557:print(head(patient_totals, 5))
1760638238559:cat("\n--- Top 10 geni per condizione ---\n")
1760638238560:print(top10_by_condition)
1760638267989:# ==========================================================
1760638267994:# TASK 4 – data.frame version
1760638267997:# ==========================================================
1760638267999:# 1. Import
1760638267999:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760638268018:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760638268021:# 2. Join
1760638268022:merged_data <- merge(counts, meta, by = "sample_id")
1760638268067:# 3. Total counts per patient
1760638268067:patient_totals <- aggregate(count ~ patient_id, data = merged_data, FUN = sum)
1760638268077:names(patient_totals)[2] <- "total_count"
1760638268081:# 4. Mean count per gene and condition
1760638268082:gene_means <- aggregate(count ~ gene + condition, data = merged_data, FUN = mean)
1760638268116:names(gene_means)[3] <- "mean_count"
1760638268123:# 5. Top 10 genes by condition
1760638268124:conditions <- unique(gene_means$condition)
1760638268125:top10_by_condition <- data.frame()
1760638268127:for (cond in conditions) {
1760638268127:subset_cond <- subset(gene_means, condition == cond)
1760638268128:subset_cond <- subset_cond[order(-subset_cond$mean_count), ]
1760638268129:top10 <- head(subset_cond, 10)
1760638268130:top10_by_condition <- rbind(top10_by_condition, top10)
1760638268130:}
1760638268144:# 6. Output
1760638268147:cat("\n--- Totale conteggi per paziente ---\n")
1760638268149:print(head(patient_totals, 5))
1760638268152:cat("\n--- Top 10 geni per condizione ---\n")
1760638268153:print(top10_by_condition)
1760638316805:# ==========================================================
1760638316814:# TASK 5 – data.table version
1760638316818:# ==========================================================
1760638316823:library(data.table)
1760638316826:# 1. Import
1760638316827:labs <- fread("project_oct25/clinical_labs.csv")
1760638316830:ref  <- fread("project_oct25/lab_reference_ranges.csv")
1760638316834:# 2. Keep unique reference intervals
1760638316834:ref_unique <- unique(ref[, .(lab, lower, upper)])
1760638316840:# 3. Join to add lower/upper limits
1760638316841:setkey(labs, lab)
1760638316842:setkey(ref_unique, lab)
1760638316843:merged_labs <- labs[ref_unique, nomatch = 0]
1760638316846:# 4. Classify each lab value
1760638316847:merged_labs[, status := fifelse(value >= lower & value <= upper,
1760638316848:"normal", "out_of_range")]
1760638316850:# 5. Summaries
1760638316851:abnormal_by_patient <- merged_labs[, .(
1760638316852:total_tests  = .N,
1760638316852:out_of_range = sum(status == "out_of_range")
1760638316853:), by = patient_id]
1760638316856:abnormal_by_lab <- merged_labs[, .(
1760638316857:total_tests  = .N,
1760638316857:out_of_range = sum(status == "out_of_range")
1760638316858:), by = lab]
1760638316861:# 6. Output
1760638316862:cat("\n--- Test fuori range per paziente ---\n")
1760638316862:print(abnormal_by_patient)
1760638316866:cat("\n--- Test fuori range per tipo di test ---\n")
1760638316866:print(abnormal_by_lab)
1760638329879:# ==========================================================
1760638329883:# TASK 5 – data.frame version
1760638329888:# ==========================================================
1760638329895:# 1. Import
1760638329896:labs <- read.csv("project_oct25/clinical_labs.csv", stringsAsFactors = FALSE)
1760638329900:ref  <- read.csv("project_oct25/lab_reference_ranges.csv", stringsAsFactors = FALSE)
1760638329905:# 2. Keep unique reference intervals
1760638329906:ref_unique <- unique(ref[, c("lab", "lower", "upper")])
1760638329909:# 3. Join
1760638329909:merged_labs <- merge(labs, ref_unique, by = "lab")
1760638329914:# 4. Classify as normal/out_of_range
1760638329914:merged_labs$status <- ifelse(merged_labs$value >= merged_labs$lower &
1760638329915:merged_labs$value <= merged_labs$upper,
1760638329916:"normal", "out_of_range")
1760638329917:# 5. Summaries
1760638329918:abnormal_by_patient <- aggregate(status ~ patient_id, data = merged_labs,
1760638329919:FUN = function(x) {
1760638329920:total <- length(x)
1760638329921:out   <- sum(x == "out_of_range")
1760638329921:c(total_tests = total, out_of_range = out)
1760638329922:})
1760638329929:# split matrix-like column into two numeric columns
1760638329930:abnormal_by_patient$total_tests  <- abnormal_by_patient$status[, "total_tests"]
1760638329931:abnormal_by_patient$out_of_range <- abnormal_by_patient$status[, "out_of_range"]
1760638329931:abnormal_by_patient$status <- NULL
1760638329932:abnormal_by_lab <- aggregate(status ~ lab, data = merged_labs,
1760638329933:FUN = function(x) {
1760638329934:total <- length(x)
1760638329935:out   <- sum(x == "out_of_range")
1760638329935:c(total_tests = total, out_of_range = out)
1760638329936:})
1760638329943:abnormal_by_lab$total_tests  <- abnormal_by_lab$status[, "total_tests"]
1760638329944:abnormal_by_lab$out_of_range <- abnormal_by_lab$status[, "out_of_range"]
1760638329945:abnormal_by_lab$status <- NULL
1760638329946:# 6. Output
1760638329947:cat("\n--- Test fuori range per paziente ---\n")
1760638329947:print(abnormal_by_patient)
1760638329951:cat("\n--- Test fuori range per tipo di test ---\n")
1760638329951:print(abnormal_by_lab)
1760638619568:# ==========================================================
1760638619571:# TASK 6 – data.table version
1760638619575:# ==========================================================
1760638619577:library(data.table)
1760638619582:# 1. Import
1760638619584:labs   <- fread("project_oct25/clinical_labs.csv")
1760638619587:vitals <- fread("project_oct25/vitals_time_series.csv")
1760638619591:# 2. Convert to POSIXct
1760638619592:labs[, time_iso := as.POSIXct(time_iso)]
1760638619594:vitals[, time_iso := as.POSIXct(time_iso)]
1760638619597:setorder(labs, patient_id, time_iso)
1760638619600:setorder(vitals, patient_id, time_iso)
1760638619602:labs[, lab_time := time_iso]
1760638619604:setkey(labs, patient_id, time_iso)
1760638619605:setkey(vitals, patient_id, time_iso)
1760638619607:# 3. Nearest HR
1760638619608:vitals_hr <- vitals[vital == "HR", .(patient_id, time_iso, value)]
1760638619612:setnames(vitals_hr, "value", "nearest_HR")
1760638619614:vitals_hr[, hr_time := time_iso]
1760638619615:setkey(vitals_hr, patient_id, time_iso)
1760638619617:labs_with_hr <- vitals_hr[labs, roll = "nearest"]
1760638619619:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1760638619622:# 4. Nearest SBP
1760638619623:vitals_sbp <- vitals[vital == "SBP", .(patient_id, time_iso, value)]
1760638619627:setnames(vitals_sbp, "value", "nearest_SBP")
1760638619628:vitals_sbp[, sbp_time := time_iso]
1760638619629:setkey(vitals_sbp, patient_id, time_iso)
1760638619630:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1760638619633:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1760638619636:# 5. Correlation CRP vs vitals
1760638619636:crp_data <- labs_with_vitals[lab == "CRP"]
1760638619640:cor_crp_hr <- crp_data[!is.na(nearest_HR),
1760638619641:.(correlation_CRP_HR = cor(value, nearest_HR, use = "complete.obs")),
1760638619641:by = patient_id
1760638619642:]
1760638619646:cor_crp_sbp <- crp_data[!is.na(nearest_SBP),
1760638619647:.(correlation_CRP_SBP = cor(value, nearest_SBP, use = "complete.obs")),
1760638619648:by = patient_id
1760638619649:]
1760638619653:cat("\n--- Correlazione CRP-HR per paziente ---\n")
1760638619653:print(cor_crp_hr)
1760638619656:cat("\n--- Correlazione CRP-SBP per paziente ---\n")
1760638619657:print(cor_crp_sbp)
1760638634407:# ==========================================================
1760638634421:# TASK 6 – data.frame version
1760638634425:# ==========================================================
1760638634428:# 1. Import
1760638634430:labs   <- read.csv("project_oct25/clinical_labs.csv", stringsAsFactors = FALSE)
1760638634434:vitals <- read.csv("project_oct25/vitals_time_series.csv", stringsAsFactors = FALSE)
1760638634441:# 2. Convert to POSIXct
1760638634443:labs$time_iso   <- as.POSIXct(labs$time_iso)
1760638634447:vitals$time_iso <- as.POSIXct(vitals$time_iso)
1760638634454:# 3. Join nearest HR/SBP manually (loop-based)
1760638634455:nearest_match <- function(lab_df, vitals_df, vital_type) {
1760638634456:vitals_sub <- vitals_df[vitals_df$vital == vital_type, ]
1760638634458:results <- list()
1760638634459:for (i in seq_len(nrow(lab_df))) {
1760638634460:pid <- lab_df$patient_id[i]
1760638634461:time <- lab_df$time_iso[i]
1760638634462:v_sub <- vitals_sub[vitals_sub$patient_id == pid, ]
1760638634463:if (nrow(v_sub) > 0) {
1760638634464:idx <- which.min(abs(difftime(v_sub$time_iso, time, units = "mins")))
1760638634465:results[[i]] <- v_sub[idx, c("value", "time_iso")]
1760638634466:} else {
1760638634467:results[[i]] <- data.frame(value = NA, time_iso = NA)
1760638634468:}
1760638634469:}
1760638634476:out <- do.call(rbind, results)
1760638634478:names(out) <- c(paste0("nearest_", vital_type), paste0(vital_type, "_time"))
1760638634479:return(out)
1760638634480:}
1760638634483:# 4. Attach nearest HR and SBP
1760638634485:hr_data  <- nearest_match(labs, vitals, "HR")
1760638634726:sbp_data <- nearest_match(labs, vitals, "SBP")
1760638634868:labs_with_vitals <- cbind(labs, hr_data, sbp_data)
1760638634869:labs_with_vitals$hr_lag_minutes  <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$HR_time, units = "mins"))
1760638634870:labs_with_vitals$sbp_lag_minutes <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$SBP_time, units = "mins"))
1760638634871:# 5. Correlation per patient (CRP only)
1760638634872:crp_data <- subset(labs_with_vitals, lab == "CRP")
1760638634873:cor_crp_hr  <- aggregate(cbind(value, nearest_HR) ~ patient_id, data = crp_data,
1760638634874:FUN = function(x) cor(x[, 1], x[, 2], use = "complete.obs"))
1760638691403:# ==========================================================
1760638691408:# TASK 7 – data.frame version
1760638691410:# ==========================================================
1760638691413:peaks <- read.csv("project_oct25/atac_peaks.bed.csv", stringsAsFactors = FALSE)
1760638691444:subset_peaks <- subset(peaks, chr == "chr2" & start >= 2000000 & start <= 4000000)
1760638691446:subset_peaks <- subset_peaks[order(-subset_peaks$score), ]
1760638691448:top50_peaks <- head(subset_peaks, 50)
1760638691450:cat("\n--- Top 50 picchi su chr2 (2–4 Mb) ---\n")
1760638691451:print(top50_peaks)
1760638695700:# ==========================================================
1760638695702:# TASK 7 – data.table version
1760638695704:# ==========================================================
1760638695708:library(data.table)
1760638695710:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1760638695718:subset_peaks <- peaks[chr == "chr2" & start >= 2e6 & start <= 4e6]
1760638695719:setorder(subset_peaks, -score)
1760638695721:top50_peaks <- head(subset_peaks, 50)
1760638695723:cat("\n--- Top 50 picchi su chr2 (2–4 Mb) ---\n")
1760638695725:print(top50_peaks)
1760638712656:# ==========================================================
1760638712667:# TASK 6 – data.frame version
1760638712670:# ==========================================================
1760638712672:# 1. Import
1760638712673:labs   <- read.csv("project_oct25/clinical_labs.csv", stringsAsFactors = FALSE)
1760638712677:vitals <- read.csv("project_oct25/vitals_time_series.csv", stringsAsFactors = FALSE)
1760638712683:# 2. Convert to POSIXct
1760638712684:labs$time_iso   <- as.POSIXct(labs$time_iso)
1760638712686:vitals$time_iso <- as.POSIXct(vitals$time_iso)
1760638712690:# 3. Join nearest HR/SBP manually (loop-based)
1760638712691:nearest_match <- function(lab_df, vitals_df, vital_type) {
1760638712692:vitals_sub <- vitals_df[vitals_df$vital == vital_type, ]
1760638712693:results <- list()
1760638712694:for (i in seq_len(nrow(lab_df))) {
1760638712694:pid <- lab_df$patient_id[i]
1760638712695:time <- lab_df$time_iso[i]
1760638712696:v_sub <- vitals_sub[vitals_sub$patient_id == pid, ]
1760638712696:if (nrow(v_sub) > 0) {
1760638712697:idx <- which.min(abs(difftime(v_sub$time_iso, time, units = "mins")))
1760638712698:results[[i]] <- v_sub[idx, c("value", "time_iso")]
1760638712699:} else {
1760638712699:results[[i]] <- data.frame(value = NA, time_iso = NA)
1760638712700:}
1760638712701:}
1760638712702:out <- do.call(rbind, results)
1760638712703:names(out) <- c(paste0("nearest_", vital_type), paste0(vital_type, "_time"))
1760638712704:return(out)
1760638712704:}
1760638712706:# 4. Attach nearest HR and SBP
1760638712706:hr_data  <- nearest_match(labs, vitals, "HR")
1760638712902:sbp_data <- nearest_match(labs, vitals, "SBP")
1760638713039:labs_with_vitals <- cbind(labs, hr_data, sbp_data)
1760638713040:labs_with_vitals$hr_lag_minutes  <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$HR_time, units = "mins"))
1760638713041:labs_with_vitals$sbp_lag_minutes <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$SBP_time, units = "mins"))
1760638713042:# 5. Correlation per patient (CRP only)
1760638713042:crp_data <- subset(labs_with_vitals, lab == "CRP")
1760638713044:cor_crp_hr  <- aggregate(cbind(value, nearest_HR) ~ patient_id, data = crp_data,
1760638713045:FUN = function(x) cor(x[, 1], x[, 2], use = "complete.obs"))
1760638729365:# ==========================================================
1760638729370:# TASK 8 – data.table version
1760638729373:# ==========================================================
1760638729378:library(data.table)
1760638729379:counts <- fread("project_oct25/bulk_counts_long.csv")
1760638729385:meta   <- fread("project_oct25/sample_metadata.csv")
1760638729387:merged <- counts[meta, on = "sample_id"]
1760638729394:stats_by_gene_condition <- merged[, .(
1760638729395:mean_count   = mean(count),
1760638729396:median_count = median(count),
1760638729397:Q1           = quantile(count, 0.25, type = 2),
1760638729398:Q3           = quantile(count, 0.75, type = 2)
1760638729399:), by = .(gene, condition)]
1760638729892:treated_means <- stats_by_gene_condition[condition == "treated", .(gene, treated_mean = mean_count)]
1760638729896:control_means <- stats_by_gene_condition[condition == "control", .(gene, control_mean = mean_count)]
1760638729900:means_wide <- merge(treated_means, control_means, by = "gene", all = FALSE)
1760638729904:kept_genes <- means_wide[treated_mean >= 2 * control_mean]
1760638740315:# ==========================================================
1760638740319:# TASK 8 – data.frame version
1760638740323:# ==========================================================
1760638740329:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760638740346:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760638740351:merged <- merge(counts, meta, by = "sample_id")
1760638740397:stats_by_gene_condition <- aggregate(count ~ gene + condition, data = merged,
1760638740398:FUN = function(x) c(mean = mean(x), median = median(x),
1760638740399:Q1 = quantile(x, 0.25, type = 2),
1760638740400:Q3 = quantile(x, 0.75, type = 2)))
1760638740889:stats_df <- data.frame(
1760638740890:gene = stats_by_gene_condition$gene,
1760638740890:condition = stats_by_gene_condition$condition,
1760638740891:mean_count = stats_by_gene_condition$count[, "mean"],
1760638740891:median_count = stats_by_gene_condition$count[, "median"],
1760638740892:Q1 = stats_by_gene_condition$count[, "Q1"],
1760638740892:Q3 = stats_by_gene_condition$count[, "Q3"]
1760638740893:)
1760638765144:# ==========================================================
1760638765147:# TASK 9 – data.frame version
1760638765149:# ==========================================================
1760638765151:counts_wide <- read.csv("project_oct25/bulk_counts_wide.csv", stringsAsFactors = FALSE)
1760638765176:counts_long <- reshape(counts_wide, varying = names(counts_wide)[-1],
1760638765177:v.names = "count", timevar = "sample_id",
1760638765179:times = names(counts_wide)[-1], idvar = "gene",
1760638765181:direction = "long")
1760638765298:meta <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760638765300:merged <- merge(counts_long, meta, by = "sample_id")
1760638765337:totals_per_sample <- aggregate(count ~ sample_id, data = merged, sum)
1760638765348:names(totals_per_sample)[2] <- "total_count"
1760638765350:merged <- merge(merged, totals_per_sample, by = "sample_id")
1760638765386:gene_condition_means <- aggregate(count ~ gene + condition, data = merged, mean)
1760638765417:counts_condition_wide <- reshape(gene_condition_means,
1760638765418:timevar = "condition", idvar = "gene",
1760638765419:direction = "wide")
1760638765426:cat("\n--- Tabella finale: media dei conteggi per gene e condizione ---\n")
1760638765428:print(head(counts_condition_wide, 10))
1760638778479:# ==========================================================
1760638778487:# TASK 9 – data.table version
1760638778489:# ==========================================================
1760638778495:library(data.table)
1760638778496:counts_wide <- fread("project_oct25/bulk_counts_wide.csv")
1760638778503:counts_long <- melt(counts_wide, id.vars = "gene",
1760638778504:variable.name = "sample_id", value.name = "count")
1760638778508:meta <- fread("project_oct25/sample_metadata.csv")
1760638778510:merged <- merge(counts_long, meta, by = "sample_id")
1760638778524:totals_per_sample <- merged[, .(total_count = sum(count)), by = sample_id]
1760638778526:merged <- merge(merged, totals_per_sample, by = "sample_id")
1760638778533:gene_condition_means <- merged[, .(mean_count = mean(count)), by = .(gene, condition)]
1760638778536:counts_condition_wide <- dcast(gene_condition_means, gene ~ condition, value.var = "mean_count")
1760638778544:cat("\n--- Tabella finale: media dei conteggi per gene e condizione ---\n")
1760638778545:print(head(counts_condition_wide, 10))
1760638796474:# ==========================================================
1760638796478:# TASK 8 – data.frame version
1760638796480:# ==========================================================
1760638796485:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760638796501:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760638796503:merged <- merge(counts, meta, by = "sample_id")
1760638796539:stats_by_gene_condition <- aggregate(count ~ gene + condition, data = merged,
1760638796540:FUN = function(x) c(mean = mean(x), median = median(x),
1760638796541:Q1 = quantile(x, 0.25, type = 2),
1760638796542:Q3 = quantile(x, 0.75, type = 2)))
1760638797025:stats_df <- data.frame(
1760638797026:gene = stats_by_gene_condition$gene,
1760638797028:condition = stats_by_gene_condition$condition,
1760638797030:mean_count = stats_by_gene_condition$count[, "mean"],
1760638797031:median_count = stats_by_gene_condition$count[, "median"],
1760638797032:Q1 = stats_by_gene_condition$count[, "Q1"],
1760638797034:Q3 = stats_by_gene_condition$count[, "Q3"]
1760638797036:)
1760639077814:library(data.table)
1760639077819:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1760639077829:genes <- fread("project_oct25/gene_annotation.bed.csv")
1760639077839:setkey(peaks, chr, start, end)
1760639077844:setkey(genes, chr, start, end)
1760639077849:overlaps <- foverlaps(peaks, genes,
1760639077850:by.x = c("chr", "start", "end"),
1760639077852:by.y = c("chr", "start", "end"),
1760639077853:type = "any", nomatch = 0L)
1760639077876:overlaps[, overlap_bp := pmin(end, i.end) - pmax(start, i.start)]
1760639077880:overlaps <- overlaps[overlap_bp > 0]
1760639077883:peaks_per_gene <- overlaps[, .N, by = gene]
1760639077887:setnames(peaks_per_gene, "N", "num_peaks")
1760639077891:overlap_sum_per_gene <- overlaps[, .(total_overlap_bp = sum(overlap_bp)), by = gene]
1760639077894:top20_genes <- overlap_sum_per_gene[order(-total_overlap_bp)][1:20]
1760639099204:peaks <- read.csv("project_oct25/atac_peaks.bed.csv", stringsAsFactors = FALSE)
1760639099239:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760639099250:# overlap calcolato “a mano”
1760639099252:overlaps_list <- lapply(1:nrow(peaks), function(i) {
1760639099254:p <- peaks[i, ]
1760639099255:gsub <- subset(genes, chr == p$chr & start <= p$end & end >= p$start)
1760639099257:if (nrow(gsub) == 0) return(NULL)
1760639099257:gsub$overlap_bp <- pmin(p$end, gsub$end) - pmax(p$start, gsub$start)
1760639099258:gsub <- gsub[gsub$overlap_bp > 0, ]
1760639099259:gsub$peak_id <- i
1760639099260:gsub
1760639099261:})
1760639100980:overlaps <- do.call(rbind, overlaps_list)
1760639101282:peaks_per_gene <- aggregate(overlap_bp ~ gene, data = overlaps, FUN = length)
1760639101289:names(peaks_per_gene)[2] <- "num_peaks"
1760639101291:overlap_sum_per_gene <- aggregate(overlap_bp ~ gene, data = overlaps, sum)
1760639101298:names(overlap_sum_per_gene)[2] <- "total_overlap_bp"
1760639101299:top20_genes <- head(overlap_sum_per_gene[order(-overlap_sum_per_gene$total_overlap_bp), ], 20)
1760639111083:peaks <- read.csv("project_oct25/atac_peaks.bed.csv", stringsAsFactors = FALSE)
1760639111110:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760639111117:# overlap calcolato “a mano”
1760639111118:overlaps_list <- lapply(1:nrow(peaks), function(i) {
1760639111119:p <- peaks[i, ]
1760639111121:gsub <- subset(genes, chr == p$chr & start <= p$end & end >= p$start)
1760639111122:if (nrow(gsub) == 0) return(NULL)
1760639111123:gsub$overlap_bp <- pmin(p$end, gsub$end) - pmax(p$start, gsub$start)
1760639111124:gsub <- gsub[gsub$overlap_bp > 0, ]
1760639111124:gsub$peak_id <- i
1760639111125:gsub
1760639111126:})
1760639112942:overlaps <- do.call(rbind, overlaps_list)
1760639113082:peaks_per_gene <- aggregate(overlap_bp ~ gene, data = overlaps, FUN = length)
1760639113089:names(peaks_per_gene)[2] <- "num_peaks"
1760639113091:overlap_sum_per_gene <- aggregate(overlap_bp ~ gene, data = overlaps, sum)
1760639113099:names(overlap_sum_per_gene)[2] <- "total_overlap_bp"
1760639113100:top20_genes <- head(overlap_sum_per_gene[order(-overlap_sum_per_gene$total_overlap_bp), ], 20)
1760639151396:library(data.table)
1760639151400:variants <- fread("project_oct25/variants.csv")
1760639151405:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760639151411:variants[, start := pos]
1760639151414:variants[, end := pos]
1760639151416:setkey(variants, chr, start, end)
1760639151418:setkey(genes, chr, start, end)
1760639151420:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1760639151431:overlaps[, impact_upper := toupper(impact)]
1760639151433:high_overlaps <- overlaps[impact_upper == "HIGH"]
1760639151438:high_counts_by_gene_sample <- high_overlaps[, .N, by = .(gene, sample_id)]
1760639151440:setnames(high_counts_by_gene_sample, "N", "high_variant_count")
1760639151442:high_counts_by_gene <- high_overlaps[, .N, by = gene][order(-N)]
1760639151445:setnames(high_counts_by_gene, "N", "total_high_variants")
1760639151447:genes_with_high <- unique(high_counts_by_gene$gene)
1760639179185:variants <- read.csv("project_oct25/variants.csv", stringsAsFactors = FALSE)
1760639179203:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760639179207:variants$start <- variants$pos
1760639179208:variants$end <- variants$pos
1760639179211:# Overlap manuale
1760639179214:overlaps_list <- lapply(1:nrow(variants), function(i) {
1760639179215:v <- variants[i, ]
1760639179215:gsub <- subset(genes, chr == v$chr & start <= v$end & end >= v$start)
1760639179216:if (nrow(gsub) == 0) return(NULL)
1760639179217:cbind(v, gsub)
1760639179218:})
1760639179947:overlaps <- do.call(rbind, overlaps_list)
1760639180089:overlaps$impact_upper <- toupper(overlaps$impact)
1760639180091:high_overlaps <- subset(overlaps, impact_upper == "HIGH")
1760639180094:high_counts_by_gene_sample <- aggregate(impact_upper ~ gene + sample_id,
1760639180094:data = high_overlaps, FUN = length)
1760639180100:names(high_counts_by_gene_sample)[3] <- "high_variant_count"
1760639180102:high_counts_by_gene <- aggregate(impact_upper ~ gene,
1760639180102:data = high_overlaps, FUN = length)
1760639180108:names(high_counts_by_gene)[2] <- "total_high_variants"
1760639180109:genes_with_high <- unique(high_counts_by_gene$gene)
1760639222258:cohortA <- read.csv("project_oct25/cohortA_samples.csv", stringsAsFactors = FALSE)
1760639222268:cohortB <- read.csv("project_oct25/cohortB_samples.csv", stringsAsFactors = FALSE)
1760639222272:counts  <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760639222293:cohortA$cohort <- "A"
1760639222295:cohortB$cohort <- "B"
1760639222297:combined_cohorts <- rbind(cohortA, cohortB)
1760639222299:combined_cohorts <- combined_cohorts[order(combined_cohorts$cohort,
1760639222301:combined_cohorts$condition,
1760639222303:combined_cohorts$sample_id), ]
1760639222306:merged <- merge(counts, combined_cohorts, by = "sample_id", all.x = TRUE)
1760639222391:gene_variance <- aggregate(count ~ gene, data = merged, FUN = var, na.rm = TRUE)
1760639222436:names(gene_variance)[2] <- "variance"
1760639222437:top100_genes <- head(gene_variance[order(-gene_variance$variance), "gene"], 100)
1760639222440:top100_data <- subset(merged, gene %in% top100_genes)
1760639222444:mean_counts <- aggregate(count ~ gene + cohort + condition,
1760639222445:data = top100_data, FUN = mean, na.rm = TRUE)
1760639222457:names(mean_counts)[4] <- "mean_count"
1760639232958:library(data.table)
1760639232961:cohortA <- fread("project_oct25/cohortA_samples.csv")
1760639232967:cohortB <- fread("project_oct25/cohortB_samples.csv")
1760639232969:counts  <- fread("project_oct25/bulk_counts_long.csv")
1760639232978:cohortA[, cohort := "A"]
1760639232982:cohortB[, cohort := "B"]
1760639232987:combined_cohorts <- rbindlist(list(cohortA, cohortB), use.names = TRUE, fill = TRUE)
1760639232989:setorder(combined_cohorts, cohort, condition, sample_id)
1760639232992:merged <- merge(counts, combined_cohorts, by = "sample_id", all.x = TRUE)
1760639232999:gene_variance <- merged[, .(variance = var(count, na.rm = TRUE)), by = gene]
1760639233003:top100_genes <- gene_variance[order(-variance)][1:100, gene]
1760639233006:top100_data <- merged[gene %in% top100_genes]
1760639233011:mean_counts <- top100_data[, .(mean_count = mean(count, na.rm = TRUE)),
1760639233013:by = .(gene, cohort, condition)]
1760639287107:library(data.table)
1760639287111:library(ggplot2)
1760639287116:integration_dt <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639287129:clustering_dt  <- fread("project_oct25/nt_combined_clustering.output.csv")
1760639287141:normalize_cell_id <- function(x) {
1760639287142:x <- as.character(x)
1760639287142:x <- trimws(x)
1760639287143:x <- gsub("_X_|_Y_", "_", x)
1760639287144:x <- gsub("_\\.", ".", x)
1760639287145:return(x)
1760639287145:}
1760639287147:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760639287176:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760639287207:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all = FALSE)
1760639287235:# Count by cluster × cell_type
1760639287238:counts_cluster_celltype <- combined[, .N, by = .(integration_cluster, cell_type)]
1760639287244:setnames(counts_cluster_celltype, "N", "cell_count")
1760639287248:# Summary with sample_type
1760639287249:tab_ct_st <- combined[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760639287252:setnames(tab_ct_st, "N", "cell_count")
1760639287253:totals_cluster <- combined[, .N, by = integration_cluster]
1760639287255:setnames(totals_cluster, "N", "cluster_total_cells")
1760639287256:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760639287261:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760639287264:totals_cluster_celltype <- combined[, .N, by = .(integration_cluster, cell_type)]
1760639287266:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760639287267:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639287268:by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760639287273:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760639301638:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639301660:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639301680:normalize_cell_id <- function(x) {
1760639301681:x <- trimws(as.character(x))
1760639301682:x <- gsub("_X_|_Y_", "_", x)
1760639301683:x <- gsub("_\\.", ".", x)
1760639301683:x
1760639301684:}
1760639301685:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639301708:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639301739:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639301806:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639301809:data = combined, FUN = length)
1760639301828:names(counts_cluster_celltype)[3] <- "cell_count"
1760639301837:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639301841:data = combined, FUN = length)
1760639301889:names(tab_ct_st)[4] <- "cell_count"
1760639301894:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639301906:names(totals_cluster)[2] <- "cluster_total_cells"
1760639301907:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639301910:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639301911:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639301912:data = combined, FUN = length)
1760639301924:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639301926:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639301927:by = c("integration_cluster", "cell_type"))
1760639301939:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639301944:tab_ct_st$cluster_celltype_total) * 100
1760639303336:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639303358:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639303382:normalize_cell_id <- function(x) {
1760639303383:x <- trimws(as.character(x))
1760639303383:x <- gsub("_X_|_Y_", "_", x)
1760639303384:x <- gsub("_\\.", ".", x)
1760639303385:x
1760639303385:}
1760639303387:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639303413:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639303441:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639303509:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639303510:data = combined, FUN = length)
1760639303525:names(counts_cluster_celltype)[3] <- "cell_count"
1760639303527:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639303529:data = combined, FUN = length)
1760639303548:names(tab_ct_st)[4] <- "cell_count"
1760639303550:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639303558:names(totals_cluster)[2] <- "cluster_total_cells"
1760639303560:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639303564:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639303566:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639303567:data = combined, FUN = length)
1760639303581:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639303582:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639303583:by = c("integration_cluster", "cell_type"))
1760639303592:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639303594:tab_ct_st$cluster_celltype_total) * 100
1760639304068:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639304088:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639304133:normalize_cell_id <- function(x) {
1760639304139:x <- trimws(as.character(x))
1760639304143:x <- gsub("_X_|_Y_", "_", x)
1760639304144:x <- gsub("_\\.", ".", x)
1760639304145:x
1760639304147:}
1760639304149:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639304183:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639304230:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639304298:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639304298:data = combined, FUN = length)
1760639304309:names(counts_cluster_celltype)[3] <- "cell_count"
1760639304310:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639304311:data = combined, FUN = length)
1760639304323:names(tab_ct_st)[4] <- "cell_count"
1760639304324:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639304331:names(totals_cluster)[2] <- "cluster_total_cells"
1760639304333:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639304335:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639304336:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639304337:data = combined, FUN = length)
1760639304348:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639304349:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639304349:by = c("integration_cluster", "cell_type"))
1760639304352:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639304353:tab_ct_st$cluster_celltype_total) * 100
1760639304553:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639304580:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639304630:normalize_cell_id <- function(x) {
1760639304632:x <- trimws(as.character(x))
1760639304633:x <- gsub("_X_|_Y_", "_", x)
1760639304634:x <- gsub("_\\.", ".", x)
1760639304634:x
1760639304635:}
1760639304636:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639304668:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639304696:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639304987:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639304988:data = combined, FUN = length)
1760639305018:names(counts_cluster_celltype)[3] <- "cell_count"
1760639305020:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639305021:data = combined, FUN = length)
1760639305043:names(tab_ct_st)[4] <- "cell_count"
1760639305048:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639305064:names(totals_cluster)[2] <- "cluster_total_cells"
1760639305065:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639305069:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639305071:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639305073:data = combined, FUN = length)
1760639305085:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639305087:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639305089:by = c("integration_cluster", "cell_type"))
1760639305096:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639305097:tab_ct_st$cluster_celltype_total) * 100
1760639305099:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639305119:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639305138:normalize_cell_id <- function(x) {
1760639305139:x <- trimws(as.character(x))
1760639305140:x <- gsub("_X_|_Y_", "_", x)
1760639305141:x <- gsub("_\\.", ".", x)
1760639305142:x
1760639305143:}
1760639305145:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639305166:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639305199:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639305240:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639305241:data = combined, FUN = length)
1760639305249:names(counts_cluster_celltype)[3] <- "cell_count"
1760639305251:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639305251:data = combined, FUN = length)
1760639305262:names(tab_ct_st)[4] <- "cell_count"
1760639305263:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639305271:names(totals_cluster)[2] <- "cluster_total_cells"
1760639305273:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639305276:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639305277:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639305278:data = combined, FUN = length)
1760639305287:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639305290:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639305291:by = c("integration_cluster", "cell_type"))
1760639305294:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639305294:tab_ct_st$cluster_celltype_total) * 100
1760639305295:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639305305:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639305320:normalize_cell_id <- function(x) {
1760639305321:x <- trimws(as.character(x))
1760639305321:x <- gsub("_X_|_Y_", "_", x)
1760639305322:x <- gsub("_\\.", ".", x)
1760639305323:x
1760639305324:}
1760639305325:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639305349:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639305376:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639305411:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639305412:data = combined, FUN = length)
1760639305421:names(counts_cluster_celltype)[3] <- "cell_count"
1760639305422:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639305422:data = combined, FUN = length)
1760639305433:names(tab_ct_st)[4] <- "cell_count"
1760639305434:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639305454:names(totals_cluster)[2] <- "cluster_total_cells"
1760639305455:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639305458:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639305460:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639305461:data = combined, FUN = length)
1760639305473:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639305474:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639305475:by = c("integration_cluster", "cell_type"))
1760639305479:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639305480:tab_ct_st$cluster_celltype_total) * 100
1760639305482:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639305494:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639305512:normalize_cell_id <- function(x) {
1760639305513:x <- trimws(as.character(x))
1760639305513:x <- gsub("_X_|_Y_", "_", x)
1760639305514:x <- gsub("_\\.", ".", x)
1760639305515:x
1760639305516:}
1760639305517:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639305537:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639305554:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639305587:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639305588:data = combined, FUN = length)
1760639305597:names(counts_cluster_celltype)[3] <- "cell_count"
1760639305598:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639305598:data = combined, FUN = length)
1760639305609:names(tab_ct_st)[4] <- "cell_count"
1760639305610:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639305617:names(totals_cluster)[2] <- "cluster_total_cells"
1760639305618:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639305620:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639305621:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639305622:data = combined, FUN = length)
1760639305631:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639305632:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639305633:by = c("integration_cluster", "cell_type"))
1760639305635:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639305636:tab_ct_st$cluster_celltype_total) * 100
1760639306166:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639306187:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639306203:normalize_cell_id <- function(x) {
1760639306204:x <- trimws(as.character(x))
1760639306204:x <- gsub("_X_|_Y_", "_", x)
1760639306205:x <- gsub("_\\.", ".", x)
1760639306206:x
1760639306206:}
1760639306208:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639306228:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639306247:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639306282:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639306283:data = combined, FUN = length)
1760639306293:names(counts_cluster_celltype)[3] <- "cell_count"
1760639306295:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639306295:data = combined, FUN = length)
1760639306307:names(tab_ct_st)[4] <- "cell_count"
1760639306308:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639306320:names(totals_cluster)[2] <- "cluster_total_cells"
1760639306322:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639306326:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639306328:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639306331:data = combined, FUN = length)
1760639306344:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639306346:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639306348:by = c("integration_cluster", "cell_type"))
1760639306355:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639306357:tab_ct_st$cluster_celltype_total) * 100
1760639306424:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639306437:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639306454:normalize_cell_id <- function(x) {
1760639306455:x <- trimws(as.character(x))
1760639306456:x <- gsub("_X_|_Y_", "_", x)
1760639306457:x <- gsub("_\\.", ".", x)
1760639306458:x
1760639306458:}
1760639306460:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639306482:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639306507:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639306546:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639306548:data = combined, FUN = length)
1760639306587:names(counts_cluster_celltype)[3] <- "cell_count"
1760639306593:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639306596:data = combined, FUN = length)
1760639306614:names(tab_ct_st)[4] <- "cell_count"
1760639306618:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639306630:names(totals_cluster)[2] <- "cluster_total_cells"
1760639306634:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639306636:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639306638:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639306639:data = combined, FUN = length)
1760639306651:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639306652:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639306653:by = c("integration_cluster", "cell_type"))
1760639306656:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639306658:tab_ct_st$cluster_celltype_total) * 100
1760639306659:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639306674:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639306704:normalize_cell_id <- function(x) {
1760639306705:x <- trimws(as.character(x))
1760639306706:x <- gsub("_X_|_Y_", "_", x)
1760639306708:x <- gsub("_\\.", ".", x)
1760639306711:x
1760639306712:}
1760639306714:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639306752:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639306777:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639306818:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639306819:data = combined, FUN = length)
1760639306832:names(counts_cluster_celltype)[3] <- "cell_count"
1760639306833:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639306834:data = combined, FUN = length)
1760639306848:names(tab_ct_st)[4] <- "cell_count"
1760639306849:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639306855:names(totals_cluster)[2] <- "cluster_total_cells"
1760639306856:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639306859:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639306860:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639306860:data = combined, FUN = length)
1760639306870:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639306872:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639306872:by = c("integration_cluster", "cell_type"))
1760639306875:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639306876:tab_ct_st$cluster_celltype_total) * 100
1760639306877:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639306888:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639306909:normalize_cell_id <- function(x) {
1760639306910:x <- trimws(as.character(x))
1760639306911:x <- gsub("_X_|_Y_", "_", x)
1760639306912:x <- gsub("_\\.", ".", x)
1760639306913:x
1760639306913:}
1760639306915:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639306941:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639306985:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639307119:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639307120:data = combined, FUN = length)
1760639307140:names(counts_cluster_celltype)[3] <- "cell_count"
1760639307142:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639307143:data = combined, FUN = length)
1760639307175:names(tab_ct_st)[4] <- "cell_count"
1760639307177:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639307195:names(totals_cluster)[2] <- "cluster_total_cells"
1760639307197:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639307200:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639307201:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639307202:data = combined, FUN = length)
1760639307216:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639307217:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639307218:by = c("integration_cluster", "cell_type"))
1760639307222:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639307223:tab_ct_st$cluster_celltype_total) * 100
1760639307224:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639307243:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639307287:normalize_cell_id <- function(x) {
1760639307288:x <- trimws(as.character(x))
1760639307289:x <- gsub("_X_|_Y_", "_", x)
1760639307290:x <- gsub("_\\.", ".", x)
1760639307291:x
1760639307292:}
1760639307294:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639307325:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639307360:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639307412:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639307412:data = combined, FUN = length)
1760639307425:names(counts_cluster_celltype)[3] <- "cell_count"
1760639307427:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639307428:data = combined, FUN = length)
1760639307442:names(tab_ct_st)[4] <- "cell_count"
1760639307444:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639307453:names(totals_cluster)[2] <- "cluster_total_cells"
1760639307455:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639307458:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639307460:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639307460:data = combined, FUN = length)
1760639307475:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639307477:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639307478:by = c("integration_cluster", "cell_type"))
1760639307482:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639307483:tab_ct_st$cluster_celltype_total) * 100
1760639307484:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760639307503:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760639307522:normalize_cell_id <- function(x) {
1760639307524:x <- trimws(as.character(x))
1760639307527:x <- gsub("_X_|_Y_", "_", x)
1760639307528:x <- gsub("_\\.", ".", x)
1760639307529:x
1760639307530:}
1760639307532:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760639307565:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760639307595:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760639307637:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639307637:data = combined, FUN = length)
1760639307668:names(counts_cluster_celltype)[3] <- "cell_count"
1760639307670:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760639307670:data = combined, FUN = length)
1760639307686:names(tab_ct_st)[4] <- "cell_count"
1760639307687:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760639307696:names(totals_cluster)[2] <- "cluster_total_cells"
1760639307697:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760639307701:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760639307702:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760639307703:data = combined, FUN = length)
1760639307715:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760639307717:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760639307717:by = c("integration_cluster", "cell_type"))
1760639307721:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760639307721:tab_ct_st$cluster_celltype_total) * 100
1760645502572:# 1. Import
1760645502578:labs   <- read.csv("project_oct25/clinical_labs.csv", stringsAsFactors = FALSE)
1760645503087:vitals <- read.csv("project_oct25/vitals_time_series.csv", stringsAsFactors = FALSE)
1760645503942:# 2. Convert to POSIXct
1760645503945:labs$time_iso   <- as.POSIXct(labs$time_iso)
1760645505137:vitals$time_iso <- as.POSIXct(vitals$time_iso)
1760645505918:# 3. Join nearest HR/SBP manually (loop-based)
1760645505922:nearest_match <- function(lab_df, vitals_df, vital_type) {
1760645505925:vitals_sub <- vitals_df[vitals_df$vital == vital_type, ]
1760645505926:results <- list()
1760645505928:for (i in seq_len(nrow(lab_df))) {
1760645505930:pid <- lab_df$patient_id[i]
1760645505931:time <- lab_df$time_iso[i]
1760645505933:v_sub <- vitals_sub[vitals_sub$patient_id == pid, ]
1760645505935:if (nrow(v_sub) > 0) {
1760645505937:idx <- which.min(abs(difftime(v_sub$time_iso, time, units = "mins")))
1760645505939:results[[i]] <- v_sub[idx, c("value", "time_iso")]
1760645505942:} else {
1760645505948:results[[i]] <- data.frame(value = NA, time_iso = NA)
1760645505950:}
1760645505953:}
1760645505955:out <- do.call(rbind, results)
1760645505956:names(out) <- c(paste0("nearest_", vital_type), paste0(vital_type, "_time"))
1760645505957:return(out)
1760645505960:}
1760645506817:# 4. Attach nearest HR and SBP
1760645506821:hr_data  <- nearest_match(labs, vitals, "HR")
1760645507707:sbp_data <- nearest_match(labs, vitals, "SBP")
1760645509408:labs_with_vitals <- cbind(labs, hr_data, sbp_data)
1760645510095:labs_with_vitals$hr_lag_minutes  <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$HR_time, units = "mins"))
1760645511202:labs_with_vitals$sbp_lag_minutes <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$SBP_time, units = "mins"))
1760645512230:# 5. Correlation per patient (CRP only)
1760645512235:crp_data <- subset(labs_with_vitals, lab == "CRP")
1760645513290:cor_crp_hr  <- aggregate(cbind(value, nearest_HR) ~ patient_id, data = crp_data,
1760645513294:FUN = function(x) cor(x[, 1], x[, 2], use = "complete.obs"))
1760645532106:?cor
1760645563059:?FUN
1760645568230:??FUN
1760645631135:# 1. Import
1760645631138:labs   <- read.csv("project_oct25/clinical_labs.csv", stringsAsFactors = FALSE)
1760645631435:vitals <- read.csv("project_oct25/vitals_time_series.csv", stringsAsFactors = FALSE)
1760645632772:# 2. Convert to POSIXct
1760645632775:labs$time_iso   <- as.POSIXct(labs$time_iso)
1760645633118:vitals$time_iso <- as.POSIXct(vitals$time_iso)
1760645634122:# 3. Join nearest HR/SBP manually (loop-based)
1760645634126:nearest_match <- function(lab_df, vitals_df, vital_type) {
1760645634127:vitals_sub <- vitals_df[vitals_df$vital == vital_type, ]
1760645634129:results <- list()
1760645634131:for (i in seq_len(nrow(lab_df))) {
1760645634132:pid <- lab_df$patient_id[i]
1760645634133:time <- lab_df$time_iso[i]
1760645634134:v_sub <- vitals_sub[vitals_sub$patient_id == pid, ]
1760645634136:if (nrow(v_sub) > 0) {
1760645634137:idx <- which.min(abs(difftime(v_sub$time_iso, time, units = "mins")))
1760645634139:results[[i]] <- v_sub[idx, c("value", "time_iso")]
1760645634140:} else {
1760645634143:results[[i]] <- data.frame(value = NA, time_iso = NA)
1760645634147:}
1760645634150:}
1760645634151:out <- do.call(rbind, results)
1760645634154:names(out) <- c(paste0("nearest_", vital_type), paste0(vital_type, "_time"))
1760645634156:return(out)
1760645634160:}
1760645637417:View(nearest_match)
1760645639181:View(nearest_match)
1760645657777:# 4. Attach nearest HR and SBP
1760645657780:hr_data  <- nearest_match(labs, vitals, "HR")
1760645659804:sbp_data <- nearest_match(labs, vitals, "SBP")
1760645660567:labs_with_vitals <- cbind(labs, hr_data, sbp_data)
1760645660999:labs_with_vitals$hr_lag_minutes  <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$HR_time, units = "mins"))
1760645661441:labs_with_vitals$sbp_lag_minutes <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$SBP_time, units = "mins"))
1760645673085:# 5. Correlation per patient (CRP only)
1760645673087:crp_data <- subset(labs_with_vitals, lab == "CRP")
1760645677606:cor_crp_hr  <- aggregate(cbind(value, nearest_HR) ~ patient_id, data = crp_data,
1760645677611:FUN = function(x) cor(x[, 1], x[, 2], use = "complete.obs"))
1760645703815:?cbind
1760645727659:View(crp_data)
1760645741232:View(labs_with_vitals)
1760646015684:# 1. Import
1760646015689:labs   <- read.csv("project_oct25/clinical_labs.csv", stringsAsFactors = FALSE)
1760646016076:vitals <- read.csv("project_oct25/vitals_time_series.csv", stringsAsFactors = FALSE)
1760646016487:# 2. Convert to POSIXct
1760646016490:labs$time_iso   <- as.POSIXct(labs$time_iso)
1760646016829:vitals$time_iso <- as.POSIXct(vitals$time_iso)
1760646017274:# 3. Join nearest HR/SBP manually (loop-based)
1760646017275:nearest_match <- function(lab_df, vitals_df, vital_type) {
1760646017277:vitals_sub <- vitals_df[vitals_df$vital == vital_type, ]
1760646017279:results <- list()
1760646017280:for (i in seq_len(nrow(lab_df))) {
1760646017282:pid <- lab_df$patient_id[i]
1760646017284:time <- lab_df$time_iso[i]
1760646017286:v_sub <- vitals_sub[vitals_sub$patient_id == pid, ]
1760646017287:if (nrow(v_sub) > 0) {
1760646017288:idx <- which.min(abs(difftime(v_sub$time_iso, time, units = "mins")))
1760646017289:results[[i]] <- v_sub[idx, c("value", "time_iso")]
1760646017291:} else {
1760646017292:results[[i]] <- data.frame(value = NA, time_iso = NA)
1760646017295:}
1760646017299:}
1760646017305:out <- do.call(rbind, results)
1760646017307:names(out) <- c(paste0("nearest_", vital_type), paste0(vital_type, "_time"))
1760646017317:return(out)
1760646017320:}
1760646018332:# 4. Attach nearest HR and SBP
1760646018334:hr_data  <- nearest_match(labs, vitals, "HR")
1760646018988:sbp_data <- nearest_match(labs, vitals, "SBP")
1760646019616:labs_with_vitals <- cbind(labs, hr_data, sbp_data)
1760646020096:labs_with_vitals$hr_lag_minutes  <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$HR_time, units = "mins"))
1760646020627:labs_with_vitals$sbp_lag_minutes <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$SBP_time, units = "mins"))
1760646021406:crp_data <- subset(labs_with_vitals, lab == "CRP")
1760646021981:# Split by patient_id
1760646021983:patients_list <- split(crp_data, crp_data$patient_id)
1760646022558:# Function to compute correlation safely
1760646022562:safe_cor <- function(df, col_x = "value", col_y = "nearest_HR") {
1760646022565:if (nrow(df) < 2) return(NA_real_)           # meno di 2 osservazioni -> NA
1760646022567:x <- df[[col_x]]
1760646022569:y <- df[[col_y]]
1760646022571:# keep only pairs non-NA
1760646022573:ok <- !is.na(x) & !is.na(y)
1760646022575:if (sum(ok) < 2) return(NA_real_)            # meno di 2 coppie valide -> NA
1760646022577:return(cor(x[ok], y[ok], use = "complete.obs"))
1760646022579:}
1760646023452:# Calcola correlazione CRP vs HR per ogni paziente
1760646023456:cor_crp_hr <- data.frame(
1760646023458:patient_id = names(patients_list),
1760646023459:correlation_CRP_HR = sapply(patients_list, safe_cor, col_x = "value", col_y = "nearest_HR"),
1760646023462:row.names = NULL,
1760646023463:stringsAsFactors = FALSE
1760646023466:)
1760646024349:# Calcola correlazione CRP vs SBP per ogni paziente
1760646024357:cor_crp_sbp <- data.frame(
1760646024362:patient_id = names(patients_list),
1760646024365:correlation_CRP_SBP = sapply(patients_list, safe_cor, col_x = "value", col_y = "nearest_SBP"),
1760646024367:row.names = NULL,
1760646024369:stringsAsFactors = FALSE
1760646024371:)
1760646025216:# Stampa risultati
1760646025220:cat("\n--- Correlazione CRP-HR per paziente ---\n")
1760646026008:print(cor_crp_hr)
1760646026712:cat("\n--- Correlazione CRP-SBP per paziente ---\n")
1760646027228:print(cor_crp_sbp)
1760646082261:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760646082442:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760646082602:merged <- merge(counts, meta, by = "sample_id")
1760646082799:stats_by_gene_condition <- aggregate(count ~ gene + condition, data = merged,
1760646082801:FUN = function(x) c(mean = mean(x), median = median(x),
1760646082802:Q1 = quantile(x, 0.25, type = 2),
1760646082803:Q3 = quantile(x, 0.75, type = 2)))
1760646083487:stats_df <- data.frame(
1760646083489:gene = stats_by_gene_condition$gene,
1760646083489:condition = stats_by_gene_condition$condition,
1760646083490:mean_count = stats_by_gene_condition$count[, "mean"],
1760646083491:median_count = stats_by_gene_condition$count[, "median"],
1760646083492:Q1 = stats_by_gene_condition$count[, "Q1"],
1760646083492:Q3 = stats_by_gene_condition$count[, "Q3"]
1760646083494:)
1760646106948:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760646107315:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760646108224:merged <- merge(counts, meta, by = "sample_id")
1760646108982:stats_by_gene_condition <- aggregate(count ~ gene + condition, data = merged,
1760646108986:FUN = function(x) c(mean = mean(x), median = median(x),
1760646108988:Q1 = quantile(x, 0.25, type = 2),
1760646108992:Q3 = quantile(x, 0.75, type = 2)))
1760646113144:stats_df <- data.frame(
1760646113148:gene = stats_by_gene_condition$gene,
1760646113150:condition = stats_by_gene_condition$condition,
1760646113151:mean_count = stats_by_gene_condition$count[, "mean"],
1760646113153:median_count = stats_by_gene_condition$count[, "median"],
1760646113154:Q1 = stats_by_gene_condition$count[, "Q1"],
1760646113156:Q3 = stats_by_gene_condition$count[, "Q3"]
1760646113158:)
1760646114766:treated <- subset(stats_df, condition == "treated")[, c("gene", "mean_count")]
1760646115517:control <- subset(stats_df, condition == "control")[, c("gene", "mean_count")]
1760646123417:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760646123819:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760646124382:merged <- merge(counts, meta, by = "sample_id")
1760646125912:stats_by_gene_condition <- aggregate(count ~ gene + condition, data = merged,
1760646125915:FUN = function(x) c(mean = mean(x), median = median(x),
1760646125916:Q1 = quantile(x, 0.25, type = 2),
1760646125917:Q3 = quantile(x, 0.75, type = 2)))
1760646127731:stats_df <- data.frame(
1760646127734:gene = stats_by_gene_condition$gene,
1760646127740:condition = stats_by_gene_condition$condition,
1760646127745:mean_count = stats_by_gene_condition$count[, "mean"],
1760646127748:median_count = stats_by_gene_condition$count[, "median"],
1760646127750:Q1 = stats_by_gene_condition$count[, "Q1"],
1760646127754:Q3 = stats_by_gene_condition$count[, "Q3"]
1760646127759:)
1760646136742:View(stats_by_gene_condition)
1760646191728:View(stats_by_gene_condition)
1760646247337:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760646247921:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760646248537:merged <- merge(counts, meta, by = "sample_id")
1760646249008:stats_by_gene_condition <- aggregate(count ~ gene + condition, data = merged,
1760646249010:FUN = function(x) c(mean = mean(x), median = median(x),
1760646249012:Q1 = quantile(x, 0.25, type = 2),
1760646249014:Q3 = quantile(x, 0.75, type = 2)))
1760646250072:stats_df <- data.frame(
1760646250074:gene = stats_by_gene_condition$gene,
1760646250076:condition = stats_by_gene_condition$condition,
1760646250078:mean_count = stats_by_gene_condition$count["mean"],
1760646250079:median_count = stats_by_gene_condition$count[, "median"],
1760646250080:Q1 = stats_by_gene_condition$count[, "Q1"],
1760646250082:Q3 = stats_by_gene_condition$count[, "Q3"]
1760646250083:)
1760646252745:View(stats_by_gene_condition)
1760646275375:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760646275683:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760646276177:merged <- merge(counts, meta, by = "sample_id")
1760646276666:stats_by_gene_condition <- aggregate(count ~ gene + condition, data = merged,
1760646276675:FUN = function(x) c(mean = mean(x), median = median(x),
1760646276678:Q1 = quantile(x, 0.25, type = 2),
1760646276680:Q3 = quantile(x, 0.75, type = 2)))
1760646278624:View(stats_by_gene_condition)
1760646322601:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760646322907:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760646323671:merged <- merge(counts, meta, by = "sample_id")
1760646327419:View(merged)
1760646332748:stats_by_gene_condition <- aggregate(count ~ gene + condition, data = merged,
1760646332752:FUN = function(x) c(mean = mean(x), median = median(x),
1760646332753:Q1 = quantile(x, 0.25, type = 2),
1760646332755:Q3 = quantile(x, 0.75, type = 2)))
1760646335865:View(stats_by_gene_condition)
1760646381344:View(stats_by_gene_condition)
1760646397875:stats_df <- data.frame(
1760646397879:gene = stats_by_gene_condition$gene,
1760646397881:condition = stats_by_gene_condition$condition,
1760646397882:mean_count = stats_by_gene_condition$count[, "mean"],
1760646397884:median_count = stats_by_gene_condition$count[, "median"],
1760646397886:Q1 = stats_by_gene_condition$count[, "Q1.25%"],
1760646397889:Q3 = stats_by_gene_condition$count[, "Q3"]
1760646397891:)
1760646418153:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760646418571:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760646419035:merged <- merge(counts, meta, by = "sample_id")
1760646419541:stats_by_gene_condition <- aggregate(count ~ gene + condition, data = merged,
1760646419570:FUN = function(x) c(mean = mean(x), median = median(x),
1760646419592:Q1 = quantile(x, 0.25, type = 2),
1760646419601:Q3 = quantile(x, 0.75, type = 2)))
1760646420296:stats_df <- data.frame(
1760646420297:gene = stats_by_gene_condition$gene,
1760646420298:condition = stats_by_gene_condition$condition,
1760646420298:mean_count = stats_by_gene_condition$count[, "mean"],
1760646420299:median_count = stats_by_gene_condition$count[, "median"],
1760646420300:Q1 = stats_by_gene_condition$count[, "Q1.25%"],
1760646420301:Q3 = stats_by_gene_condition$count[, "Q3.75%"]
1760646420302:)
1760646426548:treated <- subset(stats_df, condition == "treated")[, c("gene", "mean_count")]
1760646427058:control <- subset(stats_df, condition == "control")[, c("gene", "mean_count")]
1760646427699:names(treated)[2] <- "treated_mean"
1760646428290:names(control)[2] <- "control_mean"
1760646428882:means_wide <- merge(treated, control, by = "gene")
1760646429378:kept_genes <- subset(means_wide, treated_mean >= 2 * control_mean)
1760646868235:library(data.table) #carica il pacchetto data.table in R per farci delle operazioni
1760646901598:# 1 Import
1760646901603:counts <- fread("project_oct25/bulk_counts_long.csv") #legge i file e li salva come variabili counts e meta che sono matrici con dati, è la funzione ad alte prestazioni di data.table per leggere file e restituisce un oggetto di classe data.table
1760646918043:meta <- fread("project_oct25/sample_metadata.csv")  #definiamo il path così sa dove trovare i file
1760646920148:View(counts)
1760646925014:View(meta)
1760647023904:?setket
1760647028901:?setkey
1760647068418:?setkey
1760647086696:# 1. Import
1760647086700:counts <- fread("project_oct25/bulk_counts_long.csv")
1760647087235:meta   <- fread("project_oct25/sample_metadata.csv")
1760647094253:View(counts)
1760647094925:View(meta)
1760647150040:?[]
1760647156510:?data.table
1760647232381:# 2. Join counts + metadata by sample_id
1760647232386:setkey(counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1760647232894:setkey(meta, sample_id)
1760647233824:merged_data <- counts[meta, nomatch = 0]
1760647235912:View(merged_data)
1760647948847:?grepl
1760648170249:# 4. Compute mean and median per gene
1760648170252:gene_summary <- filtered_data[, .(
1760648170254:mean_count   = mean(count),
1760648170256:median_count = median(count)
1760648170258:), by = gene]
1760648187952:library(data.table)
1760648188561:# 1. Import
1760648188564:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760648189408:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760648189913:# 2. Join counts + metadata by sample_id
1760648189916:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1760648189917:#effettua una modifica in place (non crea una copia)
1760648189919:#questo permette join molto più rapidi
1760648189920:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1760648190718:setkey(sample_meta, sample_id)
1760648191449:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760648193990:# 3. Filter for treated samples and GENE_00* genes
1760648193994:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1760648194162:# 4. Compute mean and median per gene
1760648194164:gene_summary <- filtered_data[, .(
1760648194165:mean_count   = mean(count),
1760648194167:median_count = median(count)
1760648194169:), by = gene]
1760648194323:# 5. Pipeline version: join + filter + summarise in one line
1760648194325:gene_mean_pipeline <- counts[meta, on = "sample_id"][
1760648194328:condition == "treated" & grepl("^GENE_00", gene),
1760648194329:.(mean_count = mean(count)),
1760648194330:by = gene
1760648194331:]
1760648204921:library(data.table)
1760648205645:# 1. Import
1760648205648:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760648206325:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760648206863:# 2. Join counts + metadata by sample_id
1760648206868:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1760648206869:#effettua una modifica in place (non crea una copia)
1760648206870:#questo permette join molto più rapidi
1760648206872:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1760648207957:setkey(sample_meta, sample_id)
1760648208636:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760648209525:# 3. Filter for treated samples and GENE_00* genes
1760648209530:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1760648212102:# 4. Compute mean and median per gene
1760648212107:gene_summary <- filtered_data[, .(
1760648212109:mean_count   = mean(count),
1760648212111:median_count = median(count)
1760648212112:), by = gene]
1760648218725:View(gene_summary)
1760648286711:library(data.table)
1760648286935:# 1. Import
1760648286939:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760648287133:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760648296030:library(data.table)
1760648307566:library(data.table)
1760648317958:library(data.table)
1760648333987:library(data.table)
1760648340795:library(data.table)
1760648341538:# 1. Import
1760648341540:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760648342795:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760648347784:# 2. Join counts + metadata by sample_id
1760648347788:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1760648347790:#effettua una modifica in place (non crea una copia)
1760648347792:#questo permette join molto più rapidi
1760648347794:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1760648348906:setkey(sample_meta, sample_id)
1760648350832:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760648357665:# 3. Filter for treated samples and GENE_00* genes
1760648357668:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1760648360029:View(filtered_data)
1760648386534:View(filtered_data)
1760648393964:# 4. Compute mean and median per gene
1760648393967:gene_mean_median <- filtered_data[, .(
1760648393968:mean_count   = mean(count),
1760648393970:median_count = median(count)
1760648393971:), by = gene]
1760648460993:# 5. Pipeline version: join + filter + summarise in one line
1760648460997:gene_mean_pipeline <- counts[meta, on = "sample_id"][
1760648460999:condition == "treated" & grepl("^GENE_00", gene),
1760648461000:.(mean_count = mean(count)),
1760648461002:by = gene
1760648461004:]
1760648486343:# 5. Pipeline version: join + filter + summarise in one line
1760648486345:gene_mean_pipeline <- bulk_counts[sample_meta, on = "sample_id"][
1760648486349:condition == "treated" & grepl("^GENE_00", gene),
1760648486351:.(mean_count = mean(count)),
1760648486353:by = gene
1760648486355:]
1760648502759:View(gene_mean_pipeline)
1760648968346:View(join_data)
1760649480412:library(data.table)
1760649480929:# 1. Import
1760649480932:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760649496256:library(data.table)
1760649497947:# 1. Import
1760649497952:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760649498756:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760649499830:# 2. Join counts + metadata by sample_id
1760649499832:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1760649499833:#effettua una modifica in place (non crea una copia)
1760649499835:#questo permette join molto più rapidi
1760649499837:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1760649501054:setkey(sample_meta, sample_id)
1760649501676:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760649509636:# 3. Filter for treated samples and GENE_00* genes
1760649509639:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1760649513629:# 4. Compute mean and median per gene
1760649513634:gene_mean_median <- filtered_data[, .(
1760649513635:mean_count   = mean(count),
1760649513637:median_count = median(count)
1760649513640:), by = gene]
1760649517999:gene_mean_pipe <- join_data[, .(
1760649518003:mean_count   = mean(count),
1760649518004:), by = gene]
1760649540113:View(join_data)
1760649632851:gene_mean_pipe <- join_data[, .(
1760649632856:mean_count   = mean(count)
1760649632858:),by = gene]
1760649637295:View(gene_mean_pipe)
1760649662760:View(join_data)
1760649684986:View(join_data)
1760649810601:library(data.table) #carica il pacchetto data.table in R per farci delle operazioni
1760649811162:# 1 Import
1760649811166:counts <- fread("project_oct25/bulk_counts_long.csv") #legge i file e li salva come variabili counts e meta che sono matrici con dati, è la funzione ad alte prestazioni di data.table per leggere file e restituisce un oggetto di classe data.table
1760649811652:meta <- fread("project_oct25/sample_metadata.csv")  #definiamo il path così sa dove trovare i file
1760649913144:library(data.table)
1760649913714:# 1. Import
1760649913718:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760649914162:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760649914883:# 2. Join counts + metadata by sample_id
1760649914887:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1760649914892:#effettua una modifica in place (non crea una copia)
1760649914894:#questo permette join molto più rapidi
1760649914896:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1760649915481:setkey(sample_meta, sample_id)
1760649916161:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760649921194:# 3. Filter for treated samples and GENE_00* genes
1760649921197:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1760649926103:# 4. Compute mean and median per gene
1760649926106:gene_mean_median <- filtered_data[, .(
1760649926108:mean_count   = mean(count),
1760649926110:median_count = median(count)
1760649926112:), by = gene]
1760649930600:# Calcola la media dei conteggi per ogni combinazione (gene, condition)
1760649930604:# tutto in una singola pipeline: unisco metadata e counts e poi raggruppo
1760649930606:gene_condition_means <- bulk_counts[
1760649930608:sample_meta,                # uso sample_meta come "i" (lookup)
1760649930609:on = "sample_id"            # join su sample_id (non serve setkey se usi on=)
1760649930610:][ , .(
1760649930613:mean_count = mean(count, na.rm = TRUE)   # media dei conteggi (ignora NA se ci sono)
1760649930615:), by = .(gene, condition) ]               # raggruppa per gene e per condition
1760649938264:View(gene_condition_means)
1760649984502:View(bulk_counts)
1760650040885:# Calcola la media dei conteggi per ogni combinazione (gene, condition)
1760650040889:# tutto in una singola pipeline: unisco metadata e counts e poi raggruppo
1760650040891:gene_condition_means <- bulk_counts[
1760650040894:sample_meta,                # uso sample_meta come "i" (lookup)
1760650040895:on = "sample_id"            # join su sample_id (non serve setkey se usi on=)
1760650040896:][ , .(
1760650040897:mean_count = mean(count)   # media dei conteggi (ignora NA se ci sono)
1760650040899:), by = .(gene, condition) ]               # raggruppa per gene e per condition
1760650045694:View(gene_condition_means)
1760650058998:View(gene_mean_median)
1760650130522:# ==========================================================
1760650130527:# TASK 1 – data.table version
1760650130530:# Goal:
1760650130531:# - Filter counts for samples in condition == "treated" and genes starting with "GENE_00"
1760650130532:# - Compute mean and median count by gene
1760650130533:# - Join metadata and compute per-condition mean counts by gene in one pipeline
1760650130534:# ==========================================================
1760650130536:library(data.table)
1760650130538:# 1. Import
1760650130539:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760650130546:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760650130550:# 2. Join counts + metadata by sample_id
1760650130551:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1760650130552:#effettua una modifica in place (non crea una copia)
1760650130553:#questo permette join molto più rapidi
1760650130554:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1760650130556:setkey(sample_meta, sample_id)
1760650130558:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760650130563:#In data.table la forma X[i] può essere usata per i join:
1760650130563:#X = tabella da cui prendi i dati (qui counts)
1760650130564:#i = tabella che serve come query/indice (qui meta)
1760650130565:#Quando ci sono chiavi compatibili (sample_id), counts[meta] interpreta meta come la tabella di lookup
1760650130566:#e per ciascuna riga di meta estrae le righe corrispondenti da counts
1760650130567:#nomatch = 0 significa: escludi le righe di meta che non trovano corrispondenza in counts.
1760650130568:#Questo equivale a un inner join (solo righe with match).
1760650130569:# 3. Filter for treated samples and GENE_00* genes
1760650130570:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1760650130575:#filtrare stringhe in base a un pattern (cioè una “regola” di testo).
1760650130575:#Quindi grepl("^GENE_00", gene) restituisce:
1760650130576:#TRUE per tutti i geni che iniziano con GENE_00
1760650130577:#FALSE per tutti gli altri.
1760650130578:# 4. Compute mean and median per gene
1760650130579:gene_mean_median <- filtered_data[, .(
1760650130579:mean_count   = mean(count),
1760650130580:median_count = median(count)
1760650130581:), by = gene]
1760650130584:# Punto 5 corretto: join + per-condition mean by gene (una pipeline)
1760650130586:# Calcola la media dei conteggi per ogni combinazione (gene, condition)
1760650130586:# tutto in una singola pipeline: unisco metadata e counts e poi raggruppo
1760650130587:gene_condition_means <- bulk_counts[
1760650130587:sample_meta,                # uso sample_meta come "i" (lookup)
1760650130588:on = "sample_id"            # join su sample_id (non serve setkey se usi on=)
1760650130588:][ , .(
1760650130589:mean_count = mean(count)   # media dei conteggi (ignora NA se ci sono)
1760650130590:), by = .(gene, condition) ]               # raggruppa per gene e per condition
1760650285309:# 1. Import
1760650285312:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760650285774:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760650287325:# 2. Join counts + metadata by sample_id
1760650287331:merged_data <- merge(counts, meta, by = "sample_id")
1760650289446:# 3. Filter for treated samples and GENE_00* genes
1760650289450:treated_data <- subset(merged_data,
1760650289452:condition == "treated" & grepl("^GENE_00", gene))
1760650307217:View(treated_data)
1760650311882:View(merged_data)
1760650331065:# 4. Compute mean and median per gene
1760650331069:gene_summary <- aggregate(
1760650331072:count ~ gene,
1760650331074:data = treated_data,
1760650331077:FUN  = function(x) c(mean = mean(x), median = median(x))
1760650331079:)
1760650333511:View(gene_summary)
1760650493731:View(counts)
1760650496315:View(meta)
1760650498803:View(gene_summary)
1760650503463:View(merged_data)
1760650505657:View(treated_data)
1760650571309:library(data.table)
1760650572040:# 1. Import
1760650572044:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760650572484:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760650573172:# 2. Join counts + metadata by sample_id
1760650573178:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1760650573180:#effettua una modifica in place (non crea una copia)
1760650573182:#questo permette join molto più rapidi
1760650573184:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1760650573354:setkey(sample_meta, sample_id)
1760650573544:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760650573727:# 3. Filter for treated samples and GENE_00* genes
1760650573730:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1760650573930:# 4. Compute mean and median per gene
1760650573934:gene_mean_median <- filtered_data[, .(
1760650573936:mean_count   = mean(count),
1760650573938:median_count = median(count)
1760650573939:), by = gene]
1760650574154:# Calcola la media dei conteggi per ogni combinazione (gene, condition)
1760650574159:# tutto in una singola pipeline: unisco metadata e counts e poi raggruppo
1760650574163:gene_condition_means <- bulk_counts[
1760650574166:sample_meta,                # uso sample_meta come "i" (lookup)
1760650574170:on = "sample_id"            # join su sample_id (non serve setkey se usi on=)
1760650574172:][ , .(
1760650574175:mean_count = mean(count)   # media dei conteggi (ignora NA se ci sono)
1760650574177:), by = .(gene, condition) ]               # raggruppa per gene e per condition
1760650578712:# 1. Import
1760650578723:counts <- read.csv("project_oct25/bulk_counts_long.csv")
1760650579912:meta   <- read.csv("project_oct25/sample_metadata.csv")
1760650580569:# 2. Join counts + metadata by sample_id
1760650580576:merged_data <- merge(counts, meta, by = "sample_id")
1760650581179:# 3. Filter for treated samples and GENE_00* genes
1760650581183:treated_data <- subset(merged_data,
1760650581186:condition == "treated" & grepl("^GENE_00", gene))
1760650582745:# 4. Compute mean and median per gene
1760650582749:gene_summary <- aggregate(
1760650582751:count ~ gene,
1760650582753:data = treated_data,
1760650582755:FUN  = function(x) c(mean = mean(x), median = median(x))
1760650582758:)
1760650583320:# 5. Simplify format
1760650583324:gene_summary_df <- data.frame(
1760650583325:gene = gene_summary$gene,
1760650583327:mean_count   = gene_summary$count[, "mean"],
1760650583328:median_count = gene_summary$count[, "median"]
1760650583332:)
1760650584083:# 6. Pipeline version: merge + filter + summarise in one expression
1760650584096:gene_mean_pipeline <- aggregate(
1760650584105:count ~ gene,
1760650584110:data = subset(
1760650584114:merge(counts, meta, by = "sample_id", all.x = TRUE),
1760650584116:condition == "treated" & grepl("^GENE_00", gene)
1760650584118:),
1760650584121:FUN = mean
1760650584124:)
1760650601784:View(bulk_counts)
1760650603471:View(counts)
1760650647360:View(join_data)
1760650648526:View(merged_data)
1760650650837:View(filtered_data)
1760650653072:View(treated_data)
1760650677683:View(gene_mean_median)
1760650688168:View(gene_summary)
1760650716410:View(gene_condition_means)
1760650727467:View(gene_mean_pipeline)
1760651173534:# 6 Calcolo della media dei conteggi per ciascun gene e condizione
1760651173539:# aggregate() calcola una funzione (mean) per gruppi
1760651173541:gene_condition_means <- aggregate(
1760651173542:count ~ gene + condition,   # formula: raggruppa per gene e condition
1760651173544:data = merged_data,         # tabella di partenza
1760651173545:FUN = mean,                 # funzione da applicare
1760651173546:na.rm = TRUE                # ignora eventuali valori mancanti
1760651173549:)
1760651174626:# 7 Ordina i risultati per gene e condition (per leggibilità)
1760651174630:gene_condition_means <- gene_condition_means[order(gene_condition_means$gene,
1760651174632:gene_condition_means$condition), ]
1760651184798:View(gene_condition_means)
1760651200881:# 6 Calcolo della media dei conteggi per ciascun gene e condizione
1760651200884:# aggregate() calcola una funzione (mean) per gruppi
1760651200886:gene_condition_means_f <- aggregate(
1760651200887:count ~ gene + condition,   # formula: raggruppa per gene e condition
1760651200889:data = merged_data,         # tabella di partenza
1760651200891:FUN = mean,                 # funzione da applicare
1760651200893:na.rm = TRUE                # ignora eventuali valori mancanti
1760651200895:)
1760651206864:# Calcola la media dei conteggi per ogni combinazione (gene, condition)
1760651206868:# tutto in una singola pipeline: unisco metadata e counts e poi raggruppo
1760651206870:gene_condition_means <- bulk_counts[
1760651206871:sample_meta,                # uso sample_meta come "i" (lookup)
1760651206873:on = "sample_id"            # join su sample_id (non serve setkey se usi on=)
1760651206875:][ , .(
1760651206877:mean_count = mean(count)   # media dei conteggi (ignora NA se ci sono)
1760651206878:), by = .(gene, condition) ]               # raggruppa per gene e per condition
1760651209795:View(gene_condition_means)
1760651210876:View(gene_condition_means_f)
1760651256395:# 7 Ordina i risultati per gene e condition (per leggibilità)
1760651256399:gene_condition_means <- gene_condition_means[order(gene_condition_means$gene,
1760651256402:gene_condition_means$condition), ]
1760651262341:# 1. Import
1760651262344:counts <- read.csv("project_oct25/bulk_counts_long.csv")
1760651262499:meta   <- read.csv("project_oct25/sample_metadata.csv")
1760651262665:# 2. Join counts + metadata by sample_id
1760651262670:merged_data <- merge(counts, meta, by = "sample_id")
1760651262819:# 3. Filter for treated samples and GENE_00* genes
1760651262824:treated_data <- subset(merged_data,
1760651262826:condition == "treated" & grepl("^GENE_00", gene))
1760651262974:# 4. Compute mean and median per gene
1760651262979:gene_summary <- aggregate(
1760651262981:count ~ gene,
1760651262983:data = treated_data,
1760651262984:FUN  = function(x) c(mean = mean(x), median = median(x))
1760651262985:)
1760651263140:# 5. Simplify format
1760651263143:gene_summary_df <- data.frame(
1760651263145:gene = gene_summary$gene,
1760651263147:mean_count   = gene_summary$count[, "mean"],
1760651263149:median_count = gene_summary$count[, "median"]
1760651263151:)
1760651263289:# 6 Calcolo della media dei conteggi per ciascun gene e condizione
1760651263293:# aggregate() calcola una funzione (mean) per gruppi
1760651263295:gene_condition_means_f <- aggregate(
1760651263296:count ~ gene + condition,   # formula: raggruppa per gene e condition
1760651263298:data = merged_data,         # tabella di partenza
1760651263299:FUN = mean,                 # funzione da applicare
1760651263301:na.rm = TRUE                # ignora eventuali valori mancanti
1760651263303:)
1760651263466:# 7 Ordina i risultati per gene e condition (per leggibilità)
1760651263472:gene_condition_means <- gene_condition_means[order(gene_condition_means$gene,
1760651263475:gene_condition_means$condition), ]
1760651299477:# ==========================================================
1760651299479:# TASK 1 – data.frame version
1760651299481:# Stesso obiettivo ma usando solo funzioni base R
1760651299483:# ==========================================================
1760651299485:# 1. Import
1760651299486:counts <- read.csv("project_oct25/bulk_counts_long.csv")
1760651299506:meta   <- read.csv("project_oct25/sample_metadata.csv")
1760651299509:# 2. Join counts + metadata by sample_id
1760651299511:merged_data <- merge(counts, meta, by = "sample_id")
1760651299555:# 3. Filter for treated samples and GENE_00* genes
1760651299555:treated_data <- subset(merged_data,
1760651299556:condition == "treated" & grepl("^GENE_00", gene))
1760651299561:# 4. Compute mean and median per gene
1760651299561:gene_summary <- aggregate(
1760651299562:count ~ gene,
1760651299563:data = treated_data,
1760651299563:FUN  = function(x) c(mean = mean(x), median = median(x))
1760651299564:)
1760651299582:# 5. Simplify format
1760651299585:gene_summary_df <- data.frame(
1760651299586:gene = gene_summary$gene,
1760651299588:mean_count   = gene_summary$count[, "mean"],
1760651299589:median_count = gene_summary$count[, "median"]
1760651299590:)
1760651299593:# 6 Calcolo della media dei conteggi per ciascun gene e condizione
1760651299594:# aggregate() calcola una funzione (mean) per gruppi
1760651299595:gene_condition_means_f <- aggregate(
1760651299596:count ~ gene + condition,   # formula: raggruppa per gene e condition
1760651299598:data = merged_data,         # tabella di partenza
1760651299599:FUN = mean,                 # funzione da applicare
1760651299600:na.rm = TRUE                # ignora eventuali valori mancanti
1760651299602:)
1760651299667:# 7 Ordina i risultati per gene e condition (per leggibilità)
1760651299668:gene_condition_means_f <- gene_condition_means_f[order(gene_condition_means$gene,
1760651299671:gene_condition_means$condition), ]
1760651316066:# ==========================================================
1760651316070:# TASK 1 – data.frame version
1760651316073:# Stesso obiettivo ma usando solo funzioni base R
1760651316075:# ==========================================================
1760651316079:# 1. Import
1760651316080:counts <- read.csv("project_oct25/bulk_counts_long.csv")
1760651316099:meta   <- read.csv("project_oct25/sample_metadata.csv")
1760651316103:# 2. Join counts + metadata by sample_id
1760651316105:merged_data <- merge(counts, meta, by = "sample_id")
1760651316148:# 3. Filter for treated samples and GENE_00* genes
1760651316149:treated_data <- subset(merged_data,
1760651316150:condition == "treated" & grepl("^GENE_00", gene))
1760651316155:# 4. Compute mean and median per gene
1760651316156:gene_summary <- aggregate(
1760651316157:count ~ gene,
1760651316157:data = treated_data,
1760651316158:FUN  = function(x) c(mean = mean(x), median = median(x))
1760651316158:)
1760651316196:# 5. Simplify format
1760651316208:gene_summary_df <- data.frame(
1760651316212:gene = gene_summary$gene,
1760651316217:mean_count   = gene_summary$count[, "mean"],
1760651316218:median_count = gene_summary$count[, "median"]
1760651316219:)
1760651316223:# 6 Calcolo della media dei conteggi per ciascun gene e condizione
1760651316225:# aggregate() calcola una funzione (mean) per gruppi
1760651316226:gene_condition_means_f <- aggregate(
1760651316227:count ~ gene + condition,   # formula: raggruppa per gene e condition
1760651316228:data = merged_data,         # tabella di partenza
1760651316229:FUN = mean,                 # funzione da applicare
1760651316231:na.rm = TRUE                # ignora eventuali valori mancanti
1760651316233:)
1760651316279:# 7 Ordina i risultati per gene e condition (per leggibilità)
1760651316281:gene_condition_means_f <- gene_condition_means_f[order(gene_condition_means_f$gene,
1760651316282:gene_condition_means_f$condition), ]
1760651336696:# ==========================================================
1760651336700:# TASK 1 – data.frame version
1760651336701:# Stesso obiettivo ma usando solo funzioni base R
1760651336703:# ==========================================================
1760651336706:# 1. Import
1760651336707:counts <- read.csv("project_oct25/bulk_counts_long.csv")
1760651336729:meta   <- read.csv("project_oct25/sample_metadata.csv")
1760651336732:# 2. Join counts + metadata by sample_id
1760651336733:merged_data <- merge(counts, meta, by = "sample_id")
1760651336780:# 3. Filter for treated samples and GENE_00* genes
1760651336781:treated_data <- subset(merged_data,
1760651336782:condition == "treated" & grepl("^GENE_00", gene))
1760651336788:# 4. Compute mean and median per gene
1760651336789:gene_summary <- aggregate(
1760651336789:count ~ gene,
1760651336790:data = treated_data,
1760651336791:FUN  = function(x) c(mean = mean(x), median = median(x))
1760651336792:)
1760651336824:# 5. Simplify format
1760651336825:gene_summary_df <- data.frame(
1760651336827:gene = gene_summary$gene,
1760651336827:mean_count   = gene_summary$count[, "mean"],
1760651336828:median_count = gene_summary$count[, "median"]
1760651336829:)
1760651336834:# 6 Calcolo della media dei conteggi per ciascun gene e condizione
1760651336836:# aggregate() calcola una funzione (mean) per gruppi
1760651336838:gene_condition_means_f <- aggregate(
1760651336839:count ~ gene + condition,   # formula: raggruppa per gene e condition
1760651336840:data = merged_data,         # tabella di partenza
1760651336841:FUN = mean,                 # funzione da applicare
1760651336842:na.rm = TRUE                # ignora eventuali valori mancanti
1760651336842:)
1760651336878:# 7 Ordina i risultati per gene e condition (per leggibilità)
1760651336880:gene_condition_means_f <- gene_condition_means_f[order(gene_condition_means_f$gene,
1760651336881:gene_condition_means_f$condition), ]
1760651343141:# 1. Import
1760651343145:counts <- read.csv("project_oct25/bulk_counts_long.csv")
1760651343288:meta   <- read.csv("project_oct25/sample_metadata.csv")
1760651343417:# 2. Join counts + metadata by sample_id
1760651343421:merged_data <- merge(counts, meta, by = "sample_id")
1760651343588:# 3. Filter for treated samples and GENE_00* genes
1760651343593:treated_data <- subset(merged_data,
1760651343594:condition == "treated" & grepl("^GENE_00", gene))
1760651343899:# 4. Compute mean and median per gene
1760651343901:gene_summary <- aggregate(
1760651343902:count ~ gene,
1760651343904:data = treated_data,
1760651343905:FUN  = function(x) c(mean = mean(x), median = median(x))
1760651343907:)
1760651344052:# 5. Simplify format
1760651344057:gene_summary_df <- data.frame(
1760651344059:gene = gene_summary$gene,
1760651344061:mean_count   = gene_summary$count[, "mean"],
1760651344063:median_count = gene_summary$count[, "median"]
1760651344065:)
1760651344206:# 6 Calcolo della media dei conteggi per ciascun gene e condizione
1760651344210:# aggregate() calcola una funzione (mean) per gruppi
1760651344212:gene_condition_means_f <- aggregate(
1760651344213:count ~ gene + condition,   # formula: raggruppa per gene e condition
1760651344215:data = merged_data,         # tabella di partenza
1760651344219:FUN = mean,                 # funzione da applicare
1760651344220:na.rm = TRUE                # ignora eventuali valori mancanti
1760651344222:)
1760651344397:# 7 Ordina i risultati per gene e condition (per leggibilità)
1760651344401:gene_condition_means_f <- gene_condition_means_f[order(gene_condition_means_f$gene,
1760651344403:gene_condition_means_f$condition), ]
1760652188817:# 1 Carico la libreria
1760652188819:library(data.table)
1760652203168:# 1 Carico la libreria
1760652203172:library(data.table)
1760652278114:# 2 Leggo il file come data.table
1760652278117:counts <- fread("project_oct25/bulk_counts_long.csv")
1760652280432:View(counts)
1760652288606:# PARTE 1: Aggiungo la colonna log2 dei conteggi
1760652288611:# -----------------------------------------------------
1760652288613:# := modifica la tabella "in place" (senza crearne una copia)
1760652288616:counts[, log2_count := log2(count)]
1760652556920:View(counts)
1760652627934:#Aggiungo la colonna binaria 'high' (count > 100)
1760652627938:counts[, high := count > 100]
1760652675768:#Aggiungo la colonna binaria 'high' (count > 100)
1760652675772:counts[, high := count > 100]
1760652715727:#Aggiungo la colonna binaria 'high' (count > 100)
1760652715732:counts[, high := count > 100]
1760652721344:View(counts)
1760652915324:# -----------------------------------------------------
1760652915329:# PARTE 3: Sovrascrivo 'high' in modo gene-wise, con questo criterio := (in place)
1760652915331:#per ogni gene verifica se il valore di count è maggiore della mediana di count per quel gene
1760652915338:# (count > median(count) per ciascun gene)
1760652915340:# -----------------------------------------------------
1760652915342:counts[, high := count > median(count), by = gene]  #x ogni gene separatamente
1760652919679:View(counts)
1760652947396:# ==========================================================
1760652947401:# TASK 2 – data.frame version
1760652947403:# ==========================================================
1760652947407:# 1. Import
1760652947408:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760652947429:# 2. Add log2(count + 1) column
1760652947430:counts$log2_count <- log2(counts$count + 1)
1760652947433:# 3. Add binary flag 'high' (count > 100)
1760652947434:counts$high <- counts$count > 100
1760652947436:# 4. Overwrite 'high' using gene-wise median threshold
1760652947436:#    Qui usiamo tapply() per calcolare la mediana per gene,
1760652947437:#    poi combiniamo i risultati in un vettore logico della stessa lunghezza
1760652947438:medians_by_gene <- tapply(counts$count, counts$gene, median)
1760652947482:counts$high <- counts$count > medians_by_gene[counts$gene]
1760652956111:# ==========================================================
1760652956114:# TASK 2 – data.frame version
1760652956116:# ==========================================================
1760652956119:# 1. Import
1760652956121:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760652956160:# 2. Add log2(count + 1) column
1760652956162:counts$log2_count <- log2(counts$count + 1)
1760652956165:# 3. Add binary flag 'high' (count > 100)
1760652956166:counts$high <- counts$count > 100
1760652956169:# 4. Overwrite 'high' using gene-wise median threshold
1760652956171:#    Qui usiamo tapply() per calcolare la mediana per gene,
1760652956172:#    poi combiniamo i risultati in un vettore logico della stessa lunghezza
1760652956174:medians_by_gene <- tapply(counts$count, counts$gene, median)
1760652956233:counts$high <- counts$count > medians_by_gene[counts$gene]
1760652958032:View(counts)
1760652962876:View(counts)
1760653750442:#Goal: Speed up joins/lookups.
1760653750446:#Data: sample_metadata.csv, bulk_counts_long.csv
1760653750447:#Tasks:
1760653750449:#• setkey() on sample_metadata by sample_id; equi-join into the long counts.
1760653750453:#• Add a secondary index on (gene, sample_id) in the counts table, then benchmark a subset query before/after.
1760653750457:# 1 Carico la libreria
1760653750457:library(data.table)
1760653750459:# 2 Leggo i file CSV come data.table
1760653750460:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760653750465:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760653750470:# PARTE 1: Imposto la chiave su sample_metadata
1760653750471:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1760653750472:setkey(meta, sample_id)
1760653769160:# 1 Carico la libreria
1760653769162:library(data.table)
1760653769653:# 2 Leggo i file CSV come data.table
1760653769678:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760653770109:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760653770679:# PARTE 1: Imposto la chiave su sample_metadata
1760653770681:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1760653770683:setkey(meta, sample_id)
1760653788016:# PARTE 1: Imposto la chiave su sample_metadata
1760653788020:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1760653788022:setkey(sample_meta, sample_id)
1760653789271:# PARTE 2: Faccio una join tra metadata e counts
1760653789274:# Dopo aver impostato la chiave, la join è automatica e più veloce
1760653789278:join_data <- sample_meta[counts, on = "sample_id"] #prende meta e attacca counts in base al sample ID
1760653798892:# 1 Carico la libreria
1760653798897:library(data.table)
1760653799348:# 2 Leggo i file CSV come data.table
1760653799352:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760653800421:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760653801186:# PARTE 1: Imposto la chiave su sample_metadata
1760653801191:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1760653801193:setkey(sample_meta, sample_id)
1760653802301:# PARTE 2: Faccio una join tra metadata e counts
1760653802304:# Dopo aver impostato la chiave, la join è automatica e più veloce
1760653802306:join_data <- sample_meta[counts, on = "sample_id"] #prende meta e attacca counts in base al sample ID
1760653830163:# PARTE 2: Faccio una join tra metadata e counts
1760653830166:# Dopo aver impostato la chiave, la join è automatica e più veloce
1760653830167:join_data <- sample_meta[bulk_counts, on = "sample_id"] #prende meta e attacca counts in base al sample ID
1760653833562:View(join_data)
1760653840896:# PARTE 3: Creo un indice secondario su (gene, sample_id)
1760653840901:# L’indice serve per accelerare query che filtrano per gene e sample
1760653840903:setindex(counts, gene, sample_id)
1760653852258:# PARTE 3: Creo un indice secondario su (gene, sample_id)
1760653852263:# L’indice serve per accelerare query che filtrano per gene e sample
1760653852265:setindex(bulk_counts, gene, sample_id)
1760653855177:# PARTE 4: Benchmark — confronto prima e dopo l’indice
1760653855179:# Esempio: voglio estrarre tutte le righe per un certo gene
1760653855181:gene_call <- "GENE_0051"
1760653858465:sample_chosen <- "S20"
1760653860674:# Prima (senza usare l’indice)
1760653860677:system.time({
1760653860680:subset_no_index <- counts[gene == gene_call & sample_id == sample_chosen]
1760653860681:})
1760653872765:# Prima (senza usare l’indice)
1760653872770:system.time({
1760653872772:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653872774:})
1760653874173:# Dopo (l’indice ora è attivo)
1760653874176:system.time({
1760653874177:subset_with_index <- bulk_counts[gene == gene_name & sample_id == sample_chosen]
1760653874179:})
1760653901725:# 1 Carico la libreria
1760653901729:library(data.table)
1760653902259:# 2 Leggo i file CSV come data.table
1760653902262:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760653902687:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760653903164:# PARTE 1: Imposto la chiave su sample_metadata
1760653903167:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1760653903168:setkey(sample_meta, sample_id)
1760653903687:# PARTE 2: Faccio una join tra metadata e counts
1760653903690:# Dopo aver impostato la chiave, la join è automatica e più veloce
1760653903692:join_data <- sample_meta[bulk_counts, on = "sample_id"] #prende meta e attacca counts in base al sample ID
1760653904227:# PARTE 3: Creo un indice secondario su (gene, sample_id)
1760653904231:# L’indice serve per accelerare query che filtrano per gene e sample
1760653904233:setindex(bulk_counts, gene, sample_id)
1760653904769:# PARTE 4: Benchmark — confronto prima e dopo l’indice
1760653904776:# Esempio: voglio estrarre tutte le righe per un certo gene
1760653904780:gene_call <- "GENE_0051"
1760653905348:sample_chosen <- "S20"
1760653905940:# Prima (senza usare l’indice)
1760653905947:system.time({
1760653905950:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653905954:})
1760653907218:# Dopo (l’indice ora è attivo)
1760653907221:system.time({
1760653907222:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653907224:})
1760653931012:# Prima (senza usare l’indice)
1760653931016:system.time({
1760653931018:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653931020:})
1760653931888:# Dopo (l’indice ora è attivo)
1760653931893:system.time({
1760653931895:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653931896:})
1760653936065:# Prima (senza usare l’indice)
1760653936068:system.time({
1760653936070:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653936071:})
1760653936869:# Dopo (l’indice ora è attivo)
1760653936873:system.time({
1760653936875:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653936876:})
1760653949159:# Prima (senza usare l’indice)
1760653949161:system.time({
1760653949165:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653949166:})
1760653949689:# Dopo (l’indice ora è attivo)
1760653949694:system.time({
1760653949698:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653949700:})
1760653954150:#Goal: Speed up joins/lookups.
1760653954155:#Data: sample_metadata.csv, bulk_counts_long.csv
1760653954157:#Tasks:
1760653954161:#• setkey() on sample_metadata by sample_id; equi-join into the long counts.
1760653954163:#• Add a secondary index on (gene, sample_id) in the counts table, then benchmark a subset query before/after.
1760653954165:# 1 Carico la libreria
1760653954167:library(data.table)
1760653954170:# 2 Leggo i file CSV come data.table
1760653954171:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760653954178:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760653954180:# PARTE 1: Imposto la chiave su sample_metadata
1760653954181:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1760653954183:setkey(sample_meta, sample_id)
1760653954185:# PARTE 2: Faccio una join tra metadata e counts
1760653954186:# Dopo aver impostato la chiave, la join è automatica e più veloce
1760653954187:join_data <- sample_meta[bulk_counts, on = "sample_id"] #prende meta e attacca counts in base al sample ID
1760653954193:# PARTE 3: Creo un indice secondario su (gene, sample_id)
1760653954194:# L’indice serve per accelerare query che filtrano per gene e sample
1760653954195:setindex(bulk_counts, gene, sample_id)
1760653954197:# PARTE 4: Benchmark — confronto prima e dopo l’indice
1760653954198:# Esempio: voglio estrarre tutte le righe per un certo gene
1760653954199:gene_call <- "GENE_0051"
1760653954200:sample_chosen <- "S20"
1760653954201:# Prima (senza usare l’indice)
1760653954202:system.time({
1760653954203:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653954203:})
1760653954318:# Dopo (l’indice ora è attivo)
1760653954320:system.time({
1760653954321:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653954322:})
1760653960078:#Goal: Speed up joins/lookups.
1760653960082:#Data: sample_metadata.csv, bulk_counts_long.csv
1760653960084:#Tasks:
1760653960085:#• setkey() on sample_metadata by sample_id; equi-join into the long counts.
1760653960086:#• Add a secondary index on (gene, sample_id) in the counts table, then benchmark a subset query before/after.
1760653960088:# 1 Carico la libreria
1760653960090:library(data.table)
1760653960094:# 2 Leggo i file CSV come data.table
1760653960095:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760653960102:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760653960106:# PARTE 1: Imposto la chiave su sample_metadata
1760653960107:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1760653960108:setkey(sample_meta, sample_id)
1760653960110:# PARTE 2: Faccio una join tra metadata e counts
1760653960110:# Dopo aver impostato la chiave, la join è automatica e più veloce
1760653960111:join_data <- sample_meta[bulk_counts, on = "sample_id"] #prende meta e attacca counts in base al sample ID
1760653960116:# PARTE 3: Creo un indice secondario su (gene, sample_id)
1760653960116:# L’indice serve per accelerare query che filtrano per gene e sample
1760653960117:setindex(bulk_counts, gene, sample_id)
1760653960120:# PARTE 4: Benchmark — confronto prima e dopo l’indice
1760653960121:# Esempio: voglio estrarre tutte le righe per un certo gene
1760653960123:gene_call <- "GENE_0051"
1760653960124:sample_chosen <- "S20"
1760653960126:# Prima (senza usare l’indice)
1760653960127:system.time({
1760653960127:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653960128:})
1760653960238:# Dopo (l’indice ora è attivo)
1760653960239:system.time({
1760653960240:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760653960241:})
1760654012127:# 1. Import
1760654012130:counts <- read.csv("project_oct25/bulk_counts_long.csv")
1760654012153:meta   <- read.csv("project_oct25/sample_metadata.csv")
1760654012159:# 2. Join metadata and counts
1760654012160:joined_data <- merge(counts, meta, by = "sample_id")
1760654012213:# 3. Query performance test without indexes
1760654012215:gene_name     <- "GENE_0051"
1760654012216:sample_chosen <- "S20"
1760654012220:system.time({
1760654012223:subset_no_index <- subset(counts, gene == gene_name & sample_id == sample_chosen)
1760654012225:})
1760654012341:# In base R non esiste un vero indice persistente sulle colonne.
1760654012342:# Possiamo solo simulare una "cache" creando un vettore logico o usando subset ripetutamente.
1760654012343:# Il tempo resterà pressoché uguale.
1760654012344:system.time({
1760654012345:subset_with_index <- subset(counts, gene == gene_name & sample_id == sample_chosen)
1760654012346:})
1760654397014:#Goal: Annotate counts with sample and patient info. Data: bulk_counts_long.csv, sample_metadata.csv Tasks:
1760654397021:#• Join and compute per-patient total counts.
1760654397024:#• Find the top 10 genes by average count within each condition.
1760654397027:library(data.table)
1760654397030:# 1. Import
1760654397031:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760654397039:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760654397043:# 2. Join counts + metadata
1760654397045:setkey(bulk_counts, sample_id)
1760654397047:setkey(sample_meta, sample_id)
1760654397049:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760654397053:# 3. Total counts per patient
1760654397054:patient_tot <- join_data[, .(total_count = sum(count)), by = patient_id]
1760654397058:# 4. Mean count per gene and condition
1760654397059:gene_means <- join_data[, .(mean_count = mean(count)), by = .(gene, condition)]
1760654397063:# 5. Top 10 genes (highest mean) within each condition
1760654397063:top10 <- gene_means[
1760654397064:order(condition, -mean_count)
1760654397065:][, head(.SD, 10), by = condition]
1760654397069:#by = condition → significa: “ripeti il comando successivo separatamente per ogni valore di condition”.
1760654397070:#.SD → significa “Subset of Data”: è la porzione della tabella relativa al gruppo attuale
1760654397070:#head(.SD, 10) → prende le prime 10 righe del gruppo (cioè i 10 geni con i valori più alti di mean_count).
1760654401535:View(top10)
1760654425689:# ==========================================================
1760654425692:# TASK 4 – data.frame version
1760654425694:# ==========================================================
1760654425696:# 1. Import
1760654425697:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760654425719:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760654425723:# 2. Join
1760654425724:merged_data <- merge(counts, meta, by = "sample_id")
1760654425765:# 3. Total counts per patient
1760654425766:patient_totals <- aggregate(count ~ patient_id, data = merged_data, FUN = sum)
1760654425790:names(patient_totals)[2] <- "total_count"
1760654425791:# 4. Mean count per gene and condition
1760654425792:gene_means <- aggregate(count ~ gene + condition, data = merged_data, FUN = mean)
1760654425823:names(gene_means)[3] <- "mean_count"
1760654425824:# 5. Top 10 genes by condition
1760654425825:conditions <- unique(gene_means$condition)
1760654425825:top10_by_condition <- data.frame()
1760654425827:for (cond in conditions) {
1760654425828:subset_cond <- subset(gene_means, condition == cond)
1760654425829:subset_cond <- subset_cond[order(-subset_cond$mean_count), ]
1760654425830:top10 <- head(subset_cond, 10)
1760654425833:top10_by_condition <- rbind(top10_by_condition, top10)
1760654425835:}
1760654427682:View(top10_by_condition)
1760654464764:View(top10)
1760654472521:View(top10_by_condition)
1760654491161:#Goal: Annotate counts with sample and patient info. Data: bulk_counts_long.csv, sample_metadata.csv Tasks:
1760654491165:#• Join and compute per-patient total counts.
1760654491167:#• Find the top 10 genes by average count within each condition.
1760654491171:library(data.table)
1760654491174:# 1. Import
1760654491174:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760654491180:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760654491184:# 2. Join counts + metadata
1760654491185:setkey(bulk_counts, sample_id)
1760654491188:setkey(sample_meta, sample_id)
1760654491189:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760654491194:# 3. Total counts per patient
1760654491195:patient_tot <- join_data[, .(total_count = sum(count)), by = patient_id]
1760654491199:# 4. Mean count per gene and condition
1760654491199:gene_means <- join_data[, .(mean_count = mean(count)), by = .(gene, condition)]
1760654491203:# 5. Top 10 genes (highest mean) within each condition
1760654491204:top10 <- gene_means[
1760654491205:order(condition, -mean_count)
1760654491205:][, head(.SD, 10), by = condition]
1760654491209:#by = condition → significa: “ripeti il comando successivo separatamente per ogni valore di condition”.
1760654491209:#.SD → significa “Subset of Data”: è la porzione della tabella relativa al gruppo attuale
1760654491210:#head(.SD, 10) → prende le prime 10 righe del gruppo (cioè i 10 geni con i valori più alti di mean_count).
1760654494070:View(top10)
1760654512322:# ==========================================================
1760654512329:# TASK 4 – data.frame version
1760654512331:# ==========================================================
1760654512333:# 1. Import
1760654512334:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760654512350:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760654512352:# 2. Join
1760654512353:merged_data <- merge(counts, meta, by = "sample_id")
1760654512387:# 3. Total counts per patient
1760654512390:patient_totals <- aggregate(count ~ patient_id, data = merged_data, FUN = sum)
1760654512402:names(patient_totals)[2] <- "total_count"
1760654512403:# 4. Mean count per gene and condition
1760654512404:gene_means <- aggregate(count ~ gene + condition, data = merged_data, FUN = mean)
1760654512441:names(gene_means)[3] <- "mean_count"
1760654512442:# 5. Top 10 genes by condition
1760654512443:conditions <- unique(gene_means$condition)
1760654512444:top10_by_condition <- data.frame()
1760654512447:for (cond in conditions) {
1760654512449:subset_cond <- subset(gene_means, condition == cond)
1760654512450:subset_cond <- subset_cond[order(-subset_cond$mean_count), ]
1760654512451:top10 <- head(subset_cond, 10)
1760654512452:top10_by_condition <- rbind(top10_by_condition, top10)
1760654512453:}
1760654516556:View(top10)
1760654518968:View(top10_by_condition)
1760654547006:#Goal: Annotate counts with sample and patient info. Data: bulk_counts_long.csv, sample_metadata.csv Tasks:
1760654547009:#• Join and compute per-patient total counts.
1760654547011:#• Find the top 10 genes by average count within each condition.
1760654547014:library(data.table)
1760654547018:# 1. Import
1760654547021:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760654547027:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760654547030:# 2. Join counts + metadata
1760654547032:setkey(bulk_counts, sample_id)
1760654547034:setkey(sample_meta, sample_id)
1760654547036:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760654547041:# 3. Total counts per patient
1760654547042:patient_tot <- join_data[, .(total_count = sum(count)), by = patient_id]
1760654547045:# 4. Mean count per gene and condition
1760654547046:gene_means <- join_data[, .(mean_count = mean(count)), by = .(gene, condition)]
1760654547050:# 5. Top 10 genes (highest mean) within each condition
1760654547051:top10 <- gene_means[
1760654547052:order(condition, -mean_count)
1760654547053:][, head(.SD, 10), by = condition]
1760654547056:#by = condition → significa: “ripeti il comando successivo separatamente per ogni valore di condition”.
1760654547056:#.SD → significa “Subset of Data”: è la porzione della tabella relativa al gruppo attuale
1760654547057:#head(.SD, 10) → prende le prime 10 righe del gruppo (cioè i 10 geni con i valori più alti di mean_count).
1760654549616:View(top10)
1760654565119:# ==========================================================
1760654565122:# TASK 4 – data.frame version
1760654565123:# ==========================================================
1760654565127:# 1. Import
1760654565127:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760654565148:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760654565151:# 2. Join
1760654565152:merged_data <- merge(counts, meta, by = "sample_id")
1760654565184:# 3. Total counts per patient
1760654565186:patient_totals <- aggregate(count ~ patient_id, data = merged_data, FUN = sum)
1760654565196:names(patient_totals)[2] <- "total_count"
1760654565200:# 4. Mean count per gene and condition
1760654565201:gene_means <- aggregate(count ~ gene + condition, data = merged_data, FUN = mean)
1760654565230:names(gene_means)[3] <- "mean_count"
1760654565235:# 5. Top 10 genes by condition
1760654565237:conditions <- unique(gene_means$condition)
1760654565238:top10_by_condition <- data.frame()
1760654565240:for (cond in conditions) {
1760654565241:subset_cond <- subset(gene_means, condition == cond)
1760654565241:subset_cond <- subset_cond[order(-subset_cond$mean_count), ]
1760654565242:top10 <- head(subset_cond, 10)
1760654565243:top10_by_condition <- rbind(top10_by_condition, top10)
1760654565243:}
1760654568404:View(top10)
1760654571126:View(top10_by_condition)
1760654580427:#Goal: Annotate counts with sample and patient info. Data: bulk_counts_long.csv, sample_metadata.csv Tasks:
1760654580429:#• Join and compute per-patient total counts.
1760654580432:#• Find the top 10 genes by average count within each condition.
1760654580436:library(data.table)
1760654580444:# 1. Import
1760654580447:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760654580462:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760654580468:# 2. Join counts + metadata
1760654580469:setkey(bulk_counts, sample_id)
1760654580472:setkey(sample_meta, sample_id)
1760654580474:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760654580481:# 3. Total counts per patient
1760654580482:patient_tot <- join_data[, .(total_count = sum(count)), by = patient_id]
1760654580489:# 4. Mean count per gene and condition
1760654580490:gene_means <- join_data[, .(mean_count = mean(count)), by = .(gene, condition)]
1760654580496:# 5. Top 10 genes (highest mean) within each condition
1760654580497:top10 <- gene_means[
1760654580498:order(condition, -mean_count)
1760654580499:][, head(.SD, 10), by = condition]
1760654580505:#by = condition → significa: “ripeti il comando successivo separatamente per ogni valore di condition”.
1760654580506:#.SD → significa “Subset of Data”: è la porzione della tabella relativa al gruppo attuale
1760654580507:#head(.SD, 10) → prende le prime 10 righe del gruppo (cioè i 10 geni con i valori più alti di mean_count).
1760654582457:View(top10)
1760654605534:# ==========================================================
1760654605537:# TASK 4 – data.frame version
1760654605538:# ==========================================================
1760654605540:# 1. Import
1760654605542:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760654605559:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760654605562:# 2. Join
1760654605562:merged_data <- merge(counts, meta, by = "sample_id")
1760654605596:# 3. Total counts per patient
1760654605597:patient_totals <- aggregate(count ~ patient_id, data = merged_data, FUN = sum)
1760654605605:names(patient_totals)[2] <- "total_count"
1760654605606:# 4. Mean count per gene and condition
1760654605607:gene_means <- aggregate(count ~ gene + condition, data = merged_data, FUN = mean)
1760654605644:names(gene_means)[3] <- "mean_count"
1760654605645:# 5. Top 10 genes by condition
1760654605646:conditions <- unique(gene_means$condition)
1760654605647:top10_by_condition <- data.frame()
1760654605649:for (cond in conditions) {
1760654605651:subset_cond <- subset(gene_means, condition == cond)
1760654605652:subset_cond <- subset_cond[order(-subset_cond$mean_count), ]
1760654605654:top10 <- head(subset_cond, 10)
1760654605654:top10_by_condition <- rbind(top10_by_condition, top10)
1760654605655:}
1760654607877:View(top10_by_condition)
1760654741840:library(data.table)
1760654742428:# 1 Carico i file
1760654742431:labs <- fread("project_oct25/clinical_labs.csv")
1760654744474:View(labs)
1760654753187:ref  <- fread("project_oct25/lab_reference_ranges.csv")
1760654754530:View(ref)
1760654850721:?unique
1760655053424:#Goal: Classify values against reference intervals.
1760655053429:#Data: clinical_labs.csv, lab_reference_ranges.csv, plus sample_metadata.csv (for sex proxy if you want to extend)
1760655053431:#Tasks:
1760655053435:#• Treat reference ranges as intervals and label each lab as "normal" vs "out_of_range" using a non-equi join
1760655053436:#(value >= lower & value <= upper).
1760655053437:#• Count abnormal rates by patient and by lab.
1760655053438:library(data.table)
1760655053440:# 1 Carico i file
1760655053441:clinical_labs <- fread("project_oct25/clinical_labs.csv")
1760655053445:lab_ref  <- fread("project_oct25/lab_reference_ranges.csv")
1760655053448:# Unisco le tabelle per aggiungere i range di riferimento
1760655053449:# Dato che i range sono uguali per M e F, li prendo una sola volta
1760655053450:ref_unique <- unique(lab_ref[, .(clinical_lab, lower, upper)])
1760655076972:#Goal: Classify values against reference intervals.
1760655076975:#Data: clinical_labs.csv, lab_reference_ranges.csv, plus sample_metadata.csv (for sex proxy if you want to extend)
1760655076977:#Tasks:
1760655076979:#• Treat reference ranges as intervals and label each lab as "normal" vs "out_of_range" using a non-equi join
1760655076981:#(value >= lower & value <= upper).
1760655076983:#• Count abnormal rates by patient and by lab.
1760655076985:library(data.table)
1760655076987:# 1 Carico i file
1760655076987:clinical_labs <- fread("project_oct25/clinical_labs.csv")
1760655076990:lab_ref  <- fread("project_oct25/lab_reference_ranges.csv")
1760655076994:# Unisco le tabelle per aggiungere i range di riferimento
1760655076995:# Dato che i range sono uguali per M e F, li prendo una sola volta
1760655076997:ref_unique <- unique(lab_ref[, .(clinical_labs, lower, upper)])
1760655077000:#unique returns a data table with duplicated rows removed.
1760655077001:#unique è una funzione che prende la tabella lab_ref e controlla quali sono le differenze nelle colonne lab,
1760655077002:#lower e upper e le salva in ref_unique
1760655077003:# Uso una join per aggiungere a ogni valore clinico i limiti lower e upper del test corrispondente
1760655077003:merged_labs <- merge(clinical_labs, ref_unique, by = "lab")
1760655108555:library(data.table)
1760655108995:# 1 Carico i file
1760655108998:clinical_labs <- fread("project_oct25/clinical_labs.csv")
1760655109426:lab_ref  <- fread("project_oct25/lab_reference_ranges.csv")
1760655110096:# Unisco le tabelle per aggiungere i range di riferimento
1760655110100:# Dato che i range sono uguali per M e F, li prendo una sola volta
1760655110101:ref_unique <- unique(lab_ref[, .(clinical_labs, lower, upper)])
1760655112762:# Uso una join per aggiungere a ogni valore clinico i limiti lower e upper del test corrispondente
1760655112766:merged_labs <- merge(clinical_labs, ref_unique, by = "lab")
1760655124379:View(ref_unique)
1760655127982:View(lab_ref)
1760655129745:View(clinical_labs)
1760655159361:View(lab_ref)
1760655164004:View(clinical_labs)
1760655213739:# Uso una join per aggiungere a ogni valore clinico i limiti lower e upper del test corrispondente
1760655213742:merged_labs <- merge(clinical_labs, ref_unique, by = "lab")
1760655236413:View(clinical_labs)
1760655239316:View(lab_ref)
1760655245077:View(clinical_labs)
1760655257102:# Uso una join per aggiungere a ogni valore clinico i limiti lower e upper del test corrispondente
1760655257105:merged_labs <- merge(labs, ref_unique, by = lab)
1760655278543:# Uso una join per aggiungere a ogni valore clinico i limiti lower e upper del test corrispondente
1760655278548:merged_labs <- merge(clinical_labs, ref_unique, by = lab)
1760655299241:#Goal: Classify values against reference intervals.
1760655299247:#Data: clinical_labs.csv, lab_reference_ranges.csv, plus sample_metadata.csv (for sex proxy if you want to extend)
1760655299249:#Tasks:
1760655299251:#• Treat reference ranges as intervals and label each lab as "normal" vs "out_of_range" using a non-equi join (value >= lower & value <= upper).
1760655299252:#• Count abnormal rates by patient and by lab.
1760655299258:# =====================================================
1760655299259:# TASK 5: Classify values against reference intervals
1760655299260:# =====================================================
1760655299262:library(data.table)
1760655299265:# 1 Carico i file
1760655299267:labs <- fread("project_oct25/clinical_labs.csv")
1760655299271:ref  <- fread("project_oct25/lab_reference_ranges.csv")
1760655299274:# -----------------------------------------------------
1760655299275:# PARTE 1: Unisco le tabelle per aggiungere i range di riferimento
1760655299276:# -----------------------------------------------------
1760655299277:# Dato che i range sono uguali per M e F, li prendo una sola volta
1760655299278:ref_unique <- unique(ref[, .(lab, lower, upper)])
1760655299282:#unique è una funzione che prende la tabella ref e controlla quali sono le differenze nelle colonne lab, lower e upper e le salva in ref_unique
1760655299284:# Uso una join per aggiungere a ogni valore clinico i limiti lower e upper del test corrispondente
1760655299284:merged_labs <- merge(labs, ref_unique, by = "lab")
1760655299288:# -----------------------------------------------------
1760655299289:# PARTE 2: Classifico i valori come "normal" o "out_of_range"
1760655299290:# -----------------------------------------------------
1760655299291:merged_labs[, status := ifelse(value >= lower & value <= upper, "normal", "out_of_range")]
1760655299293:#all'interno di merged labs, a dx, metti status con questa condizione, rispettivamente, se out o normale e le salva in una colonna che è status
1760655299295:# -----------------------------------------------------
1760655299295:# PARTE 3: Calcolo la percentuale di risultati fuori range per paziente
1760655299296:# -----------------------------------------------------
1760655299297:abnormal_by_patient <- merged_labs[, .(
1760655299298:total_tests = .N,                                 # numero totale di test per paziente
1760655299299:out_of_range = sum(status == "out_of_range")      # quanti sono fuori range
1760655299300:), by = patient_id]
1760655299303:# -----------------------------------------------------
1760655299303:# PARTE 4: Calcolo i risultati fuori range per tipo di test
1760655299304:# -----------------------------------------------------
1760655299305:abnormal_by_lab <- merged_labs[, .(
1760655299305:total_tests = .N,
1760655299306:out_of_range = sum(status == "out_of_range")
1760655299307:), by = lab]
1760655299310:# -----------------------------------------------------
1760655299311:# PARTE 5: Mostro i risultati
1760655299312:# -----------------------------------------------------
1760655299312:cat("\n--- Test fuori range per paziente ---\n")
1760655299313:print(abnormal_by_patient)
1760655299318:cat("\n--- Test fuori range per tipo di test ---\n")
1760655299319:print(abnormal_by_lab)
1760655427216:#Goal: Classify values against reference intervals.
1760655427222:#Data: clinical_labs.csv, lab_reference_ranges.csv, plus sample_metadata.csv (for sex proxy if you want to extend)
1760655427224:#Tasks:
1760655427227:#• Treat reference ranges as intervals and label each lab as "normal" vs "out_of_range" using a non-equi join
1760655427229:#(value >= lower & value <= upper).
1760655427229:#• Count abnormal rates by patient and by lab.
1760655427231:library(data.table)
1760655427232:# 1 Carico i file
1760655427233:labs <- fread("project_oct25/clinical_labs.csv")
1760655427236:ref  <- fread("project_oct25/lab_reference_ranges.csv")
1760655427238:# Unisco le tabelle per aggiungere i range di riferimento
1760655427239:# Dato che i range sono uguali per M e F, li prendo una sola volta
1760655427240:ref_unique <- unique(ref[, .(lab, lower, upper)])
1760655427242:#unique returns a data table with duplicated rows removed.
1760655427244:#unique è una funzione che prende la tabella lab_ref e controlla quali sono le differenze nelle colonne lab,
1760655427245:#lower e upper e le salva in ref_unique
1760655427248:# Uso una join per aggiungere a ogni valore clinico i limiti lower e upper del test corrispondente
1760655427249:merged_labs <- merge(labs, ref_unique, by = "lab")
1760655427252:# -----------------------------------------------------
1760655427253:# PARTE 2: Classifico i valori come "normal" o "out_of_range"
1760655427253:# -----------------------------------------------------
1760655427254:merged_labs[, status := ifelse(value >= lower & value <= upper, "normal", "out_of_range")]
1760655427256:#all'interno di merged labs, a dx, metti status con questa condizione,
1760655427257:#rispettivamente, se out o normale e le salva in una colonna che è status
1760655427259:# -----------------------------------------------------
1760655427260:# PARTE 3: Calcolo la percentuale di risultati fuori range per paziente
1760655427260:# -----------------------------------------------------
1760655427261:abnormal_by_patient <- merged_labs[, .(
1760655427262:total_tests = .N,                                 # numero totale di test per paziente
1760655427262:out_of_range = sum(status == "out_of_range")      # quanti sono fuori range
1760655427263:), by = patient_id]
1760655427265:# -----------------------------------------------------
1760655427266:# PARTE 4: Calcolo i risultati fuori range per tipo di test
1760655427267:# -----------------------------------------------------
1760655427268:abnormal_by_lab <- merged_labs[, .(
1760655427268:total_tests = .N,
1760655427269:out_of_range = sum(status == "out_of_range")
1760655427269:), by = lab]
1760655433935:View(merged_labs)
1760655532484:# 1. Import
1760655532489:labs <- read.csv("project_oct25/clinical_labs.csv")
1760655532497:ref  <- read.csv("project_oct25/lab_reference_ranges.csv")
1760655532500:# 2. Keep unique reference intervals
1760655532501:ref_unique <- unique(ref[, c("lab", "lower", "upper")])
1760655532507:# 3. Join
1760655532508:merged_labs <- merge(labs, ref_unique, by = "lab")
1760655532511:# 4. Classify as normal/out_of_range
1760655532512:merged_labs$status <- ifelse(merged_labs$value >= merged_labs$lower &
1760655532512:merged_labs$value <= merged_labs$upper,
1760655532513:"normal", "out_of_range")
1760655532515:# 5. Summaries
1760655532516:abnormal_by_patient <- aggregate(status ~ patient_id, data = merged_labs,
1760655532516:FUN = function(x) {
1760655532517:total <- length(x)
1760655532518:out   <- sum(x == "out_of_range")
1760655532519:c(total_tests = total, out_of_range = out)
1760655532519:})
1760655532528:# split matrix-like column into two numeric columns
1760655532528:abnormal_by_patient$total_tests  <- abnormal_by_patient$status[, "total_tests"]
1760655532529:abnormal_by_patient$out_of_range <- abnormal_by_patient$status[, "out_of_range"]
1760655532530:abnormal_by_patient$status <- NULL
1760655532531:abnormal_by_lab <- aggregate(status ~ lab, data = merged_labs,
1760655532532:FUN = function(x) {
1760655532533:total <- length(x)
1760655532533:out   <- sum(x == "out_of_range")
1760655532534:c(total_tests = total, out_of_range = out)
1760655532535:})
1760655532542:abnormal_by_lab$total_tests  <- abnormal_by_lab$status[, "total_tests"]
1760655532543:abnormal_by_lab$out_of_range <- abnormal_by_lab$status[, "out_of_range"]
1760655532544:abnormal_by_lab$status <- NULL
1760655540355:View(abnormal_by_lab)
1760655544407:View(abnormal_by_patient)
1760655562213:#Goal: Classify values against reference intervals.
1760655562217:#Data: clinical_labs.csv, lab_reference_ranges.csv, plus sample_metadata.csv (for sex proxy if you want to extend)
1760655562219:#Tasks:
1760655562222:#• Treat reference ranges as intervals and label each lab as "normal" vs "out_of_range" using a non-equi join
1760655562226:#(value >= lower & value <= upper).
1760655562227:#• Count abnormal rates by patient and by lab.
1760655562230:library(data.table)
1760655562232:# 1 Carico i file
1760655562233:labs <- fread("project_oct25/clinical_labs.csv")
1760655562236:ref  <- fread("project_oct25/lab_reference_ranges.csv")
1760655562241:# Unisco le tabelle per aggiungere i range di riferimento
1760655562242:# Dato che i range sono uguali per M e F, li prendo una sola volta
1760655562243:ref_unique <- unique(ref[, .(lab, lower, upper)])
1760655562245:#unique returns a data table with duplicated rows removed.
1760655562246:#unique è una funzione che prende la tabella lab_ref e controlla quali sono le differenze nelle colonne lab,
1760655562247:#lower e upper e le salva in ref_unique
1760655562249:# Uso una join per aggiungere a ogni valore clinico i limiti lower e upper del test corrispondente
1760655562250:merged_labs <- merge(labs, ref_unique, by = "lab")
1760655562254:# -----------------------------------------------------
1760655562254:# PARTE 2: Classifico i valori come "normal" o "out_of_range"
1760655562255:# -----------------------------------------------------
1760655562256:merged_labs[, status := ifelse(value >= lower & value <= upper, "normal", "out_of_range")]
1760655562258:#all'interno di merged labs, a dx, metti status con questa condizione,
1760655562259:#rispettivamente, se out o normale e le salva in una colonna che è status
1760655562260:# -----------------------------------------------------
1760655562260:# PARTE 3: Calcolo la percentuale di risultati fuori range per paziente
1760655562261:# -----------------------------------------------------
1760655562262:abnormal_by_patient <- merged_labs[, .(
1760655562262:total_tests = .N,                                 # numero totale di test per paziente
1760655562263:out_of_range = sum(status == "out_of_range")      # quanti sono fuori range
1760655562263:), by = patient_id]
1760655562266:# -----------------------------------------------------
1760655562267:# PARTE 4: Calcolo i risultati fuori range per tipo di test
1760655562268:# -----------------------------------------------------
1760655562269:abnormal_by_lab <- merged_labs[, .(
1760655562270:total_tests = .N,
1760655562271:out_of_range = sum(status == "out_of_range")
1760655562272:), by = lab]
1760655564066:View(abnormal_by_lab)
1760655566172:View(abnormal_by_patient)
1760655573319:# 1. Import
1760655573322:labs <- read.csv("project_oct25/clinical_labs.csv")
1760655573330:ref  <- read.csv("project_oct25/lab_reference_ranges.csv")
1760655573334:# 2. Keep unique reference intervals
1760655573336:ref_unique <- unique(ref[, c("lab", "lower", "upper")])
1760655573340:# 3. Join
1760655573340:merged_labs <- merge(labs, ref_unique, by = "lab")
1760655573346:# 4. Classify as normal/out_of_range
1760655573347:merged_labs$status <- ifelse(merged_labs$value >= merged_labs$lower &
1760655573348:merged_labs$value <= merged_labs$upper,
1760655573349:"normal", "out_of_range")
1760655573352:# 5. Summaries
1760655573353:abnormal_by_patient <- aggregate(status ~ patient_id, data = merged_labs,
1760655573354:FUN = function(x) {
1760655573355:total <- length(x)
1760655573356:out   <- sum(x == "out_of_range")
1760655573357:c(total_tests = total, out_of_range = out)
1760655573358:})
1760655573366:# split matrix-like column into two numeric columns
1760655573367:abnormal_by_patient$total_tests  <- abnormal_by_patient$status[, "total_tests"]
1760655573367:abnormal_by_patient$out_of_range <- abnormal_by_patient$status[, "out_of_range"]
1760655573368:abnormal_by_patient$status <- NULL
1760655573369:abnormal_by_lab <- aggregate(status ~ lab, data = merged_labs,
1760655573370:FUN = function(x) {
1760655573371:total <- length(x)
1760655573372:out   <- sum(x == "out_of_range")
1760655573373:c(total_tests = total, out_of_range = out)
1760655573374:})
1760655573380:abnormal_by_lab$total_tests  <- abnormal_by_lab$status[, "total_tests"]
1760655573381:abnormal_by_lab$out_of_range <- abnormal_by_lab$status[, "out_of_range"]
1760655573382:abnormal_by_lab$status <- NULL
1760655587590:#Goal: Classify values against reference intervals.
1760655587595:#Data: clinical_labs.csv, lab_reference_ranges.csv, plus sample_metadata.csv (for sex proxy if you want to extend)
1760655587602:#Tasks:
1760655587607:#• Treat reference ranges as intervals and label each lab as "normal" vs "out_of_range" using a non-equi join
1760655587608:#(value >= lower & value <= upper).
1760655587609:#• Count abnormal rates by patient and by lab.
1760655587610:library(data.table)
1760655587612:# 1 Carico i file
1760655587613:labs <- fread("project_oct25/clinical_labs.csv")
1760655587619:ref  <- fread("project_oct25/lab_reference_ranges.csv")
1760655587623:# Unisco le tabelle per aggiungere i range di riferimento
1760655587623:# Dato che i range sono uguali per M e F, li prendo una sola volta
1760655587624:ref_unique <- unique(ref[, .(lab, lower, upper)])
1760655587627:#unique returns a data table with duplicated rows removed.
1760655587628:#unique è una funzione che prende la tabella lab_ref e controlla quali sono le differenze nelle colonne lab,
1760655587628:#lower e upper e le salva in ref_unique
1760655587630:# Uso una join per aggiungere a ogni valore clinico i limiti lower e upper del test corrispondente
1760655587630:merged_labs <- merge(labs, ref_unique, by = "lab")
1760655587633:# -----------------------------------------------------
1760655587634:# PARTE 2: Classifico i valori come "normal" o "out_of_range"
1760655587634:# -----------------------------------------------------
1760655587635:merged_labs[, status := ifelse(value >= lower & value <= upper, "normal", "out_of_range")]
1760655587637:#all'interno di merged labs, a dx, metti status con questa condizione,
1760655587637:#rispettivamente, se out o normale e le salva in una colonna che è status
1760655587638:# -----------------------------------------------------
1760655587639:# PARTE 3: Calcolo la percentuale di risultati fuori range per paziente
1760655587640:# -----------------------------------------------------
1760655587641:abnormal_by_patient <- merged_labs[, .(
1760655587641:total_tests = .N,                                 # numero totale di test per paziente
1760655587642:out_of_range = sum(status == "out_of_range")      # quanti sono fuori range
1760655587643:), by = patient_id]
1760655587645:# -----------------------------------------------------
1760655587646:# PARTE 4: Calcolo i risultati fuori range per tipo di test
1760655587646:# -----------------------------------------------------
1760655587647:abnormal_by_lab <- merged_labs[, .(
1760655587647:total_tests = .N,
1760655587648:out_of_range = sum(status == "out_of_range")
1760655587649:), by = lab]
1760697100454:#TASK 6: Nearest-time matching of vitals to lab draws
1760697100458:# =====================================================
1760697100461:library(data.table)
1760697101111:# 1. Carico i dati
1760697101114:labs <- fread("project_oct25/clinical_labs.csv")
1760697103008:vitals <- fread("project_oct25/vitals_time_series.csv")
1760697104791:View(labs)
1760697105470:View(vitals)
1760697408251:# 2. Preparo le tabelle e ordina i dati nel tempo
1760697408253:labs[, time_iso := as.POSIXct(time_iso)]
1760697412287:View(labs)
1760697416159:vitals[, time_iso := as.POSIXct(time_iso)]
1760697417429:View(vitals)
1760697432457:#ordinare le righe per paziente e per tempo serve per i join temporali
1760697432460:setorder(labs, patient_id, time_iso)
1760697433248:setorder(vitals, patient_id, time_iso)
1760697443443:# Salvo il tempo del lab in una nuova colonna PRIMA del join
1760697443446:labs[, lab_time := time_iso]
1760697444594:View(labs)
1760697451800:#importante per il join
1760697451805:setkey(labs, patient_id, time_iso)
1760697453581:setkey(vitals, patient_id, time_iso)
1760697494904:# 3. Trovo l'HR più vicino
1760697494908:vitals_hr <- vitals[vital == "HR", .(patient_id, time_iso, value)]
1760697495516:setnames(vitals_hr, "value", "nearest_HR")
1760697496093:# SALVO IL TEMPO DELL'HR PRIMA DEL JOIN!
1760697496096:vitals_hr[, hr_time := time_iso]
1760697497133:setkey(vitals_hr, patient_id, time_iso)
1760697497946:labs_with_hr <- vitals_hr[labs, roll = "nearest"]
1760697498622:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1760697500301:# 4. Trovo l'SBP più vicino
1760697500305:vitals_sbp <- vitals[vital == "SBP", .(patient_id, time_iso, value)]
1760697500916:setnames(vitals_sbp, "value", "nearest_SBP")
1760697501548:# SALVO IL TEMPO DELL'SBP PRIMA DEL JOIN!
1760697501552:vitals_sbp[, sbp_time := time_iso]
1760697502581:setkey(vitals_sbp, patient_id, time_iso)
1760697503402:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1760697506004:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1760697506955:# 5. Mostro i risultati
1760697506958:cat("\n--- Primi risultati: lab con vitals più vicini ---\n")
1760697516244:print(head(labs_with_vitals[, .(patient_id, lab, lab_time, nearest_HR, hr_time, hr_lag_minutes, nearest_SBP, sbp_time, sbp_lag_minutes)], 20))
1760697517124:# 6. Analisi CRP
1760697517128:crp_data <- labs_with_vitals[lab == "CRP"]
1760697530064:cor_crp_hr <- crp_data[!is.na(nearest_HR), .(
1760697530069:correlation_CRP_HR = cor(value, nearest_HR, use = "complete.obs")
1760697530071:), by = patient_id]
1760698087747:#TASK 6: Nearest-time matching of vitals to lab draws
1760698087750:# =====================================================
1760698087751:library(data.table)
1760698089120:# 1. Carico i dati
1760698089122:labs <- fread("project_oct25/clinical_labs.csv")
1760698089853:vitals <- fread("project_oct25/vitals_time_series.csv")
1760698092513:View(labs)
1760698095040:View(vitals)
1760698099270:# 2. Preparo le tabelle e converte le date in un formato tempo che R può confrontare
1760698099274:labs[, time_iso := as.POSIXct(time_iso)]
1760698101143:vitals[, time_iso := as.POSIXct(time_iso)]
1760698103060:View(labs)
1760698105397:View(vitals)
1760698110574:#ordina i dati per paziente e per tempo, serve per i join temporali
1760698110577:setorder(labs, patient_id, time_iso)
1760698111319:setorder(vitals, patient_id, time_iso)
1760698114339:View(labs)
1760698115544:View(vitals)
1760698122104:# Salvo il tempo del laboratorio, creando una nuova colonna lab_time con l'orario del prelievo
1760698122108:labs[, lab_time := time_iso]
1760698125549:#imposto le chiavi, importante per il join
1760698125553:setkey(labs, patient_id, time_iso)
1760698126008:setkey(vitals, patient_id, time_iso)
1760698127388:View(labs)
1760698134181:# 3. Trovo l'HR più vicino
1760698134184:vitals_hr <- vitals[vital == "HR", .(patient_id, time_iso, value)] #prendo solo le righe dei HR
1760698135517:View(vitals_hr)
1760698143601:setnames(vitals_hr, "value", "nearest_HR") #rinomino la colonna value in nearest HR
1760698144942:View(vitals_hr)
1760698152891:# SALVO IL TEMPO DELL'HR PRIMA DEL JOIN!
1760698152893:vitals_hr[, hr_time := time_iso] #salvo l'ora della misura HR
1760698153567:setkey(vitals_hr, patient_id, time_iso)
1760698154677:View(vitals_hr)
1760698177948:#TASK 6: Nearest-time matching of vitals to lab draws
1760698177951:# =====================================================
1760698177952:library(data.table)
1760698178261:# 1. Carico i dati
1760698178264:labs <- fread("project_oct25/clinical_labs.csv")
1760698179215:vitals <- fread("project_oct25/vitals_time_series.csv")
1760698180281:# 2. Preparo le tabelle e converte le date in un formato tempo che R può confrontare
1760698180284:labs[, time_iso := as.POSIXct(time_iso)]
1760698181952:vitals[, time_iso := as.POSIXct(time_iso)]
1760698182406:#ordina i dati per paziente e per tempo, serve per i join temporali
1760698182408:setorder(labs, patient_id, time_iso)
1760698187706:View(labs)
1760698193365:setorder(vitals, patient_id, time_iso)
1760698194908:# Salvo il tempo del laboratorio, creando una nuova colonna lab_time con l'orario del prelievo
1760698194912:labs[, lab_time := time_iso]
1760698196535:View(labs)
1760698205867:#imposto le chiavi, importante per il join
1760698205871:setkey(labs, patient_id, time_iso)
1760698206570:setkey(vitals, patient_id, time_iso)
1760698210363:# 3. Trovo l'HR più vicino
1760698210365:vitals_hr <- vitals[vital == "HR", .(patient_id, time_iso, value)] #prendo solo le righe dei HR
1760698214832:View(vitals_hr)
1760698218570:setnames(vitals_hr, "value", "nearest_HR") #rinomino la colonna value in nearest HR
1760698219656:# SALVO IL TEMPO DELL'HR PRIMA DEL JOIN!
1760698219661:vitals_hr[, hr_time := time_iso] #salvo l'ora della misura HR
1760698220343:setkey(vitals_hr, patient_id, time_iso)
1760698222435:View(vitals_hr)
1760698229191:labs_with_hr <- vitals_hr[labs, roll = "nearest"] #rolling join
1760698230588:View(labs_with_hr)
1760698240769:#per ogni esame di lab, trova il battito HR più vicino nel tempo x lo stesso paziente
1760698240773:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1760698242907:View(labs_with_hr)
1760698260250:# 4. Trovo l'SBP più vicino, esattamente lo stesso per pressione
1760698260253:vitals_sbp <- vitals[vital == "SBP", .(patient_id, time_iso, value)]
1760698260410:setnames(vitals_sbp, "value", "nearest_SBP")
1760698260607:# SALVO IL TEMPO DELL'SBP PRIMA DEL JOIN!
1760698260622:vitals_sbp[, sbp_time := time_iso]
1760698262846:setkey(vitals_sbp, patient_id, time_iso)
1760698287068:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1760698287865:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1760698288729:# 6. Analisi CRP: filtra solo le righe dove il lab è CRP
1760698288733:crp_data <- labs_with_vitals[lab == "CRP"]
1760698289535:#per ogni paziente (by sample id) calcola la correlazione tra CRP e battito e CRP e pressione
1760698289541:#complete.obs: ignora le righe con dati mancanti
1760698289542:cor_crp_hr <- crp_data[!is.na(nearest_HR), .(
1760698289543:correlation_CRP_HR = cor(value, nearest_HR, use = "complete.obs")
1760698289545:), by = patient_id]
1760698290865:cor_crp_sbp <- crp_data[!is.na(nearest_SBP), .(
1760698290869:correlation_CRP_SBP = cor(value, nearest_SBP, use = "complete.obs")
1760698290871:), by = patient_id]
1760698324702:# ==========================================================
1760698324705:# TASK 6 – data.frame version
1760698324707:# ==========================================================
1760698324712:# 1. Import
1760698324714:labs   <- read.csv("project_oct25/clinical_labs.csv")
1760698324717:vitals <- read.csv("project_oct25/vitals_time_series.csv")
1760698324722:# 2. Convert to POSIXct
1760698324723:labs$time_iso   <- as.POSIXct(labs$time_iso)
1760698324727:vitals$time_iso <- as.POSIXct(vitals$time_iso)
1760698324732:# 3. Join nearest HR/SBP manually (loop-based)
1760698324733:nearest_match <- function(lab_df, vitals_df, vital_type) {
1760698324734:vitals_sub <- vitals_df[vitals_df$vital == vital_type, ]
1760698324734:results <- list()
1760698324735:for (i in seq_len(nrow(lab_df))) {
1760698324736:pid <- lab_df$patient_id[i]
1760698324736:time <- lab_df$time_iso[i]
1760698324737:v_sub <- vitals_sub[vitals_sub$patient_id == pid, ]
1760698324738:if (nrow(v_sub) > 0) {
1760698324739:idx <- which.min(abs(difftime(v_sub$time_iso, time, units = "mins")))
1760698324740:results[[i]] <- v_sub[idx, c("value", "time_iso")]
1760698324741:} else {
1760698324742:results[[i]] <- data.frame(value = NA, time_iso = NA)
1760698324742:}
1760698324743:}
1760698324744:out <- do.call(rbind, results)
1760698324745:names(out) <- c(paste0("nearest_", vital_type), paste0(vital_type, "_time"))
1760698324746:return(out)
1760698324746:}
1760698324748:# 4. Attach nearest HR and SBP
1760698324748:hr_data  <- nearest_match(labs, vitals, "HR")
1760698324911:sbp_data <- nearest_match(labs, vitals, "SBP")
1760698325067:labs_with_vitals <- cbind(labs, hr_data, sbp_data)
1760698325069:labs_with_vitals$hr_lag_minutes  <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$HR_time, units = "mins"))
1760698325070:labs_with_vitals$sbp_lag_minutes <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$SBP_time, units = "mins"))
1760698325072:# 5. Correlation per patient (CRP only) — robust version in base R
1760698325073:crp_data <- subset(labs_with_vitals, lab == "CRP")
1760698325075:# Split by patient_id
1760698325076:patients_list <- split(crp_data, crp_data$patient_id)
1760698325082:# Function to compute correlation safely
1760698325083:safe_cor <- function(df, col_x = "value", col_y = "nearest_HR") {
1760698325084:if (nrow(df) < 2) return(NA_real_)           # meno di 2 osservazioni -> NA
1760698325085:x <- df[[col_x]]
1760698325086:y <- df[[col_y]]
1760698325087:# keep only pairs non-NA
1760698325087:ok <- !is.na(x) & !is.na(y)
1760698325088:if (sum(ok) < 2) return(NA_real_)            # meno di 2 coppie valide -> NA
1760698325089:return(cor(x[ok], y[ok], use = "complete.obs"))
1760698325089:}
1760698325091:# Calcola correlazione CRP vs HR per ogni paziente
1760698325091:cor_crp_hr <- data.frame(
1760698325092:patient_id = names(patients_list),
1760698325093:correlation_CRP_HR = sapply(patients_list, safe_cor, col_x = "value", col_y = "nearest_HR"),
1760698325094:row.names = NULL,
1760698325095:stringsAsFactors = FALSE
1760698325095:)
1760698325120:# Calcola correlazione CRP vs SBP per ogni paziente
1760698325121:cor_crp_sbp <- data.frame(
1760698325122:patient_id = names(patients_list),
1760698325123:correlation_CRP_SBP = sapply(patients_list, safe_cor, col_x = "value", col_y = "nearest_SBP"),
1760698325124:row.names = NULL,
1760698325125:stringsAsFactors = FALSE
1760698325126:)
1760703534883:#Goal: Slice genomics windows efficiently. Data: atac_peaks.bed.csv
1760703534890:#Tasks:
1760703534894:#• Extract peaks on chr2 with start between 2‚Äì4 Mb.
1760703534896:#• Among those peaks, return the top 50 by score after setorder() (descending)
1760703534897:# Carico la libreria
1760703534898:library(data.table)
1760703534900:# Leggo il file dei picchi ATAC
1760703534900:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1760703534909:# Filtro i picchi su chr2 e nella finestra 2–4 Mb
1760703534911:# Nota: 1 Mb = 1.000.000 basi
1760703534912:subset_peaks <- peaks[chr == "chr2" & start >= 2000000 & start <= 4000000]
1760703534925:#Ordino i picchi per punteggio decrescente
1760703534926:subset_peaks <- setorder(subset_peaks, -score)
1760703534929:#Prendo i primi 50 picchi
1760703534930:top50_peaks <- head(subset_peaks, 50)
1760703545154:# ==========================================================
1760703545157:# TASK 7 – data.frame version
1760703545158:# ==========================================================
1760703545160:peaks <- read.csv("project_oct25/atac_peaks.bed.csv", stringsAsFactors = FALSE)
1760703545184:subset_peaks <- subset(peaks, chr == "chr2" & start >= 2000000 & start <= 4000000)
1760703545189:subset_peaks <- subset_peaks[order(-subset_peaks$score), ]
1760703545191:top50_peaks <- head(subset_peaks, 50)
1760703545196:cat("\n--- Top 50 picchi su chr2 (2–4 Mb) ---\n")
1760703545199:print(top50_peaks)
1760703547129:View(top50_peaks)
1760703557242:#Goal: Slice genomics windows efficiently. Data: atac_peaks.bed.csv
1760703557246:#Tasks:
1760703557248:#• Extract peaks on chr2 with start between 2‚Äì4 Mb.
1760703557250:#• Among those peaks, return the top 50 by score after setorder() (descending)
1760703557254:# Carico la libreria
1760703557256:library(data.table)
1760703557257:# Leggo il file dei picchi ATAC
1760703557259:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1760703557264:# Filtro i picchi su chr2 e nella finestra 2–4 Mb
1760703557265:# Nota: 1 Mb = 1.000.000 basi
1760703557266:subset_peaks <- peaks[chr == "chr2" & start >= 2000000 & start <= 4000000]
1760703557267:#Ordino i picchi per punteggio decrescente
1760703557268:subset_peaks <- setorder(subset_peaks, -score)
1760703557271:#Prendo i primi 50 picchi
1760703557272:top50_peaks <- head(subset_peaks, 50)
1760703558383:View(top50_peaks)
1760703612053:# ==========================================================
1760703612058:# TASK 8 – data.table version
1760703612061:# ==========================================================
1760703612064:library(data.table)
1760703612066:counts <- fread("project_oct25/bulk_counts_long.csv")
1760703612079:meta   <- fread("project_oct25/sample_metadata.csv")
1760703612084:merged <- counts[meta, on = "sample_id"]
1760703612093:stats_by_gene_condition <- merged[, .(
1760703612094:mean_count   = mean(count),
1760703612094:median_count = median(count),
1760703612095:Q1           = quantile(count, 0.25, type = 2),
1760703612095:Q3           = quantile(count, 0.75, type = 2)
1760703612096:), by = .(gene, condition)]
1760703612601:treated_means <- stats_by_gene_condition[condition == "treated", .(gene, treated_mean = mean_count)]
1760703612608:control_means <- stats_by_gene_condition[condition == "control", .(gene, control_mean = mean_count)]
1760703612612:means_wide <- merge(treated_means, control_means, by = "gene", all = FALSE)
1760703612615:kept_genes <- means_wide[treated_mean >= 2 * control_mean]
1760703647986:#Goal: Multi-column operations per group.
1760703647989:#Data: bulk_counts_long.csv, sample_metadata.csv
1760703647994:#Tasks:
1760703647995:#• Compute per-condition robust summary stats for each gene: mean, median, Q1/Q3.
1760703647996:#• Return only genes where treated mean ‚â• 2√ó control mean.
1760703647998:# =====================================================
1760703647999:# TASK 8: Multi-column operations per group (semplice)
1760703648000:# =====================================================
1760703648001:library(data.table)
1760703648002:counts <- fread("project_oct25/bulk_counts_long.csv")
1760703648007:meta   <- fread("project_oct25/sample_metadata.csv")
1760703648009:merged <- counts[meta, on = "sample_id"]
1760703648014:stats_by_gene_condition <- merged[, .(
1760703648015:mean_count   = mean(count),
1760703648015:median_count = median(count),
1760703648016:Q1           = quantile(count, 0.25, type = 2),
1760703648016:Q3           = quantile(count, 0.75, type = 2)
1760703648017:), by = .(gene, condition)]
1760703648655:treated_means <- stats_by_gene_condition[condition == "treated", .(gene, treated_mean = mean_count)]
1760703648662:control_means <- stats_by_gene_condition[condition == "control", .(gene, control_mean = mean_count)]
1760703648669:means_wide <- merge(treated_means, control_means, by = "gene", all = FALSE)
1760703648674:kept_genes <- means_wide[treated_mean >= 2 * control_mean]
1760703665008:View(treated_means)
1760703669181:View(control_means)
1760703789253:library(data.table)
1760703789676:counts <- fread("project_oct25/bulk_counts_long.csv")
1760703790113:meta   <- fread("project_oct25/sample_metadata.csv")
1760703791279:#unione di counts e metadata per avere la colonna 'condition' insieme ai conteggi
1760703791281:merged <- counts[meta, on = "sample_id"]
1760703793272:View(merged)
1760704041447:# ==========================================================
1760704041451:# TASK 8 – data.frame version
1760704041453:# ==========================================================
1760704041456:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760704041472:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760704041474:merged <- merge(counts, meta, by = "sample_id")
1760704041518:stats_by_gene_condition <- aggregate(count ~ gene + condition, data = merged,
1760704041519:FUN = function(x) c(mean = mean(x), median = median(x),
1760704041520:Q1 = quantile(x, 0.25, type = 2),
1760704041521:Q3 = quantile(x, 0.75, type = 2)))
1760704042348:stats_df <- data.frame(
1760704042349:gene = stats_by_gene_condition$gene,
1760704042350:condition = stats_by_gene_condition$condition,
1760704042351:mean_count = stats_by_gene_condition$count[, "mean"],
1760704042351:median_count = stats_by_gene_condition$count[, "median"],
1760704042352:Q1 = stats_by_gene_condition$count[, "Q1.25%"],
1760704042353:Q3 = stats_by_gene_condition$count[, "Q3.75%"]
1760704042354:)
1760704042357:treated <- subset(stats_df, condition == "treated")[, c("gene", "mean_count")]
1760704042358:control <- subset(stats_df, condition == "control")[, c("gene", "mean_count")]
1760704042359:names(treated)[2] <- "treated_mean"
1760704042360:names(control)[2] <- "control_mean"
1760704042362:means_wide <- merge(treated, control, by = "gene")
1760704042366:kept_genes <- subset(means_wide, treated_mean >= 2 * control_mean)
1760704708132:# ==========================================================
1760704708136:# TASK 9 – data.frame version
1760704708137:# ==========================================================
1760704708139:counts_wide <- read.csv("project_oct25/bulk_counts_wide.csv", stringsAsFactors = FALSE)
1760704708150:counts_long <- reshape(counts_wide, varying = names(counts_wide)[-1],
1760704708152:v.names = "count", timevar = "sample_id",
1760704708153:times = names(counts_wide)[-1], idvar = "gene",
1760704708154:direction = "long")
1760704708213:meta <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1760704708215:merged <- merge(counts_long, meta, by = "sample_id")
1760704708252:totals_per_sample <- aggregate(count ~ sample_id, data = merged, sum)
1760704708263:names(totals_per_sample)[2] <- "total_count"
1760704708265:merged <- merge(merged, totals_per_sample, by = "sample_id")
1760704708305:gene_condition_means <- aggregate(count ~ gene + condition, data = merged, mean)
1760704708346:counts_condition_wide <- reshape(gene_condition_means,
1760704708349:timevar = "condition", idvar = "gene",
1760704708350:direction = "wide")
1760704708358:cat("\n--- Tabella finale: media dei conteggi per gene e condizione ---\n")
1760704708360:print(head(counts_condition_wide, 10))
1760704856355:# 1️ Carichiamo la libreria
1760704856358:library(data.table)
1760704856824:# 2 Leggiamo i file
1760704856827:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1760704857470:genes <- fread("project_oct25/gene_annotation.bed.csv")
1760704859506:# -----------------------------------------------------
1760704859512:# PARTE 1: Imposta le chiavi per (chr, start, end)
1760704859514:# -----------------------------------------------------
1760704859518:setkey(peaks, chr, start, end)
1760704860045:setkey(genes, chr, start, end)
1760704866201:# -----------------------------------------------------
1760704866204:# PARTE 2: Trova intersezioni tra picchi e geni
1760704866206:# (non-equi join: regioni che si sovrappongono)
1760704866207:# -----------------------------------------------------
1760704866208:# La condizione di overlap:
1760704866209:# start_peak <= end_gene e end_peak >= start_gene
1760704866210:overlaps <- foverlaps(peaks, genes,
1760704866211:by.x = c("chr", "start", "end"),
1760704866212:by.y = c("chr", "start", "end"),
1760704866213:type = "any", nomatch = 0L)
1760704869077:View(overlaps)
1760704881528:View(overlaps)
1760704909605:# -----------------------------------------------------
1760704909608:# PARTE 3: Calcola la lunghezza di overlap (in basi)
1760704909610:# -----------------------------------------------------
1760704909613:# L'overlap fra due intervalli è: min(end1, end2) - max(start1, start2)
1760704909614:overlaps[, overlap_bp := pmin(end, i.end) - pmax(start, i.start)]
1760704911428:View(overlaps)
1760705116968:#Goal: ATAC-to-gene mapping.
1760705116973:#Data: atac_peaks.bed.csv, gene_annotation.bed.csv
1760705116975:#Tasks:
1760705116977:#• setkey() both on (chr, start, end) and intersect peaks with gene bodies.
1760705116979:#• Count peaks per gene.
1760705116981:#• Compute overlap length (bp) per peak-gene pair and then sum per gene.
1760705116989:#• Return the top 20 genes by total overlapped bp.
1760705116992:# Carichiamo la libreria
1760705116993:library(data.table)
1760705116995:# Leggiamo i file
1760705116996:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1760705117002:genes <- fread("project_oct25/gene_annotation.bed.csv")
1760705117006:# Imposta le chiavi per (chr, start, end)
1760705117007:setkey(peaks, chr, start, end)
1760705117010:setkey(genes, chr, start, end)
1760705117014:# Trova intersezioni tra picchi e geni
1760705117015:# (non-equi join: regioni che si sovrappongono)
1760705117016:# La condizione di overlap:
1760705117017:# start_peak <= end_gene e end_peak >= start_gene
1760705117018:overlaps <- foverlaps(peaks, genes,
1760705117019:by.x = c("chr", "start", "end"),
1760705117020:by.y = c("chr", "start", "end"),
1760705117021:type = "any", nomatch = 0L)
1760705117114:# Calcola la lunghezza di overlap (in basi)
1760705117115:# L'overlap fra due intervalli è: min(end1, end2) - max(start1, start2)
1760705117116:overlaps[, overlap_bp := pmin(end, i.end) - pmax(start, i.start)]
1760705117144:# Mantieni solo le righe con overlap positivo
1760705117145:overlaps <- overlaps[overlap_bp > 0]
1760705117154:# Conta quanti picchi per gene
1760705117155:peaks_per_gene <- overlaps[, .N, by = gene]
1760705117169:setnames(peaks_per_gene, "N", "num_peaks")
1760705117173:# Somma la lunghezza totale di overlap per gene
1760705117174:overlap_sum_per_gene <- overlaps[, .(total_overlap_bp = sum(overlap_bp)), by = gene]
1760705117181:# Ordina per overlap totale (decrescente) e prendi top 20
1760705117183:# -----------------------------------------------------
1760705117184:top20_genes <- overlap_sum_per_gene[order(-total_overlap_bp)][1:20]
1760705282198:# carico la libreria
1760705282201:library(data.table)
1760705282798:# leggo i file
1760705282800:variants <- fread("project_oct25/variants.csv")
1760705283350:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760705284690:View(genes)
1760705286744:View(variants)
1760705302968:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1760705302971:#    (foverlaps lavora con intervalli start-end)
1760705302973:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1760705304713:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1760705305739:View(variants)
1760705325359:# 5) imposto le chiavi per foverlaps: (chr, start, end), requisito per foverlaps utile per velocizzare
1760705325366:setkey(variants, chr, start, end)
1760705325805:setkey(genes,    chr, start, end)
1760705355601:# 6) eseguo l'overlap: trovo per ogni variante i geni che si sovrappongono
1760705355608:#    nomatch = 0L rimuove le varianti senza overlap, che non sovrappongono alcun gene
1760705355611:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1760705382972:# 7) filtro le varianti di alto impatto (impact == "HIGH")
1760705382977:#    normalizzo il valore di impact a maiuscole per sicurezza
1760705382979:overlaps[, impact_upper := toupper(impact)] #normalizzo il campo impact
1760705384686:View(overlaps)
1760705583076:variants <- read.csv("project_oct25/variants.csv", stringsAsFactors = FALSE)
1760705583089:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760705583093:variants$start <- variants$pos
1760705583093:variants$end <- variants$pos
1760705583095:# Overlap manuale
1760705583096:overlaps_list <- lapply(1:nrow(variants), function(i) {
1760705583098:v <- variants[i, ]
1760705583099:gsub <- subset(genes, chr == v$chr & start <= v$end & end >= v$start)
1760705583100:if (nrow(gsub) == 0) return(NULL)
1760705583101:cbind(v, gsub)
1760705583102:})
1760705583829:overlaps <- do.call(rbind, overlaps_list)
1760705583928:overlaps$impact_upper <- toupper(overlaps$impact)
1760705583929:high_overlaps <- subset(overlaps, impact_upper == "HIGH")
1760705583931:high_counts_by_gene_sample <- aggregate(impact_upper ~ gene + sample_id,
1760705583931:data = high_overlaps, FUN = length)
1760705583935:names(high_counts_by_gene_sample)[3] <- "high_variant_count"
1760705583936:high_counts_by_gene <- aggregate(impact_upper ~ gene,
1760705583936:data = high_overlaps, FUN = length)
1760705583939:names(high_counts_by_gene)[2] <- "total_high_variants"
1760705583940:genes_with_high <- unique(high_counts_by_gene$gene)
1760705593863:variants <- read.csv("project_oct25/variants.csv", stringsAsFactors = FALSE)
1760705593876:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760705593881:variants$start <- variants$pos
1760705593883:variants$end <- variants$pos
1760705593884:# Overlap manuale
1760705593886:overlaps_list <- lapply(1:nrow(variants), function(i) {
1760705593886:v <- variants[i, ]
1760705593887:gsub <- subset(genes, chr == v$chr & start <= v$end & end >= v$start)
1760705593888:if (nrow(gsub) == 0) return(NULL)
1760705593889:cbind(v, gsub)
1760705593890:})
1760705594560:overlaps <- do.call(rbind, overlaps_list)
1760705594679:overlaps$impact_upper <- toupper(overlaps$impact)
1760705594680:high_overlaps <- subset(overlaps, impact_upper == "HIGH")
1760705594682:high_counts_by_gene_sample <- aggregate(impact_upper ~ gene + sample_id,
1760705594684:data = high_overlaps, FUN = length)
1760705594688:names(high_counts_by_gene_sample)[3] <- "high_variant_count"
1760705594689:high_counts_by_gene <- aggregate(impact_upper ~ gene,
1760705594691:data = high_overlaps, FUN = length)
1760705594694:names(high_counts_by_gene)[2] <- "total_high_variants"
1760705594695:genes_with_high <- unique(high_counts_by_gene$gene)
1760705609579:variants <- read.csv("project_oct25/variants.csv", stringsAsFactors = FALSE)
1760705610375:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760705610848:variants$start <- variants$pos
1760705611344:variants$end <- variants$pos
1760705611832:# Overlap manuale
1760705611835:overlaps_list <- lapply(1:nrow(variants), function(i) {
1760705611837:v <- variants[i, ]
1760705611839:gsub <- subset(genes, chr == v$chr & start <= v$end & end >= v$start)
1760705611840:if (nrow(gsub) == 0) return(NULL)
1760705611843:cbind(v, gsub)
1760705611845:})
1760705612702:overlaps <- do.call(rbind, overlaps_list)
1760705614161:overlaps$impact_upper <- toupper(overlaps$impact)
1760705614698:high_overlaps <- subset(overlaps, impact_upper == "HIGH")
1760705615221:high_counts_by_gene_sample <- aggregate(impact_upper ~ gene + sample_id,
1760705615223:data = high_overlaps, FUN = length)
1760705615961:names(high_counts_by_gene_sample)[3] <- "high_variant_count"
1760705616453:high_counts_by_gene <- aggregate(impact_upper ~ gene,
1760705616456:data = high_overlaps, FUN = length)
1760705616942:names(high_counts_by_gene)[2] <- "total_high_variants"
1760705617418:genes_with_high <- unique(high_counts_by_gene$gene)
1760705764042:# Carichiamo la libreria
1760705764045:library(data.table)
1760705764511:# Leggiamo i file, specificando i percorsi
1760705764513:cohortA <- fread("project_oct25/cohortA_samples.csv")
1760705765258:cohortB <- fread("project_oct25/cohortB_samples.csv")
1760705766632:counts  <- fread("project_oct25/bulk_counts_long.csv")
1760705771557:View(cohortA)
1760705776008:# Aggiungiamo una colonna 'cohort' per tenere traccia della provenienza #HA SENSO???
1760705776011:cohortA[, cohort := "A"]
1760705776741:cohortB[, cohort := "B"]
1760705778141:View(cohortA)
1760705885366:# Uniamo le due coorti
1760705885370:# use.names = TRUE --> allinea le colonne con lo stesso nome
1760705885372:# fill = TRUE      --> se mancano colonne in uno dei due file, le crea e le riempie con NA
1760705885373:combined_cohorts <- rbindlist(list(cohortA, cohortB), use.names = TRUE, fill = TRUE)
1760705889684:View(combined_cohorts)
1760705899544:# Ordiniamo per coorte, condizione e sample_id
1760705899547:setorder(combined_cohorts, cohort, condition, sample_id)
1760705905807:# Uniamo per sample_id
1760705905809:merged_per_sampleid <- merge(counts, combined_cohorts, by = "sample_id", all.x = TRUE)
1760705908069:View(merged_per_sampleid)
1760705912266:View(counts)
1760705914348:View(combined_cohorts)
1760705999963:cohortA <- read.csv("project_oct25/cohortA_samples.csv", stringsAsFactors = FALSE)
1760705999968:cohortB <- read.csv("project_oct25/cohortB_samples.csv", stringsAsFactors = FALSE)
1760705999971:counts  <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760706000002:cohortA$cohort <- "A"
1760706000004:cohortB$cohort <- "B"
1760706000010:combined_cohorts <- rbind(cohortA, cohortB)
1760706000012:combined_cohorts <- combined_cohorts[order(combined_cohorts$cohort,
1760706000013:combined_cohorts$condition,
1760706000014:combined_cohorts$sample_id), ]
1760706000018:merged <- merge(counts, combined_cohorts, by = "sample_id", all.x = TRUE)
1760706000070:gene_variance <- aggregate(count ~ gene, data = merged, FUN = var, na.rm = TRUE)
1760706000108:names(gene_variance)[2] <- "variance"
1760706000109:top100_genes <- head(gene_variance[order(-gene_variance$variance), "gene"], 100)
1760706000111:top100_data <- subset(merged, gene %in% top100_genes)
1760706000114:mean_counts <- aggregate(count ~ gene + cohort + condition,
1760706000115:data = top100_data, FUN = mean, na.rm = TRUE)
1760706000127:names(mean_counts)[4] <- "mean_count"
1760707282657:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760707282675:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760707282694:normalize_cell_id <- function(x) {
1760707282695:x <- trimws(as.character(x))
1760707282696:x <- gsub("_X_|_Y_", "_", x)
1760707282697:x <- gsub("_\\.", ".", x)
1760707282698:x
1760707282698:}
1760707282700:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760707282724:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760707282776:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760707282819:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760707282819:data = combined, FUN = length)
1760707282828:names(counts_cluster_celltype)[3] <- "cell_count"
1760707282829:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760707282830:data = combined, FUN = length)
1760707282842:names(tab_ct_st)[4] <- "cell_count"
1760707282844:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760707282851:names(totals_cluster)[2] <- "cluster_total_cells"
1760707282852:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760707282854:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760707282856:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760707282856:data = combined, FUN = length)
1760707282866:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760707282867:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760707282867:by = c("integration_cluster", "cell_type"))
1760707282871:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760707282872:tab_ct_st$cluster_celltype_total) * 100
1760707288780:#Final revision
1760707288788:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760707288790:#Data:
1760707288791:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760707288793:#• cell = cell id
1760707288794:#• integration_cluster = integration cluster
1760707288795:#nt_combined_clustering.output.csv contains the following columns:
1760707288796:#• cell = cell id
1760707288797:#• cell_type = predicted cell type
1760707288798:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760707288800:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760707288801:#SETUP PACCHETTI E PERCORSI
1760707288802:# Setup iniziale
1760707288803:library(data.table)   # lavoro tabellare semplice e veloce
1760707288804:library(ggplot2)      # per il plot richiesto
1760707289680:#TASK 1.1
1760707289682:#provide a new file where cell type, cells and integration clusters are combined
1760707289685:#Leggi i due file
1760707289688:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760707289696:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760707289706:#Controlliamo i nomi delle colonne
1760707289710:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760707289712:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760707289717:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760707289719:normalize_cell_id <- function(x) {
1760707289720:x <- as.character(x)
1760707289721:x <- trimws(x)                     # toglie spazi iniziali/finali
1760707289722:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760707289723:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760707289725:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760707289727:return(x)
1760707289728:}
1760707289732:# Applichiamo la funzione di normalizzazione
1760707289734:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760707289776:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760707289816:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760707289817:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760707289860:#Salvo il file risultante
1760707289861:fwrite(combined)
1760707289870:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760707289871:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760707289871:#(tabella cluster × cell_type con conti).
1760707289872:# 1. Assicuriamoci di usare la tabella combinata
1760707289873:start_point <- copy(combined)
1760707289874:# 2. Conta per cluster x cell_type
1760707289876:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760707289879:setnames(counts_cluster_celltype, "N", "cell_count")
1760707289882:fwrite(counts_cluster_celltype)
1760707289884:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760707289885:#and also their association to normal and tumor tissue
1760707289886:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760707289887:#cell_count (numero di celle),
1760707289887:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760707289888:#(cioè cell_count / total_cells_in_cluster * 100),
1760707289888:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760707289889:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760707289890:# 1. Ripartiamo da combined
1760707289890:start_point <- copy(combined)
1760707289892:# 2. Conta righe per (cluster, cell_type, sample_type)
1760707289893:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760707289896:setnames(tab_ct_st, "N", "cell_count")
1760707289897:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760707289898:totals_cluster <- start_point[, .N, by = integration_cluster]
1760707289901:setnames(totals_cluster, "N", "cluster_total_cells")
1760707289902:# 4. Unisci il totale per cluster
1760707289903:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760707289915:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760707289916:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760707289919:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760707289919:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760707289920:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760707289923:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760707289924:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760707289925:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760707289928:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760707289930:# 8. Riordino colonne per chiarezza e salvo
1760707289931:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760707289931:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760707289932:"cluster_total_cells", "pct_within_cluster"))
1760707289934:out3 <- paste0("_summary_cluster_celltype_sampletype.csv")
1760707289935:fwrite(tab_ct_st, out3)
1760707289937:#TASK4.1
1760707289938:#Provide a plot describing the distribution of the cell type in normal/tumor tissue
1760707289938:#given the integration clusters.
1760707289939:# Usiamo il file che hai già creato nel Task 1
1760707289940:# (quello con le colonne: cell_type, integration_cluster, sample_type)
1760707289941:data <- combined
1760707289942:# Contiamo quante celle ci sono per combinazione di cluster, tipo di cellula e tipo di tessuto
1760707289942:counts <- as.data.frame(table(data$integration_cluster, data$cell_type, data$sample_type))
1760707289947:names(counts) <- c("cluster", "cell_type", "tissue", "count")
1760707289948:# Calcoliamo la percentuale di ogni cell_type dentro ciascun cluster e tessuto
1760707289949:# Per farlo, prima troviamo il totale per cluster e tessuto
1760707289950:totals <- aggregate(count ~ cluster + tissue, data = counts, sum)
1760707289953:names(totals)[3] <- "total"
1760707289955:# Ora uniamo le due tabelle
1760707289955:counts2 <- merge(counts, totals, by = c("cluster", "tissue"))
1760707289964:# Calcoliamo la percentuale
1760707289965:counts2$percent <- (counts2$count / counts2$total) * 100
1760707289967:# Facciamo il grafico
1760707289968:ggplot(counts2, aes(x = cluster, y = percent, fill = cell_type)) +
1760707289969:geom_bar(stat = "identity") +
1760707289970:facet_wrap(~ tissue) +
1760707289971:labs(title = "Distribuzione dei tipi cellulari nei cluster",
1760707289973:x = "Integration cluster",
1760707289974:y = "Percentuale di celle (%)") +
1760707289974:theme_minimal() +
1760707289975:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1760707292230:#TASK5.1
1760707292231:#Provide a normalized % for the cell types in each of the integration clusters
1760707292232:#for normal and tumor specimen.
1760707292233:# Ripartiamo dai conteggi usati nel grafico
1760707292234:counts <- as.data.frame(table(data$integration_cluster, data$cell_type, data$sample_type))
1760707292238:names(counts) <- c("cluster", "cell_type", "tissue", "count")
1760707292239:# Calcoliamo il totale per ogni cluster e tessuto
1760707292239:totals <- aggregate(count ~ cluster + tissue, data = counts, sum)
1760707292243:names(totals)[3] <- "total"
1760707292244:# Uniamo i totali ai conteggi
1760707292245:final_table <- merge(counts, totals, by = c("cluster", "tissue"))
1760707292251:# Calcoliamo la percentuale
1760707292252:final_table$percent <- round((final_table$count / final_table$total) * 100, 2)
1760707292254:# Ordiniamo per cluster
1760707292254:final_table <- final_table[order(final_table$cluster), ]
1760707292256:# Salviamo il risultato in un file
1760707292257:write.csv(final_table, "project_oct25/final_revision_percentages_simple.csv", row.names = FALSE)
1760707292264:# Mostriamo le prime righe
1760707292265:head(final_table, 10)
1760707306476:# ==========================================================
1760707306479:# TASK 1 – data.frame version
1760707306480:# Stesso obiettivo ma usando solo funzioni base R
1760707306481:# ==========================================================
1760707306483:# 1. Import
1760707306484:counts <- read.csv("project_oct25/bulk_counts_long.csv")
1760707306499:meta   <- read.csv("project_oct25/sample_metadata.csv")
1760707306502:# 2. Join counts + metadata by sample_id
1760707306502:merged_data <- merge(counts, meta, by = "sample_id")
1760707306537:# 3. Filter for treated samples and GENE_00* genes
1760707306538:treated_data <- subset(merged_data,
1760707306538:condition == "treated" & grepl("^GENE_00", gene))
1760707306548:# 4. Compute mean and median per gene
1760707306549:gene_summary <- aggregate(
1760707306550:count ~ gene,
1760707306550:data = treated_data,
1760707306551:FUN  = function(x) c(mean = mean(x), median = median(x))
1760707306552:)
1760707306565:# 5. Simplify format
1760707306566:gene_summary_df <- data.frame(
1760707306567:gene = gene_summary$gene,
1760707306567:mean_count   = gene_summary$count[, "mean"],
1760707306568:median_count = gene_summary$count[, "median"]
1760707306569:)
1760707306571:# 6 Calcolo della media dei conteggi per ciascun gene e condizione
1760707306572:# aggregate() calcola una funzione (mean) per gruppi
1760707306572:gene_condition_means_f <- aggregate(
1760707306573:count ~ gene + condition,   # formula: raggruppa per gene e condition
1760707306574:data = merged_data,         # tabella di partenza
1760707306575:FUN = mean,                 # funzione da applicare
1760707306576:na.rm = TRUE                # ignora eventuali valori mancanti
1760707306576:)
1760707306611:# 7 Ordina i risultati per gene e condition (per leggibilità)
1760707306611:gene_condition_means_f <- gene_condition_means_f[order(gene_condition_means_f$gene,
1760707306612:gene_condition_means_f$condition), ]
1760707311854:#Goal: Filter, summarize, and group bulk counts. Data: bulk_counts_long.csv, sample_metadata.csv Tasks:
1760707311857:#• Keep counts for samples in condition == "treated" and genes starting with "GENE_00".
1760707311858:#• Compute mean and median count by gene (valore centrale).
1760707311860:#• Join sample metadata and compute per-condition mean counts by gene in one pipeline.
1760707311866:library(data.table)
1760707311869:# 1. Import
1760707311869:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760707311879:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760707311883:# 2. Join counts + metadata by sample_id
1760707311884:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1760707311884:#effettua una modifica in place (non crea una copia)
1760707311885:#questo permette join molto più rapidi
1760707311886:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1760707311888:setkey(sample_meta, sample_id)
1760707311891:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760707311895:#In data.table la forma X[i] può essere usata per i join:
1760707311896:#X = tabella da cui prendi i dati (qui counts)
1760707311897:#i = tabella che serve come query/indice (qui meta)
1760707311898:#Quando ci sono chiavi compatibili (sample_id), counts[meta] interpreta meta come la tabella di lookup
1760707311899:#e per ciascuna riga di meta estrae le righe corrispondenti da counts
1760707311900:#nomatch = 0 significa: escludi le righe di meta che non trovano corrispondenza in counts.
1760707311900:#Questo equivale a un inner join (solo righe with match).
1760707311902:# 3. Filter for treated samples and GENE_00* genes
1760707311902:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1760707311907:#filtrare stringhe in base a un pattern (cioè una “regola” di testo).
1760707311907:#Quindi grepl("^GENE_00", gene) restituisce:
1760707311908:#TRUE per tutti i geni che iniziano con GENE_00
1760707311909:#FALSE per tutti gli altri.
1760707311910:# 4. Compute mean and median per gene
1760707311911:gene_mean_median <- filtered_data[, .(
1760707311911:mean_count   = mean(count),
1760707311912:median_count = median(count)
1760707311912:), by = gene]
1760707311916:# Punto 5 corretto: join + per-condition mean by gene (una pipeline)
1760707311917:# Calcola la media dei conteggi per ogni combinazione (gene, condition)
1760707311918:# tutto in una singola pipeline: unisco metadata e counts e poi raggruppo
1760707311919:gene_condition_means <- bulk_counts[
1760707311919:sample_meta,                # uso sample_meta come "i" (lookup)
1760707311920:on = "sample_id"            # join su sample_id (non serve setkey se usi on=)
1760707311921:][ , .(
1760707311921:mean_count = mean(count)   # media dei conteggi (ignora NA se ci sono)
1760707311922:), by = .(gene, condition) ]               # raggruppa per gene e per condition
1760707316893:# ==========================================================
1760707316896:# TASK 2 – data.frame version
1760707316899:# ==========================================================
1760707316903:# 1. Import
1760707316905:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760707316922:# 2. Add log2(count + 1) column
1760707316923:counts$log2_count <- log2(counts$count + 1)
1760707316925:# 3. Add binary flag 'high' (count > 100)
1760707316925:counts$high <- counts$count > 100
1760707316927:# 4. Overwrite 'high' using gene-wise median threshold
1760707316928:#    Qui usiamo tapply() per calcolare la mediana per gene,
1760707316928:#    poi combiniamo i risultati in un vettore logico della stessa lunghezza
1760707316929:medians_by_gene <- tapply(counts$count, counts$gene, median)
1760707316961:counts$high <- counts$count > medians_by_gene[counts$gene]
1760707363190:#Goal: Add QC-style derived columns without copying. Data: bulk_counts_long.csv
1760707363192:#Tasks:
1760707363193:#• Add la log2 counts column and a binary flag high if count > 100.
1760707363194:#• Overwrite high to use a gene-wise threshold (e.g., count > median(count) by=gene).
1760707363195:# 1 Carico la libreria
1760707363197:library(data.table)
1760707363200:# 2 Leggo il file come data.table
1760707363206:counts <- fread("project_oct25/bulk_counts_long.csv")
1760707363211:# PARTE 1: Aggiungo la colonna log2 dei conteggi
1760707363212:# -----------------------------------------------------
1760707363212:# := modifica la tabella "in place" (senza crearne una copia)
1760707363213:counts[, log2_count := log2(count)]  #modifica o calcola qualcosa in questa tabella
1760707363215:#:= significa che la modifica è in place
1760707363216:#calcola il log in base due dei valori nella colonna count per stabilizzare la varianza
1760707363216:#rende i dati più confrontabili tra geni
1760707363217:# posso aggiungere +1 dopo count per evitare log2(0), che non è definito)
1760707363219:#Aggiungo la colonna binaria 'high' (count > 100)
1760707363220:counts[, high := count > 100]
1760707363222:#se il count è >100 restituisce TRUE altrimenti FALSE
1760707363223:#quindi crea una nuova colonna high con valori booleani
1760707363223:#per classificare i geni in highly expressed o no usando 100 come soglia
1760707363224:# -----------------------------------------------------
1760707363225:# PARTE 3: Sovrascrivo 'high' in modo gene-wise, con questo criterio := (in place)
1760707363226:#per ogni gene verifica se il valore di count è maggiore della mediana di count per quel gene
1760707363227:# (count > median(count) per ciascun gene)
1760707363227:# -----------------------------------------------------
1760707363228:counts[, high := count > median(count), by = gene]  #x ogni gene separatamente
1760707368687:# ==========================================================
1760707368697:# TASK 2 – data.frame version
1760707368698:# ==========================================================
1760707368699:# 1. Import
1760707368700:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1760707368715:# 2. Add log2(count + 1) column
1760707368717:counts$log2_count <- log2(counts$count + 1)
1760707368720:# 3. Add binary flag 'high' (count > 100)
1760707368721:counts$high <- counts$count > 100
1760707368723:# 4. Overwrite 'high' using gene-wise median threshold
1760707368724:#    Qui usiamo tapply() per calcolare la mediana per gene,
1760707368724:#    poi combiniamo i risultati in un vettore logico della stessa lunghezza
1760707368725:medians_by_gene <- tapply(counts$count, counts$gene, median)
1760707368760:counts$high <- counts$count > medians_by_gene[counts$gene]
1760708464235:variants <- read.csv("project_oct25/variants.csv", stringsAsFactors = FALSE)
1760708464250:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760708464254:variants$start <- variants$pos
1760708464256:variants$end <- variants$pos
1760708464258:# Overlap manuale
1760708464259:overlaps_list <- lapply(1:nrow(variants), function(i) {
1760708464260:v <- variants[i, ]
1760708464260:gsub <- subset(genes, chr == v$chr & start <= v$end & end >= v$start)
1760708464262:if (nrow(gsub) == 0) return(NULL)
1760708464264:cbind(v, gsub)
1760708464267:})
1760708465394:overlaps <- do.call(rbind, overlaps_list)
1760708465587:overlaps$impact_upper <- toupper(overlaps$impact)
1760708465591:high_overlaps <- subset(overlaps, impact_upper == "HIGH")
1760708465594:high_counts_by_gene_sample <- aggregate(impact_upper ~ gene + sample_id,
1760708465596:data = high_overlaps, FUN = length)
1760708465606:names(high_counts_by_gene_sample)[3] <- "high_variant_count"
1760708465610:high_counts_by_gene <- aggregate(impact_upper ~ gene,
1760708465612:data = high_overlaps, FUN = length)
1760708465616:names(high_counts_by_gene)[2] <- "total_high_variants"
1760708465617:genes_with_high <- unique(high_counts_by_gene$gene)
1760708471945:variants <- read.csv("project_oct25/variants.csv", stringsAsFactors = FALSE)
1760708471954:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760708471958:variants$start <- variants$pos
1760708471959:variants$end <- variants$pos
1760708471960:# Overlap manuale
1760708471961:overlaps_list <- lapply(1:nrow(variants), function(i) {
1760708471963:v <- variants[i, ]
1760708471965:gsub <- subset(genes, chr == v$chr & start <= v$end & end >= v$start)
1760708471966:if (nrow(gsub) == 0) return(NULL)
1760708471967:cbind(v, gsub)
1760708471968:})
1760708473082:overlaps <- do.call(rbind, overlaps_list)
1760708473258:overlaps$impact_upper <- toupper(overlaps$impact)
1760708473260:high_overlaps <- subset(overlaps, impact_upper == "HIGH")
1760708473263:high_counts_by_gene_sample <- aggregate(impact_upper ~ gene + sample_id,
1760708473265:data = high_overlaps, FUN = length)
1760708473270:names(high_counts_by_gene_sample)[3] <- "high_variant_count"
1760708473273:high_counts_by_gene <- aggregate(impact_upper ~ gene,
1760708473275:data = high_overlaps, FUN = length)
1760708473280:names(high_counts_by_gene)[2] <- "total_high_variants"
1760708473281:genes_with_high <- unique(high_counts_by_gene$gene)
1760708649043:# 1 Carico la libreria
1760708649046:library(data.table)
1760708651599:# 2 Leggo i file CSV come data.table
1760708651602:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760708652366:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760708653483:# PARTE 1: Imposto la chiave su sample_metadata
1760708653486:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1760708653489:setkey(sample_meta, sample_id)
1760708664214:# PARTE 2: Faccio una join tra metadata e counts
1760708664217:# Dopo aver impostato la chiave, la join è automatica e più veloce
1760708664219:join_data <- sample_meta[bulk_counts, on = "sample_id"] #prende meta e attacca counts in base al sample ID
1760708664269:# PARTE 3: Creo un indice secondario su (gene, sample_id)
1760708664274:# L’indice serve per accelerare query che filtrano per gene e sample
1760708664276:setindex(bulk_counts, gene, sample_id)
1760708672111:# PARTE 4: Benchmark — confronto prima e dopo l’indice
1760708672114:# Esempio: voglio estrarre tutte le righe per un certo gene
1760708672116:gene_call <- "GENE_0051"
1760708679407:sample_chosen <- "S20"
1760708775880:# Prima (senza usare l’indice)
1760708775886:system.time({
1760708775889:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760708775891:})
1760708780018:# Dopo (l’indice ora è attivo)
1760708780021:system.time({
1760708780023:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760708780025:})
1760718008355:# 1 Carico la libreria
1760718008357:library(data.table)
1760718009108:# 2 Leggo i file CSV come data.table
1760718009112:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760718009828:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760718010640:# PARTE 1: Imposto la chiave su sample_metadata
1760718010643:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1760718010645:setkey(sample_meta, sample_id)
1760718015926:# PARTE 2: Faccio una join tra metadata e counts
1760718015931:# Dopo aver impostato la chiave, la join è automatica e più veloce
1760718015932:join_data <- sample_meta[bulk_counts, on = "sample_id"] #prende meta e attacca counts in base al sample ID
1760718018599:# PARTE 4: Benchmark — confronto prima e dopo l’indice
1760718018605:# Esempio: voglio estrarre tutte le righe per un certo gene
1760718018607:gene_call <- "GENE_0051"
1760718020112:sample_chosen <- "S20"
1760718031891:# Prima (senza usare l’indice)
1760718031893:system.time({
1760718031895:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760718031897:})
1760718033309:# PARTE 3: Creo un indice secondario su (gene, sample_id)
1760718033312:# L’indice serve per accelerare query che filtrano per gene e sample
1760718033314:setindex(bulk_counts, gene, sample_id)
1760718034012:# Dopo (l’indice ora è attivo)
1760718034016:system.time({
1760718034018:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760718034020:})
1760718064302:# 1 Carico la libreria
1760718064305:library(data.table)
1760718064930:# 2 Leggo i file CSV come data.table
1760718064934:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760718065277:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760718066854:View(bulk_counts)
1760718067493:View(sample_meta)
1760718141229:# 1 Carico la libreria
1760718141233:library(data.table)
1760718141702:# 2 Leggo i file CSV come data.table
1760718141706:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760718141982:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760718142290:# PARTE 1: Imposto la chiave su sample_metadata
1760718142294:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1760718142296:setkey(sample_meta, sample_id)
1760718142613:# PARTE 2: Faccio una join tra metadata e counts
1760718142617:# Dopo aver impostato la chiave, la join è automatica e più veloce
1760718142621:join_data <- sample_meta[bulk_counts, on = "sample_id"] #prende meta e attacca counts in base al sample ID
1760718142990:# PARTE 4: Benchmark — confronto prima e dopo l’indice
1760718142992:# Esempio: voglio estrarre tutte le righe per un certo gene
1760718142994:gene_call <- "GENE_0051"
1760718143342:sample_chosen <- "S20"
1760718143897:# Prima (senza usare l’indice)
1760718143900:system.time({
1760718143902:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760718143904:})
1760718144512:# PARTE 3: Creo un indice secondario su (gene, sample_id)
1760718144514:# L’indice serve per accelerare query che filtrano per gene e sample
1760718144515:setindex(bulk_counts, gene, sample_id)
1760718145007:# Dopo (l’indice ora è attivo)
1760718145010:system.time({
1760718145013:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1760718145015:})
1760718200216:library(data.table)
1760718200748:# 1 Carico i file
1760718200751:labs <- fread("project_oct25/clinical_labs.csv")
1760718200960:ref  <- fread("project_oct25/lab_reference_ranges.csv")
1760718201682:# Unisco le tabelle per aggiungere i range di riferimento
1760718201685:# Dato che i range sono uguali per M e F, li prendo una sola volta
1760718201687:ref_unique <- unique(ref[, .(lab, lower, upper)])
1760718202329:# Uso una join per aggiungere a ogni valore clinico i limiti lower e upper del test corrispondente
1760718202334:merged_labs <- merge(labs, ref_unique, by = "lab")
1760718203025:# -----------------------------------------------------
1760718203028:# PARTE 2: Classifico i valori come "normal" o "out_of_range"
1760718203030:# -----------------------------------------------------
1760718203031:merged_labs[, status := ifelse(value >= lower & value <= upper, "normal", "out_of_range")]
1760718210168:# -----------------------------------------------------
1760718210172:# PARTE 3: Calcolo la percentuale di risultati fuori range per paziente
1760718210174:# -----------------------------------------------------
1760718210175:abnormal_by_patient <- merged_labs[, .(
1760718210177:total_tests = .N,                                 # numero totale di test per paziente
1760718210179:out_of_range = sum(status == "out_of_range")      # quanti sono fuori range
1760718210181:), by = patient_id]
1760718213079:# -----------------------------------------------------
1760718213084:# PARTE 4: Calcolo i risultati fuori range per tipo di test
1760718213086:# -----------------------------------------------------
1760718213087:abnormal_by_lab <- merged_labs[, .(
1760718213089:total_tests = .N,
1760718213090:out_of_range = sum(status == "out_of_range")
1760718213092:), by = lab]
1760718229976:View(abnormal_by_patient)
1760718260852:View(labs)
1760718261424:View(ref)
1760718274941:View(ref_unique)
1760718291827:View(merged_labs)
1760718331704:View(abnormal_by_lab)
1760718448023:#TASK 6: Nearest-time matching of vitals to lab draws
1760718448033:# =====================================================
1760718448038:library(data.table)
1760718448574:# 1. Carico i dati
1760718448578:labs <- fread("project_oct25/clinical_labs.csv")
1760718449140:vitals <- fread("project_oct25/vitals_time_series.csv")
1760718449695:# 2. Preparo le tabelle e converte le date in un formato tempo che R può confrontare
1760718449699:labs[, time_iso := as.POSIXct(time_iso)]
1760718450168:vitals[, time_iso := as.POSIXct(time_iso)]
1760718450702:#ordina i dati per paziente e per tempo, serve per i join temporali
1760718450706:setorder(labs, patient_id, time_iso)
1760718451206:setorder(vitals, patient_id, time_iso)
1760718451730:# Salvo il tempo del laboratorio, creando una nuova colonna lab_time con l'orario del prelievo
1760718451736:labs[, lab_time := time_iso]
1760718452363:#imposto le chiavi, importante per il join
1760718452367:setkey(labs, patient_id, time_iso)
1760718452900:setkey(vitals, patient_id, time_iso)
1760718453404:# 3. Trovo l'HR più vicino
1760718453407:vitals_hr <- vitals[vital == "HR", .(patient_id, time_iso, value)] #prendo solo le righe dei HR
1760718454030:setnames(vitals_hr, "value", "nearest_HR") #rinomino la colonna value in nearest HR
1760718454920:# SALVO IL TEMPO DELL'HR PRIMA DEL JOIN!
1760718454925:vitals_hr[, hr_time := time_iso] #salvo l'ora della misura HR
1760718455489:setkey(vitals_hr, patient_id, time_iso)
1760718456012:labs_with_hr <- vitals_hr[labs, roll = "nearest"] #rolling join
1760718456592:#per ogni esame di lab, trova il battito HR più vicino nel tempo x lo stesso paziente
1760718456600:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1760718457322:# 4. Trovo l'SBP più vicino, esattamente lo stesso per pressione
1760718457326:vitals_sbp <- vitals[vital == "SBP", .(patient_id, time_iso, value)]
1760718457926:setnames(vitals_sbp, "value", "nearest_SBP")
1760718458506:# SALVO IL TEMPO DELL'SBP PRIMA DEL JOIN!
1760718458512:vitals_sbp[, sbp_time := time_iso]
1760718459058:setkey(vitals_sbp, patient_id, time_iso)
1760718459636:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1760718460124:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1760718460681:# 6. Analisi CRP: filtra solo le righe dove il lab è CRP
1760718460684:crp_data <- labs_with_vitals[lab == "CRP"]
1760718461231:#per ogni paziente (by sample id) calcola la correlazione tra CRP e battito e CRP e pressione
1760718461234:#complete.obs: ignora le righe con dati mancanti
1760718461235:cor_crp_hr <- crp_data[!is.na(nearest_HR), .(
1760718461238:correlation_CRP_HR = cor(value, nearest_HR, use = "complete.obs")
1760718461239:), by = patient_id]
1760718461781:cor_crp_sbp <- crp_data[!is.na(nearest_SBP), .(
1760718461784:correlation_CRP_SBP = cor(value, nearest_SBP, use = "complete.obs")
1760718461786:), by = patient_id]
1760718525573:?quantile
1760718618033:?dcast
1760718673774:# Carichiamo le librerie
1760718673778:library(data.table)
1760718673945:# Leggiamo i dati (matrice larga: una riga per gene, una colonna per campione)
1760718673948:counts_wide <- fread("project_oct25/bulk_counts_wide.csv")
1760718674132:# PARTE 1: Convertiamo da formato wide → long
1760718674135:# -----------------------------------------------------
1760718674137:# Supponiamo che la prima colonna si chiami "gene"
1760718674140:counts_long <- melt(counts_wide, id.vars = "gene",
1760718674142:variable.name = "sample_id", value.name = "count")
1760718674309:# Aggiungiamo le informazioni di condizione per ogni sample
1760718674314:# Carichiamo i metadati
1760718674315:meta <- fread("project_oct25/sample_metadata.csv")
1760718674460:# Uniamo metadati ai conteggi
1760718674464:merged <- merge(counts_long, meta, by = "sample_id")
1760718674716:# Calcoliamo i totali per campione
1760718674719:totals_per_sample <- merged[, .(total_count = sum(count)), by = sample_id]
1760718674799:# Aggiungiamo questi totali alla tabella principale
1760718674803:merged <- merge(merged, totals_per_sample, by = "sample_id")
1760718674941:# Torniamo da long → wide,
1760718674944:#           ma ora con colonne per condizione (treated, control)
1760718674946:#           e valori = media dei conteggi per gene
1760718674949:gene_condition_means <- merged[, .(mean_count = mean(count)),
1760718674952:by = .(gene, condition)]
1760718675126:# Da long a wide: una riga per gene, colonne = condizioni #VERIFICARE FUNZIONAMENTO
1760718675129:counts_condition_wide <- dcast(gene_condition_means,
1760718675131:gene ~ condition,
1760718675134:value.var = "mean_count")
1760718700219:View(counts_condition_wide)
1760718708604:View(gene_condition_means)
1760718804248:variants <- read.csv("project_oct25/variants.csv", stringsAsFactors = FALSE)
1760718804712:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760718805835:variants$start <- variants$pos
1760718806357:variants$end <- variants$pos
1760718806928:# Overlap manuale
1760718806933:overlaps_list <- lapply(1:nrow(variants), function(i) {
1760718806937:v <- variants[i, ]
1760718806942:gsub <- subset(genes, chr == v$chr & start <= v$end & end >= v$start)
1760718806947:if (nrow(gsub) == 0) return(NULL)
1760718806950:cbind(v, gsub)
1760718806951:})
1760718808026:overlaps <- do.call(rbind, overlaps_list)
1760718808640:overlaps$impact_upper <- toupper(overlaps$impact)
1760718818551:variants <- read.csv("project_oct25/variants.csv", stringsAsFactors = FALSE)
1760718819183:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760718820090:variants$start <- variants$pos
1760718821567:variants$end <- variants$pos
1760718826203:# Overlap manuale
1760718826207:overlaps_list <- lapply(1:nrow(variants), function(i) {
1760718826209:v <- variants[i, ]
1760718826211:gsub <- subset(genes, chr == v$chr & start <= v$end & end >= v$start)
1760718826214:if (nrow(gsub) == 0) return(NULL)
1760718826219:cbind(v, gsub)
1760718826222:})
1760718837179:warnings()
1760718863400:# Carichiamo le librerie
1760718863402:library(data.table)
1760718863612:# Leggiamo i dati (matrice larga: una riga per gene, una colonna per campione)
1760718863614:counts_wide <- fread("project_oct25/bulk_counts_wide.csv")
1760718863752:# PARTE 1: Convertiamo da formato wide → long
1760718863754:# -----------------------------------------------------
1760718863758:# Supponiamo che la prima colonna si chiami "gene"
1760718863759:counts_long <- melt(counts_wide, id.vars = "gene",
1760718863761:variable.name = "sample_id", value.name = "count")
1760718864012:# Aggiungiamo le informazioni di condizione per ogni sample
1760718864014:# Carichiamo i metadati
1760718864016:meta <- fread("project_oct25/sample_metadata.csv")
1760718864113:# Uniamo metadati ai conteggi
1760718864117:merged <- merge(counts_long, meta, by = "sample_id")
1760718864263:# Calcoliamo i totali per campione
1760718864267:totals_per_sample <- merged[, .(total_count = sum(count)), by = sample_id]
1760718864431:# Aggiungiamo questi totali alla tabella principale
1760718864435:merged <- merge(merged, totals_per_sample, by = "sample_id")
1760718864617:# Torniamo da long → wide,
1760718864621:#           ma ora con colonne per condizione (treated, control)
1760718864622:#           e valori = media dei conteggi per gene
1760718864624:gene_condition_means <- merged[, .(mean_count = mean(count)),
1760718864625:by = .(gene, condition)]
1760718864837:# Da long a wide: una riga per gene, colonne = condizioni
1760718864840:counts_condition_wide <- dcast(gene_condition_means,
1760718864842:gene ~ condition,
1760718864843:value.var = "mean_count")
1760718872721:variants <- read.csv("project_oct25/variants.csv", stringsAsFactors = FALSE)
1760718873198:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760718874708:View(genes)
1760718875018:View(variants)
1760718890084:variants$start <- variants$pos
1760718893675:variants$end <- variants$pos
1760718896605:View(variants)
1760718906933:variants <- read.csv("project_oct25/variants.csv", stringsAsFactors = FALSE)
1760718907428:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1760718910527:View(variants)
1760718918596:variants$start <- variants$pos
1760718924800:variants$end <- variants$pos
1760719080166:# Leggiamo i file, specificando i percorsi
1760719080169:cohortA <- fread("project_oct25/cohortA_samples.csv")
1760719080876:cohortB <- fread("project_oct25/cohortB_samples.csv")
1760719081619:counts  <- fread("project_oct25/bulk_counts_long.csv")
1760719082748:View(cohortA)
1760719084067:View(cohortB)
1760719104013:View(counts)
1760719109203:# Aggiungiamo una colonna 'cohort' per tenere traccia della provenienza #HA SENSO???
1760719109207:cohortA[, cohort := "A"]
1760719109726:cohortB[, cohort := "B"]
1760719111061:View(cohortA)
1760719111701:View(cohortB)
1760719124358:# Uniamo le due coorti
1760719124361:# use.names = TRUE --> allinea le colonne con lo stesso nome
1760719124363:# fill = TRUE      --> se mancano colonne in uno dei due file, le crea e le riempie con NA
1760719124364:combined_cohorts <- rbindlist(list(cohortA, cohortB), use.names = TRUE, fill = TRUE)
1760719126306:View(combined_cohorts)
1760719140935:# Ordiniamo per coorte, condizione e sample_id
1760719140939:setorder(combined_cohorts, cohort, condition, sample_id)
1760719142766:View(combined_cohorts)
1760719166181:View(combined_cohorts)
1760719785453:#Final revision
1760719785456:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760719785458:#Data:
1760719785459:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760719785460:#• cell = cell id
1760719785461:#• integration_cluster = integration cluster
1760719785462:#nt_combined_clustering.output.csv contains the following columns:
1760719785463:#• cell = cell id
1760719785464:#• cell_type = predicted cell type
1760719785465:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760719785467:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760719785468:#SETUP PACCHETTI E PERCORSI
1760719785469:# Setup iniziale
1760719785471:library(data.table)   # lavoro tabellare semplice e veloce
1760719785472:library(ggplot2)      # per il plot richiesto
1760719785474:#TASK 1.1
1760719785475:#provide a new file where cell type, cells and integration clusters are combined
1760719785476:#Leggi i due file
1760719785477:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760719785496:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760719785512:#Controlliamo i nomi delle colonne
1760719785512:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760719785514:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760719785515:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760719785516:normalize_cell_id <- function(x) {
1760719785517:x <- as.character(x)
1760719785517:x <- trimws(x)                     # toglie spazi iniziali/finali
1760719785518:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760719785519:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760719785520:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760719785520:return(x)
1760719785521:}
1760719785523:# Applichiamo la funzione di normalizzazione
1760719785524:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760719785564:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760719785600:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760719785601:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760719785649:#Salvo il file risultante
1760719785650:fwrite(combined)
1760719785678:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760719785680:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760719785681:#(tabella cluster × cell_type con conti).
1760719785682:# 1. Assicuriamoci di usare la tabella combinata
1760719785683:start_point <- copy(combined)
1760719785689:# 2. Conta per cluster x cell_type
1760719785692:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760719785710:setnames(counts_cluster_celltype, "N", "cell_count")
1760719785712:fwrite(counts_cluster_celltype)
1760719785715:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760719785716:#and also their association to normal and tumor tissue
1760719785717:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760719785718:#cell_count (numero di celle),
1760719785718:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760719785721:#(cioè cell_count / total_cells_in_cluster * 100),
1760719785721:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760719785722:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760719785724:# 1. Ripartiamo da combined
1760719785724:start_point <- copy(combined)
1760719785731:# 2. Conta righe per (cluster, cell_type, sample_type)
1760719785732:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760719785760:setnames(tab_ct_st, "N", "cell_count")
1760719785770:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760719785770:totals_cluster <- start_point[, .N, by = integration_cluster]
1760719785788:setnames(totals_cluster, "N", "cluster_total_cells")
1760719785798:# 4. Unisci il totale per cluster
1760719785803:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760719785809:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760719785809:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760719785812:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760719785812:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760719785813:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760719785817:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760719785820:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760719785820:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760719785831:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760719785835:# 8. Riordino colonne per chiarezza e salvo
1760719785836:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760719785837:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760719785837:"cluster_total_cells", "pct_within_cluster"))
1760719785838:out3 <- paste0("_summary_cluster_celltype_sampletype.csv")
1760719785839:fwrite(tab_ct_st, out3)
1760719785841:#TASK4.1
1760719785842:#Provide a plot describing the distribution of the cell type in normal/tumor tissue
1760719785842:#given the integration clusters.
1760719785843:# Usiamo il file che hai già creato nel Task 1
1760719785843:# (quello con le colonne: cell_type, integration_cluster, sample_type)
1760719785844:data <- combined
1760719785845:# Contiamo quante celle ci sono per combinazione di cluster, tipo di cellula e tipo di tessuto
1760719785846:counts <- as.data.frame(table(data$integration_cluster, data$cell_type, data$sample_type))
1760719785853:names(counts) <- c("cluster", "cell_type", "tissue", "count")
1760719785854:# Calcoliamo la percentuale di ogni cell_type dentro ciascun cluster e tessuto
1760719785854:# Per farlo, prima troviamo il totale per cluster e tessuto
1760719785855:totals <- aggregate(count ~ cluster + tissue, data = counts, sum)
1760719785864:names(totals)[3] <- "total"
1760719785865:# Ora uniamo le due tabelle
1760719785865:counts2 <- merge(counts, totals, by = c("cluster", "tissue"))
1760719785913:# Calcoliamo la percentuale
1760719785913:counts2$percent <- (counts2$count / counts2$total) * 100
1760719785914:# Facciamo il grafico
1760719785915:ggplot(counts2, aes(x = cluster, y = percent, fill = cell_type)) +
1760719785915:geom_bar(stat = "identity") +
1760719785916:facet_wrap(~ tissue) +
1760719785916:labs(title = "Distribuzione dei tipi cellulari nei cluster",
1760719785917:x = "Integration cluster",
1760719785917:y = "Percentuale di celle (%)") +
1760719785918:theme_minimal() +
1760719785918:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1760719787769:#TASK5.1
1760719787770:#Provide a normalized % for the cell types in each of the integration clusters
1760719787771:#for normal and tumor specimen.
1760719787773:# Ripartiamo dai conteggi usati nel grafico
1760719787774:counts <- as.data.frame(table(data$integration_cluster, data$cell_type, data$sample_type))
1760719787778:names(counts) <- c("cluster", "cell_type", "tissue", "count")
1760719787779:# Calcoliamo il totale per ogni cluster e tessuto
1760719787780:totals <- aggregate(count ~ cluster + tissue, data = counts, sum)
1760719787784:names(totals)[3] <- "total"
1760719787785:# Uniamo i totali ai conteggi
1760719787786:final_table <- merge(counts, totals, by = c("cluster", "tissue"))
1760719787793:# Calcoliamo la percentuale
1760719787794:final_table$percent <- round((final_table$count / final_table$total) * 100, 2)
1760719787795:# Ordiniamo per cluster
1760719787796:final_table <- final_table[order(final_table$cluster), ]
1760719787797:# Salviamo il risultato in un file
1760719787798:write.csv(final_table, "project_oct25/final_revision_percentages_simple.csv", row.names = FALSE)
1760719787805:# Mostriamo le prime righe
1760719787806:head(final_table, 10)
1760719947477:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760719947480:#SETUP PACCHETTI E PERCORSI
1760719947482:# Setup iniziale
1760719947483:library(data.table)   # lavoro tabellare semplice e veloce
1760719948047:library(ggplot2)      # per il plot richiesto
1760719968138:#TASK 1.1
1760719968144:#provide a new file where cell type, cells and integration clusters are combined
1760719968146:#Leggi i due file
1760719968150:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760719971844:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760719979007:View(clustering_dt)
1760719980497:View(integration_dt)
1760720122974:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760720122979:normalize_cell_id <- function(x) {
1760720122981:x <- as.character(x)
1760720122983:x <- trimws(x)                     # toglie spazi iniziali/finali
1760720122985:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760720122987:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760720122990:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760720122994:return(x)
1760720122998:}
1760720124574:# Applichiamo la funzione di normalizzazione
1760720124578:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760720125111:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760720127054:View(clustering_dt)
1760720127675:View(integration_dt)
1760720160173:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760720160178:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760720162706:#Salvo il file risultante
1760720162708:fwrite(combined)
1760720221557:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760720221560:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760720221562:#(tabella cluster × cell_type con conti).
1760720221563:# 1. Assicuriamoci di usare la tabella combinata
1760720221564:start_point <- copy(combined)
1760720251560:# 2. Conta per cluster x cell_type
1760720251563:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760720255897:View(counts_cluster_celltype)
1760720278132:setnames(counts_cluster_celltype, "N", "cell_count")
1760720279792:View(counts_cluster_celltype)
1760720421420:# Usiamo il file che hai già creato nel Task 1
1760720421425:# (quello con le colonne: cell_type, integration_cluster, sample_type)
1760720421428:data <- combined
1760720429338:# Contiamo quante celle ci sono per combinazione di cluster, tipo di cellula e tipo di tessuto
1760720429345:counts <- as.data.frame(table(data$integration_cluster, data$cell_type, data$sample_type))
1760720430238:names(counts) <- c("cluster", "cell_type", "tissue", "count")
1760720435783:View(counts)
1760720467157:names(counts) <- c("cluster", "cell_type", "tissue", "count")
1760720469740:# Calcoliamo la percentuale di ogni cell_type dentro ciascun cluster e tessuto
1760720469743:# Per farlo, prima troviamo il totale per cluster e tessuto
1760720469744:totals <- aggregate(count ~ cluster + tissue, data = counts, sum)
1760720472603:View(totals)
1760720477017:names(totals)[3] <- "total"
1760720478966:View(totals)
1760720514555:# Ora uniamo le due tabelle
1760720514559:counts2 <- merge(counts, totals, by = c("cluster", "tissue"))
1760720519923:# Calcoliamo la percentuale
1760720519926:counts2$percent <- (counts2$count / counts2$total) * 100
1760720542342:?ggplot
1760720572331:# Facciamo il grafico
1760720572333:ggplot(counts2, aes(x = cluster, y = percent, fill = cell_type)) +
1760720572335:geom_bar(stat = "identity") +
1760720572336:facet_wrap(~ tissue) +
1760720572337:labs(title = "Distribuzione dei tipi cellulari nei cluster",
1760720572338:x = "Integration cluster",
1760720572339:y = "Percentuale di celle (%)") +
1760720572340:theme_minimal() +
1760720572341:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1760720792051:View(counts2)
1760721448315:# Ripartiamo dai conteggi usati nel grafico
1760721448317:counts <- as.data.frame(table(data$integration_cluster, data$cell_type, data$sample_type))
1760721479223:?round
1760721624800:?as.data.frame
1760721659703:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760721660176:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760721660646:normalize_cell_id <- function(x) {
1760721660649:x <- trimws(as.character(x))
1760721660651:x <- gsub("_X_|_Y_", "_", x)
1760721660653:x <- gsub("_\\.", ".", x)
1760721660655:x
1760721660663:}
1760721663040:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760721664049:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760721665381:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760721665931:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760721665935:data = combined, FUN = length)
1760721666660:names(counts_cluster_celltype)[3] <- "cell_count"
1760721668437:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760721668440:data = combined, FUN = length)
1760721669780:names(tab_ct_st)[4] <- "cell_count"
1760721670390:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760721670861:names(totals_cluster)[2] <- "cluster_total_cells"
1760721671754:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760721672425:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760721673015:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760721673021:data = combined, FUN = length)
1760721673666:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760721674238:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760721674246:by = c("integration_cluster", "cell_type"))
1760721674784:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760721674789:tab_ct_st$cluster_celltype_total) * 100
1760721787238:View(integration_dt)
1760721789537:View(counts_cluster_celltype)
1760721792467:View(counts_cluster_celltype)
1760721794827:View(clustering_dt)
1760721797890:View(tab_ct_st)
1760721800902:View(totals_cluster)
1760721805031:View(totals_cluster_celltype)
1760721840153:View(totals_cluster)
1760721856344:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760721856365:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1760721856388:normalize_cell_id <- function(x) {
1760721856390:x <- trimws(as.character(x))
1760721856391:x <- gsub("_X_|_Y_", "_", x)
1760721856392:x <- gsub("_\\.", ".", x)
1760721856393:x
1760721856395:}
1760721856398:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1760721856428:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1760721856470:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1760721856531:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760721856532:data = combined, FUN = length)
1760721856542:names(counts_cluster_celltype)[3] <- "cell_count"
1760721856545:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1760721856546:data = combined, FUN = length)
1760721856561:names(tab_ct_st)[4] <- "cell_count"
1760721856563:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1760721856570:names(totals_cluster)[2] <- "cluster_total_cells"
1760721856571:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1760721856574:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1760721856576:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1760721856578:data = combined, FUN = length)
1760721856589:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1760721856591:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1760721856592:by = c("integration_cluster", "cell_type"))
1760721856595:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1760721856596:tab_ct_st$cluster_celltype_total) * 100
1760721883365:#Final revision
1760721883370:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1760721883372:#Data:
1760721883374:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1760721883375:#• cell = cell id
1760721883376:#• integration_cluster = integration cluster
1760721883377:#nt_combined_clustering.output.csv contains the following columns:
1760721883378:#• cell = cell id
1760721883379:#• cell_type = predicted cell type
1760721883379:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1760721883381:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1760721883382:#SETUP PACCHETTI E PERCORSI
1760721883383:# Setup iniziale
1760721883384:library(data.table)   # lavoro tabellare semplice e veloce
1760721883385:library(ggplot2)      # per il plot richiesto
1760721883386:#TASK 1.1
1760721883387:#provide a new file where cell type, cells and integration clusters are combined
1760721883388:#Leggi i due file
1760721883389:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1760721883397:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1760721883405:#Controlliamo i nomi delle colonne #NON RICHIESTO
1760721883406:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1760721883407:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1760721883409:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1760721883410:normalize_cell_id <- function(x) {
1760721883411:x <- as.character(x)
1760721883412:x <- trimws(x)                     # toglie spazi iniziali/finali
1760721883413:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1760721883413:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1760721883414:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1760721883415:return(x)
1760721883416:}
1760721883417:# Applichiamo la funzione di normalizzazione
1760721883418:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760721883449:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1760721883485:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1760721883486:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1760721883530:#Salvo il file risultante
1760721883531:#fwrite(combined) NO!!
1760721883533:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1760721883534:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1760721883535:#(tabella cluster × cell_type con conti).
1760721883536:# 1. Assicuriamoci di usare la tabella combinata
1760721883538:start_point <- copy(combined)
1760721883541:# 2. Conta per cluster x cell_type
1760721883542:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760721883547:setnames(counts_cluster_celltype, "N", "cell_count")
1760721883548:#fwrite(counts_cluster_celltype) NO!!
1760721883549:#TASK3.1:provide summary table showing cell types associated to integration clusters
1760721883550:#and also their association to normal and tumor tissue
1760721883551:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1760721883552:#cell_count (numero di celle),
1760721883553:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1760721883554:#(cioè cell_count / total_cells_in_cluster * 100),
1760721883557:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1760721883560:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1760721883562:# 1. Ripartiamo da combined
1760721883563:start_point <- copy(combined)
1760721883565:# 2. Conta righe per (cluster, cell_type, sample_type)
1760721883565:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760721883571:setnames(tab_ct_st, "N", "cell_count")
1760721883574:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1760721883575:totals_cluster <- start_point[, .N, by = integration_cluster]
1760721883579:setnames(totals_cluster, "N", "cluster_total_cells")
1760721883581:# 4. Unisci il totale per cluster
1760721883581:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1760721883589:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1760721883589:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1760721883593:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1760721883594:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1760721883595:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1760721883600:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1760721883602:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1760721883603:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1760721883610:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1760721883614:# 8. Riordino colonne per chiarezza e salvo
1760721883614:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1760721883615:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1760721883616:"cluster_total_cells", "pct_within_cluster"))
1760721883617:out3 <- paste0("_summary_cluster_celltype_sampletype.csv")
1760721883618:fwrite(tab_ct_st, out3)
1760721883621:#TASK4.1
1760721883622:#Provide a plot describing the distribution of the cell type in normal/tumor tissue
1760721883623:#given the integration clusters.
1760721883624:# Usiamo il file che hai già creato nel Task 1
1760721883625:# (quello con le colonne: cell_type, integration_cluster, sample_type)
1760721883626:data <- combined
1760721883629:# Contiamo quante celle ci sono per combinazione di cluster, tipo di cellula e tipo di tessuto
1760721883630:counts <- as.data.frame(table(data$integration_cluster, data$cell_type, data$sample_type))
1760721883635:names(counts) <- c("cluster", "cell_type", "tissue", "count")
1760721883636:# Calcoliamo la percentuale di ogni cell_type dentro ciascun cluster e tessuto
1760721883637:# Per farlo, prima troviamo il totale per cluster e tessuto
1760721883637:totals <- aggregate(count ~ cluster + tissue, data = counts, sum)
1760721883641:names(totals)[3] <- "total" #cambia il nome della terza colonna da counts a total
1760721883642:# Ora uniamo le due tabelle
1760721883643:counts2 <- merge(counts, totals, by = c("cluster", "tissue"))
1760721883651:# Calcoliamo la percentuale
1760721883652:counts2$percent <- (counts2$count / counts2$total) * 100
1760721883653:# Facciamo il grafico
1760721883654:ggplot(counts2, aes(x = cluster, y = percent, fill = cell_type)) +
1760721883654:geom_bar(stat = "identity") +
1760721883655:facet_wrap(~ tissue) +
1760721883656:labs(title = "Distribution of cell types in clusters",
1760721883657:x = "Integration cluster",
1760721883657:y = "Cells percentage (%)") +
1760721883658:theme_minimal() +
1760721883659:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1760721884937:#TASK5.1
1760721884937:#Provide a normalized % for the cell types in each of the integration clusters
1760721884938:#for normal and tumor specimen.
1760721884939:# Ripartiamo dai conteggi usati nel grafico
1760721884940:counts <- as.data.frame(table(data$integration_cluster, data$cell_type, data$sample_type))
1760721884944:names(counts) <- c("cluster", "cell_type", "tissue", "count")
1760721884945:# Calcoliamo il totale per ogni cluster e tessuto
1760721884946:totals <- aggregate(count ~ cluster + tissue, data = counts, sum)
1760721884949:names(totals)[3] <- "total"
1760721884950:# Uniamo i totali ai conteggi
1760721884951:final_table <- merge(counts, totals, by = c("cluster", "tissue"))
1760721884958:# Calcoliamo la percentuale
1760721884959:final_table$percent <- round((final_table$count / final_table$total) * 100, 2)
1760721884959:#prende la colonna count e la colonna total di final_table, le divide e le moltiplica x 100
1760721884960:#arrotondando (round) alla seconda cifra decimale , 2)
1760721884961:# Ordiniamo per cluster
1760721884962:final_table <- final_table[order(final_table$cluster), ]
1760721884964:# Salviamo il risultato in un file
1760721884964:write.csv(final_table, "project_oct25/final_revision_percentages_simple.csv", row.names = FALSE)
1760721884972:# Mostriamo le prime righe
1760721884973:head(final_table, 10)
1760725968641:#Goal: Map SNPs to genes.
1760725968644:#Data: variants.csv, gene_annotation.bed.csv
1760725968647:#Tasks:
1760725968648:#• Convert variant positions to 1-bp intervals (pos, pos)
1760725968649:#and find overlaps with gene intervals.
1760725968649:#• Summarize counts of HIGH impact variants by gene and by sample.
1760725968650:#• List genes with HIGH-impact variants across all samples.
1760725968652:#Obiettivo:
1760725968653:#mappare le varianti (SNP) sui geni
1760725968654:#contare le varianti ad alto impatto (HIGH) per gene e per campione
1760725968655:#ottenere la lista dei geni che presentano almeno una variante HIGH in qualsiasi campione
1760725968657:# carico la libreria
1760725968657:library(data.table)
1760725968659:# leggo i file
1760725968660:variants <- fread("project_oct25/variants.csv")
1760725968663:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760725968667:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1760725968668:#    (foverlaps lavora con intervalli start-end)
1760725968668:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1760725968670:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1760725968673:# 5) imposto le chiavi per foverlaps: (chr, start, end), requisito per foverlaps utile per velocizzare
1760725968673:setkey(variants, chr, start, end)
1760725968675:setkey(genes,    chr, start, end)
1760725968677:# 6) eseguo l'overlap: trovo per ogni variante i geni che si sovrappongono
1760725968677:#    nomatch = 0L rimuove le varianti senza overlap, che non sovrappongono alcun gene
1760725968678:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1760725968689:#type any cioè prende qualsiasi sovrapposizione (parziale o completa)
1760725968691:# 7) filtro le varianti di alto impatto (impact == "HIGH")
1760725968691:#    normalizzo il valore di impact a maiuscole per sicurezza
1760725968692:overlaps[, impact_upper := toupper(impact)] #normalizzo il campo impact
1760725968694:#overlaps	È il nome della tabella su cui stai lavorando (una data.table).
1760725968695:#[,]	In data.table, serve per dire “fai qualcosa su questa tabella”.
1760725968695:#impact_upper := ...	Con := stai creando una nuova colonna chiamata impact_upper, oppure sovrascrivendo se già esiste.
1760725968696:#toupper(impact)	È una funzione di R che trasforma tutto il testo in maiuscolo prendendo i valori della colonna impact.
1760725968697:high_overlaps <- overlaps[impact_upper == "HIGH"] #seleziono solo le varianti con impact HIGH
1760725968701:# 8) conto le varianti HIGH per gene e per sample_id
1760725968702:#conta quante varianti ci sono per coppia gene x sample_id
1760725968702:#.N è il conteggio delle righe del gruppo
1760725968703:high_counts_by_gene_sample <- high_overlaps[, .(
1760725968704:high_variant_count = .N
1760725968705:), by = .(gene, sample_id)]
1760725968708:# 9) conto le varianti HIGH per gene (tutte le sample aggregate)
1760725968708:high_counts_by_gene <- high_overlaps[, .(
1760725968709:total_high_variants = .N
1760725968710:), by = gene][order(-total_high_variants)]
1760725968712:#conta quanti HIGH per gene complessivamente e ordina decrescente i geni
1760725968713:# 10) lista dei geni che hanno almeno una variante HIGH (unique gene)
1760725968714:#Estrae i geni con almeno una variante HIGH
1760725968715:genes_with_high <- unique(high_counts_by_gene$gene)
1760725968716:# 11) (Opzionale) salvo i risultati su file CSV nella cartella project_oct25
1760725968717:fwrite(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv")
1760725968718:fwrite(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv")
1760725968719:fwrite(data.table(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv")
1760726033532:# =========================================================
1760726033534:# TASK 11 (versione base R con data.frame)
1760726033535:# Goal:
1760726033536:# - Mappare varianti (SNP) ai geni
1760726033537:# - Contare varianti ad alto impatto (HIGH) per gene e per sample
1760726033538:# =========================================================
1760726033539:# 1️⃣ Carico i dati -----------------------------------------------------------
1760726033540:variants <- read.csv("project_oct25/variants.csv")
1760726033546:genes    <- read.csv("project_oct25/gene_annotation.bed.csv")
1760726033550:# 2️⃣ Creo intervalli 1-bp per le varianti -----------------------------------
1760726033551:# Ogni variante è un punto, quindi creo due colonne identiche (start, end)
1760726033552:variants$start <- variants$pos
1760726033553:variants$end   <- variants$pos
1760726033554:# 3️⃣ Trovo le varianti che si sovrappongono a ciascun gene ------------------
1760726033555:# (equivalente a foverlaps)
1760726033555:# Facciamo un ciclo semplice: per ogni variante controlliamo se rientra nell’intervallo del gene
1760726033556:# Questo è molto meno efficiente, ma chiaro e comprensibile
1760726033557:overlaps_list <- list()
1760726033558:for (i in seq_len(nrow(variants))) {
1760726033559:var_chr   <- variants$chr[i]
1760726033560:var_start <- variants$start[i]
1760726033560:var_end   <- variants$end[i]
1760726033561:# Trova i geni sullo stesso cromosoma che si sovrappongono a quella variante
1760726033562:overlapping_genes <- subset(genes,
1760726033563:chr == var_chr &
1760726033563:start <= var_end &
1760726033564:end >= var_start)
1760726033565:# Se ci sono geni che si sovrappongono, li aggiungo alla lista
1760726033565:if (nrow(overlapping_genes) > 0) {
1760726033566:tmp <- data.frame(
1760726033567:sample_id = variants$sample_id[i],
1760726033568:gene = overlapping_genes$gene,
1760726033568:chr = var_chr,
1760726033569:pos = var_start,
1760726033570:impact = variants$impact[i],
1760726033570:stringsAsFactors = FALSE
1760726033571:)
1760726033571:overlaps_list[[length(overlaps_list) + 1]] <- tmp
1760726033572:}
1760726033573:}
1760726034131:# Combino tutti i risultati in un unico data.frame
1760726034132:if (length(overlaps_list) > 0) {
1760726034133:overlaps <- do.call(rbind, overlaps_list)
1760726034133:} else {
1760726034134:overlaps <- data.frame()
1760726034135:}
1760726034195:# 4️⃣ Normalizzo la colonna impact a maiuscolo --------------------------------
1760726034196:if (nrow(overlaps) > 0) {
1760726034198:overlaps$impact_upper <- toupper(overlaps$impact)
1760726034199:}
1760726034203:# 5️⃣ Filtro solo le varianti di alto impatto ---------------------------------
1760726034205:high_overlaps <- subset(overlaps, impact_upper == "HIGH")
1760726034210:# 6️⃣ Conteggio delle varianti HIGH per gene e per sample ---------------------
1760726034211:if (nrow(high_overlaps) > 0) {
1760726034212:high_counts_by_gene_sample <- aggregate(
1760726034213:x = list(high_variant_count = high_overlaps$impact_upper),
1760726034213:by = list(gene = high_overlaps$gene, sample_id = high_overlaps$sample_id),
1760726034214:FUN = length
1760726034215:)
1760726034216:} else {
1760726034216:high_counts_by_gene_sample <- data.frame()
1760726034217:}
1760726034222:# 7️⃣ Conteggio totale delle varianti HIGH per gene --------------------------
1760726034223:if (nrow(high_overlaps) > 0) {
1760726034224:high_counts_by_gene <- aggregate(
1760726034225:x = list(total_high_variants = high_overlaps$impact_upper),
1760726034226:by = list(gene = high_overlaps$gene),
1760726034227:FUN = length
1760726034228:)
1760726034229:# Ordina in modo decrescente
1760726034230:high_counts_by_gene <- high_counts_by_gene[order(-high_counts_by_gene$total_high_variants), ]
1760726034233:# Geni con almeno una variante HIGH
1760726034234:genes_with_high <- unique(high_counts_by_gene$gene)
1760726034235:} else {
1760726034236:high_counts_by_gene <- data.frame()
1760726034237:genes_with_high <- character(0)
1760726034238:}
1760726034242:# 8️⃣ Salvo i risultati su file CSV ------------------------------------------
1760726034242:write.csv(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv", row.names = FALSE)
1760726034244:write.csv(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv", row.names = FALSE)
1760726034245:write.csv(data.frame(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv", row.names = FALSE)
1760726034248:cat("\nAnalisi completata. File salvati in project_oct25/.\n")
1760784649472:View(overlapping_genes)
1760784748316:# 1️⃣ Carico i dati -----------------------------------------------------------
1760784748320:variants <- read.csv("project_oct25/variants.csv")
1760784748689:genes    <- read.csv("project_oct25/gene_annotation.bed.csv")
1760784749639:# 2️⃣ Creo intervalli 1-bp per le varianti -----------------------------------
1760784749644:# Ogni variante è un punto, quindi creo due colonne identiche (start, end)
1760784749647:variants$start <- variants$pos
1760784750913:variants$end   <- variants$pos
1760784752170:# 3 Trovo le varianti che si sovrappongono a ciascun gene ------------------
1760784752178:# (equivalente a foverlaps)
1760784752180:# Facciamo un ciclo semplice: per ogni variante controlliamo se rientra nell’intervallo del gene
1760784752182:# Questo è molto meno efficiente, ma chiaro e comprensibile
1760784752185:overlaps_list <- list()
1760784777592:View(variants)
1760784794934:?seq_len
1760784816963:for (i in seq_len(nrow(variants))) {
1760784816964:var_chr   <- variants$chr[i]
1760784816967:var_start <- variants$start[i]
1760784816968:var_end   <- variants$end[i]
1760784816971:# Trova i geni sullo stesso cromosoma che si sovrappongono a quella variante?????
1760784816972:#???????OVERLAPPING_GENES 0 OBS
1760784816973:overlapping_genes <- subset(genes,
1760784816973:chr == var_chr &
1760784816974:start <= var_end &
1760784816975:end >= var_start)
1760784816976:# Se ci sono geni che si sovrappongono, li aggiungo alla lista
1760784816977:if (nrow(overlapping_genes) > 0) {
1760784816977:tmp <- data.frame(
1760784816978:sample_id = variants$sample_id[i],
1760784816979:gene = overlapping_genes$gene,
1760784816979:chr = var_chr,
1760784816980:pos = var_start,
1760784816981:impact = variants$impact[i],
1760784816981:stringsAsFactors = FALSE
1760784816982:)
1760784816983:overlaps_list[[length(overlaps_list) + 1]] <- tmp
1760784816984:}
1760784816984:}
1760784952067:View(overlaps_list)
1760784984602:#Goal: Map SNPs to genes.
1760784984607:#Data: variants.csv, gene_annotation.bed.csv
1760784984609:#Tasks:
1760784984610:#• Convert variant positions to 1-bp intervals (pos, pos)
1760784984615:#and find overlaps with gene intervals.
1760784984616:#• Summarize counts of HIGH impact variants by gene and by sample.
1760784984617:#• List genes with HIGH-impact variants across all samples.
1760784984618:#Obiettivo:
1760784984619:#mappare le varianti (SNP) sui geni
1760784984620:#contare le varianti ad alto impatto (HIGH) per gene e per campione
1760784984621:#ottenere la lista dei geni che presentano almeno una variante HIGH in qualsiasi campione
1760784984623:# carico la libreria
1760784984624:library(data.table)
1760784984625:# leggo i file
1760784984626:variants <- fread("project_oct25/variants.csv")
1760784984633:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760784984638:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1760784984639:#    (foverlaps lavora con intervalli start-end)
1760784984640:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1760784984656:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1760784984659:# 5) imposto le chiavi per foverlaps: (chr, start, end), requisito per foverlaps utile per velocizzare
1760784984660:setkey(variants, chr, start, end)
1760784984663:setkey(genes,    chr, start, end)
1760784984665:# 6) eseguo l'overlap: trovo per ogni variante i geni che si sovrappongono
1760784984666:#    nomatch = 0L rimuove le varianti senza overlap, che non sovrappongono alcun gene
1760784984667:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1760784984679:#type any cioè prende qualsiasi sovrapposizione (parziale o completa)
1760784984680:# 7) filtro le varianti di alto impatto (impact == "HIGH")
1760784984681:#    normalizzo il valore di impact a maiuscole per sicurezza
1760784984682:overlaps[, impact_upper := toupper(impact)] #normalizzo il campo impact
1760784984684:#overlaps	È il nome della tabella su cui stai lavorando (una data.table).
1760784984685:#[,]	In data.table, serve per dire “fai qualcosa su questa tabella”.
1760784984686:#impact_upper := ...	Con := stai creando una nuova colonna chiamata impact_upper, oppure sovrascrivendo se già esiste.
1760784984686:#toupper(impact)	È una funzione di R che trasforma tutto il testo in maiuscolo prendendo i valori della colonna impact.
1760784984688:high_overlaps <- overlaps[impact_upper == "HIGH"] #seleziono solo le varianti con impact HIGH
1760784984694:# 8) conto le varianti HIGH per gene e per sample_id
1760784984695:#conta quante varianti ci sono per coppia gene x sample_id
1760784984695:#.N è il conteggio delle righe del gruppo
1760784984696:high_counts_by_gene_sample <- high_overlaps[, .(
1760784984697:high_variant_count = .N
1760784984697:), by = .(gene, sample_id)]
1760784984700:# 9) conto le varianti HIGH per gene (tutte le sample aggregate)
1760784984701:high_counts_by_gene <- high_overlaps[, .(
1760784984702:total_high_variants = .N
1760784984702:), by = gene][order(-total_high_variants)]
1760784984705:#conta quanti HIGH per gene complessivamente e ordina decrescente i geni
1760784984706:# 10) lista dei geni che hanno almeno una variante HIGH (unique gene)
1760784984708:#Estrae i geni con almeno una variante HIGH
1760784984708:genes_with_high <- unique(high_counts_by_gene$gene)
1760784984710:# 11) (Opzionale) salvo i risultati su file CSV nella cartella project_oct25
1760784984710:fwrite(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv")
1760784984712:fwrite(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv")
1760784984713:fwrite(data.table(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv")
1760786317351:# carico la libreria
1760786317364:library(data.table)
1760786317506:# leggo i file
1760786317513:variants <- fread("project_oct25/variants.csv")
1760786317683:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760786317827:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1760786317830:#    (foverlaps lavora con intervalli start-end)
1760786317832:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1760786317990:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1760786318160:# 5) imposto le chiavi per foverlaps: (chr, start, end), requisito per foverlaps utile per velocizzare
1760786318164:setkey(variants, chr, start, end)
1760786318381:setkey(genes,    chr, start, end)
1760786318463:# 6) eseguo l'overlap: trovo per ogni variante i geni che si sovrappongono
1760786318467:#    nomatch = 0L rimuove le varianti senza overlap, che non sovrappongono alcun gene
1760786318469:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1760786318678:# 7) filtro le varianti di alto impatto (impact == "HIGH")
1760786318681:#    normalizzo il valore di impact a maiuscole per sicurezza
1760786318683:overlaps[, impact_upper := toupper(impact)] #normalizzo il campo impact
1760786318796:high_overlaps <- overlaps[impact_upper == "HIGH"] #seleziono solo le varianti con impact HIGH
1760786319109:# 8) conto le varianti HIGH per gene e per sample_id
1760786319111:#conta quante varianti ci sono per coppia gene x sample_id
1760786319112:#.N è il conteggio delle righe del gruppo
1760786319113:high_counts_by_gene_sample <- high_overlaps[, .(
1760786319114:high_variant_count = .N
1760786319115:), by = .(gene, sample_id)]
1760786319220:# 9) conto le varianti HIGH per gene (tutte le sample aggregate)
1760786319225:high_counts_by_gene <- high_overlaps[, .(
1760786319226:total_high_variants = .N
1760786319228:), by = gene][order(-total_high_variants)]
1760786319398:# 10) lista dei geni che hanno almeno una variante HIGH (unique gene)
1760786319402:#Estrae i geni con almeno una variante HIGH
1760786319404:genes_with_high <- unique(high_counts_by_gene$gene)
1760786319602:# 11) (Opzionale) salvo i risultati su file CSV nella cartella project_oct25
1760786319606:fwrite(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv")
1760786319759:fwrite(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv")
1760786320224:fwrite(data.table(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv")
1760786335083:View(overlaps)
1760786345689:# 1️⃣ Carico i dati -----------------------------------------------------------
1760786345694:variants <- read.csv("project_oct25/variants.csv")
1760786350347:genes    <- read.csv("project_oct25/gene_annotation.bed.csv")
1760786351807:# 2️⃣ Creo intervalli 1-bp per le varianti -----------------------------------
1760786351810:# Ogni variante è un punto, quindi creo due colonne identiche (start, end)
1760786351813:variants$start <- variants$pos
1760786352656:variants$end   <- variants$pos
1760786355177:# 3 Trovo le varianti che si sovrappongono a ciascun gene ------------------
1760786355180:# (equivalente a foverlaps)
1760786355182:# Facciamo un ciclo semplice: per ogni variante controlliamo se rientra nell’intervallo del gene
1760786355183:# Questo è molto meno efficiente, ma chiaro e comprensibile
1760786355185:overlaps_list <- list()
1760786357302:for (i in seq_len(nrow(variants))) {
1760786357304:var_chr   <- variants$chr[i]
1760786357305:var_start <- variants$start[i]
1760786357307:var_end   <- variants$end[i]
1760786357311:# Trova i geni sullo stesso cromosoma che si sovrappongono a quella variante?????
1760786357312:#???????OVERLAPPING_GENES 0 OBS
1760786357313:overlapping_genes <- subset(genes,
1760786357314:chr == var_chr &
1760786357316:start <= var_end &
1760786357318:end >= var_start)
1760786357322:# Se ci sono geni che si sovrappongono, li aggiungo alla lista
1760786357335:if (nrow(overlapping_genes) > 0) {
1760786357343:tmp <- data.frame(
1760786357347:sample_id = variants$sample_id[i],
1760786357348:gene = overlapping_genes$gene,
1760786357350:chr = var_chr,
1760786357351:pos = var_start,
1760786357352:impact = variants$impact[i],
1760786357353:stringsAsFactors = FALSE
1760786357354:)
1760786357355:overlaps_list[[length(overlaps_list) + 1]] <- tmp
1760786357358:}
1760786357359:}
1760786369313:View(overlapping_genes)
1760786422722:# Se ci sono geni che si sovrappongono, li aggiungo alla lista
1760786422726:if (nrow(overlapping_genes) > 0) {
1760786422728:tmp <- data.frame(
1760786422732:sample_id = variants$sample_id[i],
1760786422733:gene = overlapping_genes$gene,
1760786422735:chr = var_chr,
1760786422737:pos = var_start,
1760786422741:impact = variants$impact[i],
1760786422743:stringsAsFactors = FALSE
1760786422744:)
1760786422747:overlaps_list[[length(overlaps_list) + 1]] <- tmp
1760786422749:}
1760786424406:for (i in seq_len(nrow(variants))) {
1760786424409:var_chr   <- variants$chr[i]
1760786424412:var_start <- variants$start[i]
1760786424414:var_end   <- variants$end[i]
1760786424418:# Trova i geni sullo stesso cromosoma che si sovrappongono a quella variante?????
1760786424425:#???????OVERLAPPING_GENES 0 OBS
1760786424428:overlapping_genes <- subset(genes,
1760786424429:chr == var_chr &
1760786424432:start <= var_end &
1760786424434:end >= var_start)
1760786424439:# Se ci sono geni che si sovrappongono, li aggiungo alla lista
1760786424444:if (nrow(overlapping_genes) > 0) {
1760786424445:tmp <- data.frame(
1760786424447:sample_id = variants$sample_id[i],
1760786424451:gene = overlapping_genes$gene,
1760786424453:chr = var_chr,
1760786424454:pos = var_start,
1760786424456:impact = variants$impact[i],
1760786424459:stringsAsFactors = FALSE
1760786424462:)
1760786424465:overlaps_list[[length(overlaps_list) + 1]] <- tmp
1760786424467:}
1760786424469:}
1760786425489:# Combino tutti i risultati in un unico data.frame
1760786425493:if (length(overlaps_list) > 0) {
1760786425495:overlaps <- do.call(rbind, overlaps_list)
1760786425497:} else {
1760786425499:overlaps <- data.frame()
1760786425501:}
1760786426390:# 4️⃣ Normalizzo la colonna impact a maiuscolo --------------------------------
1760786426392:if (nrow(overlaps) > 0) {
1760786426397:overlaps$impact_upper <- toupper(overlaps$impact)
1760786426400:}
1760786427058:# 5️⃣ Filtro solo le varianti di alto impatto ---------------------------------
1760786427066:high_overlaps <- subset(overlaps, impact_upper == "HIGH")
1760786427725:# 6️⃣ Conteggio delle varianti HIGH per gene e per sample ---------------------
1760786427731:if (nrow(high_overlaps) > 0) {
1760786427733:high_counts_by_gene_sample <- aggregate(
1760786427735:x = list(high_variant_count = high_overlaps$impact_upper),
1760786427736:by = list(gene = high_overlaps$gene, sample_id = high_overlaps$sample_id),
1760786427738:FUN = length
1760786427740:)
1760786427741:} else {
1760786427742:high_counts_by_gene_sample <- data.frame()
1760786427744:}
1760786428477:# 7️⃣ Conteggio totale delle varianti HIGH per gene --------------------------
1760786428482:if (nrow(high_overlaps) > 0) {
1760786428485:high_counts_by_gene <- aggregate(
1760786428489:x = list(total_high_variants = high_overlaps$impact_upper),
1760786428493:by = list(gene = high_overlaps$gene),
1760786428495:FUN = length
1760786428500:)
1760786428506:# Ordina in modo decrescente
1760786428508:high_counts_by_gene <- high_counts_by_gene[order(-high_counts_by_gene$total_high_variants), ]
1760786428512:# Geni con almeno una variante HIGH
1760786428515:genes_with_high <- unique(high_counts_by_gene$gene)
1760786428516:} else {
1760786428519:high_counts_by_gene <- data.frame()
1760786428520:genes_with_high <- character(0)
1760786428521:}
1760786429151:# 8️⃣ Salvo i risultati su file CSV ------------------------------------------
1760786429156:write.csv(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv", row.names = FALSE)
1760786429864:write.csv(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv", row.names = FALSE)
1760786430597:write.csv(data.frame(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv", row.names = FALSE)
1760786431421:cat("\nAnalisi completata. File salvati in project_oct25/.\n")
1760786446124:View(overlaps_list)
1760786458206:# 1️⃣ Carico i dati -----------------------------------------------------------
1760786458210:variants <- read.csv("project_oct25/variants.csv")
1760786458696:genes    <- read.csv("project_oct25/gene_annotation.bed.csv")
1760786459627:# 2️⃣ Creo intervalli 1-bp per le varianti -----------------------------------
1760786459631:# Ogni variante è un punto, quindi creo due colonne identiche (start, end)
1760786459633:variants$start <- variants$pos
1760786460353:variants$end   <- variants$pos
1760786461200:# 3 Trovo le varianti che si sovrappongono a ciascun gene ------------------
1760786461203:# (equivalente a foverlaps)
1760786461206:# Facciamo un ciclo semplice: per ogni variante controlliamo se rientra nell’intervallo del gene
1760786461208:# Questo è molto meno efficiente, ma chiaro e comprensibile
1760786461209:overlaps_list <- list()
1760786464013:for (i in seq_len(nrow(variants))) {
1760786464015:var_chr   <- variants$chr[i]
1760786464018:var_start <- variants$start[i]
1760786464020:var_end   <- variants$end[i]
1760786464023:# Trova i geni sullo stesso cromosoma che si sovrappongono a quella variante?????
1760786464024:#???????OVERLAPPING_GENES 0 OBS
1760786464026:overlapping_genes <- subset(genes,
1760786464027:chr == var_chr &
1760786464028:start <= var_end &
1760786464030:end >= var_start)
1760786464034:# Se ci sono geni che si sovrappongono, li aggiungo alla lista
1760786464036:if (nrow(overlapping_genes) > 0) {
1760786464039:tmp <- data.frame(
1760786464042:sample_id = variants$sample_id[i],
1760786464045:gene = overlapping_genes$gene,
1760786464048:chr = var_chr,
1760786464051:pos = var_start,
1760786464052:impact = variants$impact[i],
1760786464054:stringsAsFactors = FALSE
1760786464056:)
1760786464057:overlaps_list[[length(overlaps_list) + 1]] <- tmp
1760786464058:}
1760786464059:}
1760786470922:# Combino tutti i risultati in un unico data.frame
1760786470928:if (length(overlaps_list) > 0) {
1760786470931:overlaps <- do.call(rbind, overlaps_list)
1760786470932:} else {
1760786470934:overlaps <- data.frame()
1760786470935:}
1760786759776:# =========================================================
1760786759778:# TASK 11 (versione base R con data.frame)
1760786759779:# Goal:
1760786759780:# - Mappare varianti (SNP) ai geni
1760786759782:# - Contare varianti ad alto impatto (HIGH) per gene e per sample
1760786759784:# =========================================================
1760786759788:# 1️⃣ Carico i dati -----------------------------------------------------------
1760786759789:variants <- read.csv("project_oct25/variants.csv")
1760786759799:genes    <- read.csv("project_oct25/gene_annotation.bed.csv")
1760786759803:# 2️⃣ Creo intervalli 1-bp per le varianti -----------------------------------
1760786759805:# Ogni variante è un punto, quindi creo due colonne identiche (start, end)
1760786759806:variants$start <- variants$pos
1760786759807:variants$end   <- variants$pos
1760786759809:# 3 Trovo le varianti che si sovrappongono a ciascun gene ------------------
1760786759810:# (equivalente a foverlaps)
1760786759811:# Facciamo un ciclo semplice: per ogni variante controlliamo se rientra nell’intervallo del gene
1760786759812:# Questo è molto meno efficiente, ma chiaro e comprensibile
1760786759813:overlaps_list <- list()
1760786759814:for (i in seq_len(nrow(variants))) {
1760786759815:var_chr   <- variants$chr[i]
1760786759816:var_start <- variants$start[i]
1760786759817:var_end   <- variants$end[i]
1760786759818:# Trova i geni sullo stesso cromosoma che si sovrappongono a quella variante?????
1760786759819:#???????OVERLAPPING_GENES 0 OBS
1760786759820:overlapping_genes <- subset(genes,
1760786759821:chr == var_chr &
1760786759822:start <= var_end &
1760786759823:end >= var_start)
1760786759824:# Se ci sono geni che si sovrappongono, li aggiungo alla lista
1760786759825:if (nrow(overlapping_genes) > 0) {
1760786759825:tmp <- data.frame(
1760786759826:sample_id = variants$sample_id[i],
1760786759827:gene = overlapping_genes$gene,
1760786759827:chr = var_chr,
1760786759828:pos = var_start,
1760786759829:impact = variants$impact[i],
1760786759830:stringsAsFactors = FALSE
1760786759830:)
1760786759831:overlaps_list[[length(overlaps_list) + 1]] <- tmp
1760786759832:}
1760786759832:}
1760786760555:# Combino tutti i risultati in un unico data.frame
1760786760555:if (length(overlaps_list) > 0) {
1760786760556:overlaps <- do.call(rbind, overlaps_list)
1760786760557:} else {
1760786760557:overlaps <- data.frame()
1760786760558:}
1760786760618:# 4️⃣ Normalizzo la colonna impact a maiuscolo --------------------------------
1760786760619:if (nrow(overlaps) > 0) {
1760786760621:overlaps$impact_upper <- toupper(overlaps$impact)
1760786760623:}
1760786760627:# 5️⃣ Filtro solo le varianti di alto impatto ---------------------------------
1760786760628:high_overlaps <- subset(overlaps, impact_upper == "HIGH")
1760786760632:# 6️⃣ Conteggio delle varianti HIGH per gene e per sample ---------------------
1760786760633:if (nrow(high_overlaps) > 0) {
1760786760634:high_counts_by_gene_sample <- aggregate(
1760786760634:x = list(high_variant_count = high_overlaps$impact_upper),
1760786760635:by = list(gene = high_overlaps$gene, sample_id = high_overlaps$sample_id),
1760786760637:FUN = length
1760786760637:)
1760786760638:} else {
1760786760639:high_counts_by_gene_sample <- data.frame()
1760786760640:}
1760786760644:# 7️⃣ Conteggio totale delle varianti HIGH per gene --------------------------
1760786760645:if (nrow(high_overlaps) > 0) {
1760786760647:high_counts_by_gene <- aggregate(
1760786760648:x = list(total_high_variants = high_overlaps$impact_upper),
1760786760649:by = list(gene = high_overlaps$gene),
1760786760650:FUN = length
1760786760651:)
1760786760653:# Ordina in modo decrescente
1760786760653:high_counts_by_gene <- high_counts_by_gene[order(-high_counts_by_gene$total_high_variants), ]
1760786760656:# Geni con almeno una variante HIGH
1760786760657:genes_with_high <- unique(high_counts_by_gene$gene)
1760786760658:} else {
1760786760659:high_counts_by_gene <- data.frame()
1760786760660:genes_with_high <- character(0)
1760786760661:}
1760786760666:# 8️⃣ Salvo i risultati su file CSV ------------------------------------------
1760786760666:write.csv(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv", row.names = FALSE)
1760786760669:write.csv(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv", row.names = FALSE)
1760786760671:write.csv(data.frame(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv", row.names = FALSE)
1760786760674:cat("\nAnalisi completata. File salvati in project_oct25/.\n")
1760786791116:#Goal: Map SNPs to genes.
1760786791120:#Data: variants.csv, gene_annotation.bed.csv
1760786791123:#Tasks:
1760786791127:#• Convert variant positions to 1-bp intervals (pos, pos)
1760786791133:#and find overlaps with gene intervals.
1760786791137:#• Summarize counts of HIGH impact variants by gene and by sample.
1760786791138:#• List genes with HIGH-impact variants across all samples.
1760786791140:#Obiettivo:
1760786791142:#mappare le varianti (SNP) sui geni
1760786791143:#contare le varianti ad alto impatto (HIGH) per gene e per campione
1760786791145:#ottenere la lista dei geni che presentano almeno una variante HIGH in qualsiasi campione
1760786791149:# carico la libreria
1760786791151:library(data.table)
1760786791155:# leggo i file
1760786791157:variants <- fread("project_oct25/variants.csv")
1760786791162:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760786791166:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1760786791167:#    (foverlaps lavora con intervalli start-end)
1760786791168:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1760786791171:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1760786791174:# 5) imposto le chiavi per foverlaps: (chr, start, end), requisito per foverlaps utile per velocizzare
1760786791175:setkey(variants, chr, start, end)
1760786791176:setkey(genes,    chr, start, end)
1760786791178:# 6) eseguo l'overlap: trovo per ogni variante i geni che si sovrappongono
1760786791179:#    nomatch = 0L rimuove le varianti senza overlap, che non sovrappongono alcun gene
1760786791180:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1760786791188:#type any cioè prende qualsiasi sovrapposizione (parziale o completa)
1760786791190:# 7) filtro le varianti di alto impatto (impact == "HIGH")
1760786791191:#    normalizzo il valore di impact a maiuscole per sicurezza
1760786791192:overlaps[, impact_upper := toupper(impact)] #normalizzo il campo impact
1760786791194:#overlaps	È il nome della tabella su cui stai lavorando (una data.table).
1760786791194:#[,]	In data.table, serve per dire “fai qualcosa su questa tabella”.
1760786791195:#impact_upper := ...	Con := stai creando una nuova colonna chiamata impact_upper, oppure sovrascrivendo se già esiste.
1760786791196:#toupper(impact)	È una funzione di R che trasforma tutto il testo in maiuscolo prendendo i valori della colonna impact.
1760786791197:high_overlaps <- overlaps[impact_upper == "HIGH"] #seleziono solo le varianti con impact HIGH
1760786791201:# 8) conto le varianti HIGH per gene e per sample_id
1760786791201:#conta quante varianti ci sono per coppia gene x sample_id
1760786791202:#.N è il conteggio delle righe del gruppo
1760786791203:high_counts_by_gene_sample <- high_overlaps[, .(
1760786791204:high_variant_count = .N
1760786791204:), by = .(gene, sample_id)]
1760786791207:# 9) conto le varianti HIGH per gene (tutte le sample aggregate)
1760786791207:high_counts_by_gene <- high_overlaps[, .(
1760786791208:total_high_variants = .N
1760786791209:), by = gene][order(-total_high_variants)]
1760786791211:#conta quanti HIGH per gene complessivamente e ordina decrescente i geni
1760786791212:# 10) lista dei geni che hanno almeno una variante HIGH (unique gene)
1760786791213:#Estrae i geni con almeno una variante HIGH
1760786791214:genes_with_high <- unique(high_counts_by_gene$gene)
1760786791215:# 11) (Opzionale) salvo i risultati su file CSV nella cartella project_oct25
1760786791216:fwrite(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv")
1760786791217:fwrite(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv")
1760786791218:fwrite(data.table(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv")
1760786975970:View(high_counts_by_gene)
1760786978344:View(high_counts_by_gene_sample)
1760786983218:View(overlaps)
1760786985365:View(variants)
1760787016632:View(overlaps)
1760787040763:View(high_counts_by_gene_sample)
1760787045571:View(high_counts_by_gene)
1760787056446:View(genes)
1760787063096:View(variants)
1760787113372:View(genes)
1760787142515:genes_with_high
1760787168082:#Goal: Map SNPs to genes.
1760787168085:#Data: variants.csv, gene_annotation.bed.csv
1760787168087:#Tasks:
1760787168089:#• Convert variant positions to 1-bp intervals (pos, pos)
1760787168092:#and find overlaps with gene intervals.
1760787168093:#• Summarize counts of HIGH impact variants by gene and by sample.
1760787168093:#• List genes with HIGH-impact variants across all samples.
1760787168095:#Obiettivo:
1760787168096:#mappare le varianti (SNP) sui geni
1760787168096:#contare le varianti ad alto impatto (HIGH) per gene e per campione
1760787168097:#ottenere la lista dei geni che presentano almeno una variante HIGH in qualsiasi campione
1760787168098:# carico la libreria
1760787168099:library(data.table)
1760787168101:# leggo i file
1760787168102:variants <- fread("project_oct25/variants.csv")
1760787168106:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760787168110:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1760787168111:#    (foverlaps lavora con intervalli start-end)
1760787168111:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1760787168114:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1760787168116:# 5) imposto le chiavi per foverlaps: (chr, start, end), requisito per foverlaps utile per velocizzare
1760787168117:setkey(variants, chr, start, end)
1760787168119:setkey(genes,    chr, start, end)
1760787168122:# 6) eseguo l'overlap: trovo per ogni variante i geni che si sovrappongono
1760787168123:#    nomatch = 0L rimuove le varianti senza overlap, che non sovrappongono alcun gene
1760787168124:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1760787168131:#type any cioè prende qualsiasi sovrapposizione (parziale o completa)
1760787168133:# 7) filtro le varianti di alto impatto (impact == "HIGH")
1760787168134:#    normalizzo il valore di impact a maiuscole per sicurezza
1760787168134:overlaps[, impact_upper := toupper(impact)] #normalizzo il campo impact
1760787168136:#overlaps	È il nome della tabella su cui stai lavorando (una data.table).
1760787168137:#[,]	In data.table, serve per dire “fai qualcosa su questa tabella”.
1760787168137:#impact_upper := ...	Con := stai creando una nuova colonna chiamata impact_upper, oppure sovrascrivendo se già esiste.
1760787168138:#toupper(impact)	È una funzione di R che trasforma tutto il testo in maiuscolo prendendo i valori della colonna impact.
1760787168140:high_overlaps <- overlaps[impact_upper == "HIGH"] #seleziono solo le varianti con impact HIGH
1760787168143:# 8) conto le varianti HIGH per gene e per sample_id
1760787168144:#conta quante varianti ci sono per coppia gene x sample_id
1760787168144:#.N è il conteggio delle righe del gruppo
1760787168145:high_counts_by_gene_sample <- high_overlaps[, .(
1760787168145:high_variant_count = .N
1760787168146:), by = .(gene, sample_id)]
1760787168148:# 9) conto le varianti HIGH per gene (tutte le sample aggregate)
1760787168149:high_counts_by_gene <- high_overlaps[, .(
1760787168150:total_high_variants = .N
1760787168150:), by = gene][order(-total_high_variants)]
1760787168152:#conta quanti HIGH per gene complessivamente e ordina decrescente i geni
1760787168153:# 10) lista dei geni che hanno almeno una variante HIGH (unique gene)
1760787168154:#Estrae i geni con almeno una variante HIGH
1760787168154:genes_with_high <- unique(high_counts_by_gene$gene)
1760787168155:print(genes_with_high)
1760787168157:# 11) (Opzionale) salvo i risultati su file CSV nella cartella project_oct25
1760787168157:fwrite(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv")
1760787168158:fwrite(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv")
1760787168160:fwrite(data.table(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv")
1760787193260:#Goal: Map SNPs to genes.
1760787193267:#Data: variants.csv, gene_annotation.bed.csv
1760787193270:#Tasks:
1760787193272:#• Convert variant positions to 1-bp intervals (pos, pos)
1760787193273:#and find overlaps with gene intervals.
1760787193274:#• Summarize counts of HIGH impact variants by gene and by sample.
1760787193275:#• List genes with HIGH-impact variants across all samples.
1760787193277:#Obiettivo:
1760787193278:#mappare le varianti (SNP) sui geni
1760787193279:#contare le varianti ad alto impatto (HIGH) per gene e per campione
1760787193280:#ottenere la lista dei geni che presentano almeno una variante HIGH in qualsiasi campione
1760787193282:# carico la libreria
1760787193283:library(data.table)
1760787193596:# leggo i file
1760787193597:variants <- fread("project_oct25/variants.csv")
1760787193613:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1760787193617:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1760787193619:#    (foverlaps lavora con intervalli start-end)
1760787193619:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1760787193645:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1760787193664:# 5) imposto le chiavi per foverlaps: (chr, start, end), requisito per foverlaps utile per velocizzare
1760787193665:setkey(variants, chr, start, end)
1760787193692:setkey(genes,    chr, start, end)
1760787193696:# 6) eseguo l'overlap: trovo per ogni variante i geni che si sovrappongono
1760787193697:#    nomatch = 0L rimuove le varianti senza overlap, che non sovrappongono alcun gene
1760787193698:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1760787193718:#type any cioè prende qualsiasi sovrapposizione (parziale o completa)
1760787193723:# 7) filtro le varianti di alto impatto (impact == "HIGH")
1760787193725:#    normalizzo il valore di impact a maiuscole per sicurezza
1760787193730:overlaps[, impact_upper := toupper(impact)] #normalizzo il campo impact
1760787193733:#overlaps	È il nome della tabella su cui stai lavorando (una data.table).
1760787193734:#[,]	In data.table, serve per dire “fai qualcosa su questa tabella”.
1760787193735:#impact_upper := ...	Con := stai creando una nuova colonna chiamata impact_upper, oppure sovrascrivendo se già esiste.
1760787193736:#toupper(impact)	È una funzione di R che trasforma tutto il testo in maiuscolo prendendo i valori della colonna impact.
1760787193739:high_overlaps <- overlaps[impact_upper == "HIGH"] #seleziono solo le varianti con impact HIGH
1760787193798:# 8) conto le varianti HIGH per gene e per sample_id
1760787193799:#conta quante varianti ci sono per coppia gene x sample_id
1760787193800:#.N è il conteggio delle righe del gruppo
1760787193802:high_counts_by_gene_sample <- high_overlaps[, .(
1760787193803:high_variant_count = .N
1760787193805:), by = .(gene, sample_id)]
1760787193811:# 9) conto le varianti HIGH per gene (tutte le sample aggregate)
1760787193812:high_counts_by_gene <- high_overlaps[, .(
1760787193813:total_high_variants = .N
1760787193814:), by = gene][order(-total_high_variants)]
1760787193820:#conta quanti HIGH per gene complessivamente e ordina decrescente i geni
1760787193822:# 10) lista dei geni che hanno almeno una variante HIGH (unique gene)
1760787193823:#Estrae i geni con almeno una variante HIGH
1760787193823:genes_with_high <- unique(high_counts_by_gene$gene)
1760787193824:print(genes_with_high)
1760787193826:# 11) (Opzionale) salvo i risultati su file CSV nella cartella project_oct25
1760787193827:fwrite(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv")
1760787193830:fwrite(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv")
1760787193832:fwrite(data.table(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv")
1760795612251:#' Merge and summarize bulk counts (data.frame version)
1760795612254:#'
1760795612255:#' Combine bulk RNA counts with metadata, filter treated samples,
1760795612256:#' and compute per-gene mean/median counts and per-condition averages.
1760795612257:#'
1760795612258:#' @param counts_path Path to `bulk_counts_long.csv`.
1760795612258:#' @param meta_path Path to `sample_metadata.csv`.
1760795612259:#' @return A list with two data.frames:
1760795612260:#'   \describe{
1760795612261:#'     \item{gene_summary_df}{Mean and median counts by gene (treated samples only).}
1760795612262:#'     \item{gene_condition_means_f}{Mean counts by gene and condition.}
1760795612264:#'   }
1760795612265:#' @export
1760795612266:bulk_counts_summary_df <- function(counts_path, meta_path) {
1760795612267:counts <- read.csv(counts_path)
1760795612268:meta   <- read.csv(meta_path)
1760795612269:merged_data <- merge(counts, meta, by = "sample_id")
1760795612270:treated_data <- subset(merged_data,
1760795612271:condition == "treated" & grepl("^GENE_00", gene))
1760795612272:gene_summary <- aggregate(
1760795612273:count ~ gene,
1760795612274:data = treated_data,
1760795612274:FUN  = function(x) c(mean = mean(x), median = median(x))
1760795612275:)
1760795612277:gene_summary_df <- data.frame(
1760795612277:gene         = gene_summary$gene,
1760795612278:mean_count   = gene_summary$count[, "mean"],
1760795612279:median_count = gene_summary$count[, "median"]
1760795612280:)
1760795612281:gene_condition_means_f <- aggregate(
1760795612282:count ~ gene + condition,
1760795612283:data = merged_data,
1760795612283:FUN  = mean,
1760795612284:na.rm = TRUE
1760795612285:)
1760795612286:gene_condition_means_f <- gene_condition_means_f[order(
1760795612287:gene_condition_means_f$gene, gene_condition_means_f$condition
1760795612287:), ]
1760795612289:list(
1760795612289:gene_summary_df       = gene_summary_df,
1760795612290:gene_condition_means_f = gene_condition_means_f
1760795612291:)
1760795612291:}
1760795620032:View(bulk_counts_summary_df)
1760795702392:#' Merge and summarize bulk counts
1760795702395:#'
1760795702397:#' Combine bulk RNA counts with metadata, filter treated samples,
1760795702401:#' and compute per-gene mean/median counts and per-condition averages.
1760795702405:bulk_counts_summary_df <- function(counts_path, meta_path) {
1760795702406:counts <- read.csv(counts_path)
1760795702407:meta   <- read.csv(meta_path)
1760795702408:merged_data <- merge(counts, meta, by = "sample_id")
1760795702410:treated_data <- subset(merged_data,
1760795702410:condition == "treated" & grepl("^GENE_00", gene))
1760795702412:gene_summary <- aggregate(
1760795702413:count ~ gene,
1760795702413:data = treated_data,
1760795702414:FUN  = function(x) c(mean = mean(x), median = median(x))
1760795702415:)
1760795702417:gene_summary_df <- data.frame(
1760795702418:gene         = gene_summary$gene,
1760795702419:mean_count   = gene_summary$count[, "mean"],
1760795702421:median_count = gene_summary$count[, "median"]
1760795702421:)
1760795702423:gene_condition_means_f <- aggregate(
1760795702424:count ~ gene + condition,
1760795702425:data = merged_data,
1760795702426:FUN  = mean,
1760795702427:na.rm = TRUE
1760795702428:)
1760795702430:gene_condition_means_f <- gene_condition_means_f[order(
1760795702431:gene_condition_means_f$gene, gene_condition_means_f$condition
1760795702432:), ]
1760795702434:list(
1760795702435:gene_summary_df       = gene_summary_df,
1760795702435:gene_condition_means_f = gene_condition_means_f
1760795702436:)
1760795702437:}
1760795707198:View(bulk_counts_summary_df)
1760795734115:?bulk_counts_summary
1760795750126:?bulk_counts_summary_df
1760795804802:#' Merge and summarize bulk counts
1760795804805:#'
1760795804809:#' Combine bulk RNA counts with metadata, filter treated samples,
1760795804811:#' and compute per-gene mean/median counts and per-condition averages.
1760795804813:bulk_counts_summary_df <- function(counts_path, meta_path) {
1760795804815:counts <- read.csv(counts_path)
1760795804815:meta   <- read.csv(meta_path)
1760795804818:merged_data <- merge(counts, meta, by = "sample_id")
1760795804820:treated_data <- subset(merged_data,
1760795804820:condition == "treated" & grepl("^GENE_00", gene))
1760795804823:gene_summary <- aggregate(
1760795804824:count ~ gene,
1760795804824:data = treated_data,
1760795804825:FUN  = function(x) c(mean = mean(x), median = median(x))
1760795804826:)
1760795804829:gene_summary_df <- data.frame(
1760795804830:gene         = gene_summary$gene,
1760795804831:mean_count   = gene_summary$count[, "mean"],
1760795804831:median_count = gene_summary$count[, "median"]
1760795804832:)
1760795804833:gene_condition_means_f <- aggregate(
1760795804834:count ~ gene + condition,
1760795804835:data = merged_data,
1760795804836:FUN  = mean,
1760795804837:na.rm = TRUE
1760795804837:)
1760795804839:gene_condition_means_f <- gene_condition_means_f[order(
1760795804840:gene_condition_means_f$gene, gene_condition_means_f$condition
1760795804841:), ]
1760795804843:list(
1760795804845:gene_summary_df       = gene_summary_df,
1760795804846:gene_condition_means_f = gene_condition_means_f
1760795804847:)
1760795804848:}
1760795804849:#' Add QC-style derived columns (data.frame version)
1760795804850:#'
1760795804851:#' Add log2-transformed counts and a binary “high” flag based on
1760795804851:#' gene-wise median thresholds.
1760795804852:#'
1760795804853:#' @param counts_path Path to `bulk_counts_long.csv`.
1760795804853:#' @return A data.frame containing the original data plus
1760795804854:#'   \code{log2_count} and \code{high} columns.
1760795804855:#' @export
1760795804855:bulk_counts_qc_df <- function(counts_path) {
1760795804856:counts <- read.csv(counts_path, stringsAsFactors = FALSE)
1760795804857:counts$log2_count <- log2(counts$count + 1)
1760795804858:counts$high <- counts$count > 100
1760795804859:medians_by_gene <- tapply(counts$count, counts$gene, median)
1760795804860:counts$high <- counts$count > medians_by_gene[counts$gene]
1760795804861:counts
1760795804862:}
1760795888422:#' Summarize bulk RNA counts with metadata (data.table version)
1760795888428:#'
1760795888431:#' This function merges bulk count data with sample metadata,
1760795888432:#' filters treated samples whose gene names start with `"GENE_00"`,
1760795888436:#' and computes mean/median counts per gene, as well as per-condition means.
1760795888437:#'
1760795888437:#' @param counts_path Path to the CSV file containing bulk counts (columns: sample_id, gene, count).
1760795888438:#' @param meta_path Path to the CSV file containing metadata (columns: sample_id, condition).
1760795888439:#' @return A list with two data.tables:
1760795888440:#'   \describe{
1760795888441:#'     \item{gene_mean_median}{Mean and median counts by gene (treated only).}
1760795888442:#'     \item{gene_condition_means}{Mean counts by gene and condition.}
1760795888442:#'   }
1760795888443:#' @examples
1760795888444:#' \dontrun{
1760795888445:#' result <- bulk_counts_summary_dt(
1760795888446:#'   counts_path = "data/bulk_counts_long.csv",
1760795888447:#'   meta_path   = "data/sample_metadata.csv"
1760795888448:#' )
1760795888448:#' }
1760795888449:#' @export
1760795888450:bulk_counts_summary_dt <- function(counts_path, meta_path) {
1760795888450:library(data.table)
1760795888453:bulk_counts <- fread(counts_path)
1760795888455:sample_meta <- fread(meta_path)
1760795888457:setkey(bulk_counts, sample_id)
1760795888457:setkey(sample_meta, sample_id)
1760795888458:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760795888459:filtered_data <- join_data[
1760795888460:condition == "treated" & grepl("^GENE_00", gene)
1760795888461:]
1760795888462:gene_mean_median <- filtered_data[, .(
1760795888463:mean_count   = mean(count),
1760795888464:median_count = median(count)
1760795888464:), by = gene]
1760795888465:gene_condition_means <- bulk_counts[
1760795888466:sample_meta,
1760795888467:on = "sample_id"
1760795888468:][, .(
1760795888469:mean_count = mean(count)
1760795888469:), by = .(gene, condition)]
1760795888471:list(
1760795888472:gene_mean_median   = gene_mean_median,
1760795888472:gene_condition_means = gene_condition_means
1760795888473:)
1760795888474:}
1760795905496:?bulk_counts_summary_dt
1760795942988:View(bulk_counts_summary_dt)
1760796287328:install.packages("devtools")
1760796293289:install.packages("roxygen2")
1760796306394:devtools::document()
1760796522626:devtools::document()
1760796581035:usethis::create_package(".")
1760796715095:devtools::document()
1760796916720:setwd("~/scripts")
1760796933261:usethis::create_package(".")
1760797273236:setwd("~/scripts")
1760797289870:devtools::document()
1760797344707:> setwd("~/scripts")
1760797362403:setwd("~/scripts")
1760797384841:devtools::document()
1760798061186:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1760799387981:library(data.table)
1760799388601:# 1. Import
1760799388607:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760799435700:library(data.table)
1760799437105:# 1. Import
1760799437108:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760799448410:getwd()
1760799489545:library(data.table)
1760799490478:# 1. Import
1760799490482:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760799491787:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1760799515318:getwd
1760799520255:getwd()
1760799703141:setwd("~/scripts")
1760799711260:usethis::create_package(".")
1760799870473:#Goal: Filter, summarize, and group bulk counts. Data: bulk_counts_long.csv, sample_metadata.csv Tasks:
1760799870477:#• Keep counts for samples in condition == "treated" and genes starting with "GENE_00".
1760799870479:#• Compute mean and median count by gene (valore centrale).
1760799870482:#• Join sample metadata and compute per-condition mean counts by gene in one pipeline.
1760799870483:library(data.table)
1760799870703:# 1. Import
1760799870703:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760799917890:setwd("~\home")
1760799925634:setwd("~/home")
1760799936094:setwd("~/rstudio")
1760799957850:setwd("~/rstudio")
1760799966277:setwd("/home")
1760799976531:library(data.table)
1760799977538:# 1. Import
1760799977542:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760799984697:getwd
1760799987713:getwd()
1760800065433:setwd("~/scripts")
1760800077659:library(data.table)
1760800078644:# 1. Import
1760800078646:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760800129457:setwd("~/home/rstudio")
1760800150195:setwd("/home/rstudio")
1760800155527:library(data.table)
1760800156687:# 1. Import
1760800156692:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1760800624920:#'     \item{gene_condition_means}{Mean counts by gene and condition.}
1760800624923:#'   }
1760800624927:#' @examples
1760800624928:#' \dontrun{
1760800624929:#' result <- bulk_counts_summary_dt(
1760800624930:#'   counts_path = "data/bulk_counts_long.csv",
1760800624931:#'   meta_path   = "data/sample_metadata.csv"
1760800624932:#' )
1760800624933:#' }
1760800624935:#' @export
1760800624936:bulk_counts_summary_dt <- function(counts_path, meta_path) {
1760800624938:library(data.table)
1760800624941:bulk_counts <- fread(counts_path)
1760800624943:sample_meta <- fread(meta_path)
1760800624946:setkey(bulk_counts, sample_id)
1760800624949:setkey(sample_meta, sample_id)
1760800624952:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760800624956:filtered_data <- join_data[
1760800624958:condition == "treated" & grepl("^GENE_00", gene)
1760800624959:]
1760800624960:gene_mean_median <- filtered_data[, .(
1760800624961:mean_count   = mean(count),
1760800624962:median_count = median(count)
1760800624964:), by = gene]
1760800624967:gene_condition_means <- bulk_counts[
1760800624968:sample_meta,
1760800624969:on = "sample_id"
1760800624970:][, .(
1760800624971:mean_count = mean(count)
1760800624971:), by = .(gene, condition)]
1760800624973:list(
1760800624974:gene_mean_median   = gene_mean_median,
1760800624975:gene_condition_means = gene_condition_means
1760800624976:)
1760800624977:}
1760800628118:#'
1760800628121:#' @param counts_path Path to `bulk_counts_long.csv`.
1760800628125:#' @return A data.table containing the original data with added
1760800628127:#'   \code{log2_count} and \code{high} columns.
1760800628128:#' @examples
1760800628130:#' \dontrun{
1760800628131:#' dt <- bulk_counts_qc_dt("data/bulk_counts_long.csv")
1760800628132:#' head(dt)
1760800628134:#' }
1760800628135:#' @export
1760800628136:bulk_counts_qc_dt <- function(counts_path) {
1760800628138:library(data.table)
1760800628143:counts <- fread(counts_path)
1760800628146:counts[, log2_count := log2(count + 1)]
1760800628149:counts[, high := count > 100]
1760800628151:counts[, high := count > median(count), by = gene]
1760800628154:counts
1760800628156:}
1760800660283:?bulk_counts_qc_dt
1760800669819:??bulk_counts_qc_dt
1760800873748:devtools::document()
1760800913533:rlang::last_trace()
1760800983473:usethis::create_package(".")
1760801038617:devtools::document()
1760801056688:devtools::load_all()
1760801070467:#'     \item{gene_condition_means}{Mean counts by gene and condition.}
1760801070472:#'   }
1760801070480:#' @examples
1760801070487:#' \dontrun{
1760801070497:#' result <- bulk_counts_summary_dt(
1760801070503:#'   counts_path = "data/bulk_counts_long.csv",
1760801070504:#'   meta_path   = "data/sample_metadata.csv"
1760801070506:#' )
1760801070513:#' }
1760801070516:#' @export
1760801070519:bulk_counts_summary_dt <- function(counts_path, meta_path) {
1760801070523:library(data.table)
1760801070528:bulk_counts <- fread(counts_path)
1760801070532:sample_meta <- fread(meta_path)
1760801070536:setkey(bulk_counts, sample_id)
1760801070537:setkey(sample_meta, sample_id)
1760801070540:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760801070545:filtered_data <- join_data[
1760801070546:condition == "treated" & grepl("^GENE_00", gene)
1760801070548:]
1760801070551:gene_mean_median <- filtered_data[, .(
1760801070552:mean_count   = mean(count),
1760801070553:median_count = median(count)
1760801070555:), by = gene]
1760801070557:gene_condition_means <- bulk_counts[
1760801070558:sample_meta,
1760801070563:on = "sample_id"
1760801070566:][, .(
1760801070567:mean_count = mean(count)
1760801070568:), by = .(gene, condition)]
1760801070571:list(
1760801070572:gene_mean_median   = gene_mean_median,
1760801070573:gene_condition_means = gene_condition_means
1760801070575:)
1760801070577:}
1760801071433:#'
1760801071441:#' @param counts_path Path to `bulk_counts_long.csv`.
1760801071499:#' @return A data.table containing the original data with added
1760801071525:#'   \code{log2_count} and \code{high} columns.
1760801071526:#' @examples
1760801071528:#' \dontrun{
1760801071529:#' dt <- bulk_counts_qc_dt("data/bulk_counts_long.csv")
1760801071531:#' head(dt)
1760801071533:#' }
1760801071534:#' @export
1760801071536:bulk_counts_qc_dt <- function(counts_path) {
1760801071537:library(data.table)
1760801071539:counts <- fread(counts_path)
1760801071541:counts[, log2_count := log2(count + 1)]
1760801071543:counts[, high := count > 100]
1760801071544:counts[, high := count > median(count), by = gene]
1760801071546:counts
1760801071548:}
1760801095324:?bulk_counts_summary_dt
1760802065750:View(bulk_counts_qc_dt)
1760802075369:?bulk_counts_summary_dt
1760802104355:?bulk_counts_summary_dt
1760802158551:??bulk_counts_qc_dt
1760802204040:devtools::document()
1760802238441:devtools::document()
1760802280987:?bulk_counts_qc_dt
1760802292331:??bulk_counts_qc_dt
1760802318913:??bulk_counts_qc_dt
1760802382512:?bulk_counts_summary_dt
1760802391685:??bulk_counts_summary_dt
1760802817223:#'     \item{gene_condition_means}{Mean counts by gene and condition.}
1760802817228:#'   }
1760802817230:#' @examples
1760802817232:#' \dontrun{
1760802817233:#' result <- bulk_counts_summary_dt(
1760802817234:#'   counts_path = "data/bulk_counts_long.csv",
1760802817236:#'   meta_path   = "data/sample_metadata.csv"
1760802817237:#' )
1760802817239:#' }
1760802817240:#' @export
1760802817242:bulk_counts_summary_dt <- function(counts_path, meta_path) {
1760802817243:library(data.table)
1760802817249:bulk_counts <- fread(counts_path)
1760802817252:sample_meta <- fread(meta_path)
1760802817260:setkey(bulk_counts, sample_id)
1760802817261:setkey(sample_meta, sample_id)
1760802817263:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760802817266:filtered_data <- join_data[
1760802817267:condition == "treated" & grepl("^GENE_00", gene)
1760802817268:]
1760802817269:gene_mean_median <- filtered_data[, .(
1760802817270:mean_count   = mean(count),
1760802817271:median_count = median(count)
1760802817272:), by = gene]
1760802817274:gene_condition_means <- bulk_counts[
1760802817275:sample_meta,
1760802817276:on = "sample_id"
1760802817278:][, .(
1760802817279:mean_count = mean(count)
1760802817280:), by = .(gene, condition)]
1760802817283:list(
1760802817285:gene_mean_median   = gene_mean_median,
1760802817286:gene_condition_means = gene_condition_means
1760802817287:)
1760802817289:}
1760802817719:#'
1760802817723:#' @param counts_path Path to `bulk_counts_long.csv`.
1760802817726:#' @return A data.table containing the original data with added
1760802817728:#'   \code{log2_count} and \code{high} columns.
1760802817730:#' @examples
1760802817731:#' \dontrun{
1760802817733:#' dt <- bulk_counts_qc_dt("data/bulk_counts_long.csv")
1760802817734:#' head(dt)
1760802817736:#' }
1760802817737:#' @export
1760802817738:bulk_counts_qc_dt <- function(counts_path) {
1760802817741:library(data.table)
1760802817748:counts <- fread(counts_path)
1760802817751:counts[, log2_count := log2(count + 1)]
1760802817754:counts[, high := count > 100]
1760802817755:counts[, high := count > median(count), by = gene]
1760802817759:counts
1760802817762:}
1760802829832:?bulk_counts_summary_dt
1760802874994:?bulk_counts_summary_dt
1760802894366:devtools::document()
1760802926620:devtools::document()
1760802943142:devtools::document()
1760802949702:devtools::document()
1760802986245:rm(list = c("bulk_counts_qc_dt", "bulk_counts_summary_dt"))
1760802993823:devtools::document()
1760803004482:load_all()
1760803020250:#'     \item{gene_condition_means}{Mean counts by gene and condition.}
1760803020255:#'   }
1760803020257:#' @examples
1760803020259:#' \dontrun{
1760803020261:#' result <- bulk_counts_summary_dt(
1760803020262:#'   counts_path = "data/bulk_counts_long.csv",
1760803020264:#'   meta_path   = "data/sample_metadata.csv"
1760803020265:#' )
1760803020266:#' }
1760803020267:#' @export
1760803020268:bulk_counts_summary_dt <- function(counts_path, meta_path) {
1760803020270:library(data.table)
1760803020273:bulk_counts <- fread(counts_path)
1760803020277:sample_meta <- fread(meta_path)
1760803020285:setkey(bulk_counts, sample_id)
1760803020286:setkey(sample_meta, sample_id)
1760803020289:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760803020293:filtered_data <- join_data[
1760803020295:condition == "treated" & grepl("^GENE_00", gene)
1760803020297:]
1760803020299:gene_mean_median <- filtered_data[, .(
1760803020299:mean_count   = mean(count),
1760803020300:median_count = median(count)
1760803020301:), by = gene]
1760803020303:gene_condition_means <- bulk_counts[
1760803020304:sample_meta,
1760803020305:on = "sample_id"
1760803020306:][, .(
1760803020308:mean_count = mean(count)
1760803020310:), by = .(gene, condition)]
1760803020313:list(
1760803020314:gene_mean_median   = gene_mean_median,
1760803020316:gene_condition_means = gene_condition_means
1760803020317:)
1760803020318:}
1760803020930:#'
1760803020933:#' @param counts_path Path to `bulk_counts_long.csv`.
1760803020935:#' @return A data.table containing the original data with added
1760803020939:#'   \code{log2_count} and \code{high} columns.
1760803020942:#' @examples
1760803020943:#' \dontrun{
1760803020945:#' dt <- bulk_counts_qc_dt("data/bulk_counts_long.csv")
1760803020947:#' head(dt)
1760803020950:#' }
1760803020953:#' @export
1760803020959:bulk_counts_qc_dt <- function(counts_path) {
1760803020963:library(data.table)
1760803020967:counts <- fread(counts_path)
1760803020968:counts[, log2_count := log2(count + 1)]
1760803020972:counts[, high := count > 100]
1760803020980:counts[, high := count > median(count), by = gene]
1760803020987:counts
1760803020995:}
1760803025819:load_all()
1760803034048:?bulk_counts_summary_dt
1760803119966:?bulk_counts_qc_dt
1760806598153:devtools::load_all()
1760912178925:devtools::load_all()
1760912207175:?combine_integration_clustering_dt
1760912231638:devtools::load_all()
1760912265643:?combine_cohorts_d
1760912272147:?combine_cohorts_dt
1760912282383:??combine_cohorts_dt
1760912293999:#' Summarize bulk RNA counts with metadata (data.table version)
1760912294002:#'
1760912294003:#' This function merges bulk count data with sample metadata,
1760912294007:#' filters treated samples whose gene names start with `"GENE_00"`,
1760912294009:#' and computes mean/median counts per gene, as well as per-condition means.
1760912294010:#'
1760912294011:#' @param counts_path Path to the CSV file containing bulk counts (columns: sample_id, gene, count).
1760912294012:#' @param meta_path Path to the CSV file containing metadata (columns: sample_id, condition).
1760912294012:#' @return A list with two data.tables:
1760912294013:#'   \describe{
1760912294015:#'     \item{gene_mean_median}{Mean and median counts by gene (treated only).}
1760912294016:#'     \item{gene_condition_means}{Mean counts by gene and condition.}
1760912294018:#'   }
1760912294019:#' @examples
1760912294020:#' \dontrun{
1760912294020:#' result <- bulk_counts_summary_dt(
1760912294021:#'   counts_path = "data/bulk_counts_long.csv",
1760912294023:#'   meta_path   = "data/sample_metadata.csv"
1760912294024:#' )
1760912294025:#' }
1760912294027:#' @export
1760912294028:bulk_counts_summary_dt <- function(counts_path, meta_path) {
1760912294029:library(data.table)
1760912294031:bulk_counts <- fread(counts_path)
1760912294031:sample_meta <- fread(meta_path)
1760912294033:setkey(bulk_counts, sample_id)
1760912294034:setkey(sample_meta, sample_id)
1760912294034:join_data <- bulk_counts[sample_meta, nomatch = 0]
1760912294036:filtered_data <- join_data[
1760912294036:condition == "treated" & grepl("^GENE_00", gene)
1760912294037:]
1760912294038:gene_mean_median <- filtered_data[, .(
1760912294039:mean_count   = mean(count),
1760912294040:median_count = median(count)
1760912294040:), by = gene]
1760912294041:gene_condition_means <- bulk_counts[
1760912294042:sample_meta,
1760912294043:on = "sample_id"
1760912294044:][, .(
1760912294045:mean_count = mean(count)
1760912294045:), by = .(gene, condition)]
1760912294047:list(
1760912294047:gene_mean_median   = gene_mean_median,
1760912294048:gene_condition_means = gene_condition_means
1760912294048:)
1760912294049:}
1760912294051:#' Add QC-style derived columns (data.table version)
1760912294052:#'
1760912294052:#' Adds log2-transformed counts and a binary flag \code{high}
1760912294053:#' based on gene-wise median thresholds. All operations are done in-place.
1760912294053:#'
1760912294054:#' @param counts_path Path to `bulk_counts_long.csv`.
1760912294054:#' @return A data.table containing the original data with added
1760912294055:#'   \code{log2_count} and \code{high} columns.
1760912294055:#' @examples
1760912294056:#' \dontrun{
1760912294057:#' dt <- bulk_counts_qc_dt("data/bulk_counts_long.csv")
1760912294057:#' head(dt)
1760912294058:#' }
1760912294059:#' @export
1760912294059:bulk_counts_qc_dt <- function(counts_path) {
1760912294060:library(data.table)
1760912294061:counts <- fread(counts_path)
1760912294061:counts[, log2_count := log2(count + 1)]
1760912294062:counts[, high := count > 100]
1760912294063:counts[, high := count > median(count), by = gene]
1760912294064:counts
1760912294065:}
1760912294066:#' Subset counts data using data.table with secondary index
1760912294066:#'
1760912294067:#' This function joins bulk counts with sample metadata and subsets rows
1760912294067:#' for a specific gene and sample using a data.table secondary index for speed.
1760912294068:#'
1760912294068:#' @param counts data.table of bulk counts
1760912294069:#' @param meta data.table of sample metadata
1760912294069:#' @param gene_name character, gene to subset
1760912294070:#' @param sample_chosen character, sample_id to subset
1760912294070:#' @return data.table subset of counts for the given gene and sample
1760912294071:#' @examples
1760912294072:#' dt_counts <- fread("project_oct25/bulk_counts_long.csv")
1760912294072:#' dt_meta <- fread("project_oct25/sample_metadata.csv")
1760912294073:#' subset_counts_dt(dt_counts, dt_meta, "GENE_0051", "S20")
1760912294074:subset_counts_dt <- function(counts, meta, gene_name, sample_chosen) {
1760912294074:library(data.table)
1760912294075:# set keys
1760912294076:setkey(meta, sample_id)
1760912294076:# join
1760912294077:joined_data <- meta[counts, on = "sample_id"]
1760912294078:# create secondary index
1760912294078:setindex(counts, gene, sample_id)
1760912294079:# subset
1760912294080:subset_data <- counts[gene == gene_name & sample_id == sample_chosen]
1760912294081:return(subset_data)
1760912294081:}
1760912294082:#' Annotate counts with sample and patient information
1760912294083:#'
1760912294083:#' Joins bulk counts with sample metadata, computes total counts per patient,
1760912294084:#' mean counts per gene and condition, and returns top 10 genes per condition.
1760912294084:#'
1760912294085:#' @param counts data.table of bulk counts
1760912294085:#' @param meta data.table of sample metadata
1760912294086:#' @return list with joined_data, patient_tot, top10
1760912294086:#' @examples
1760912294087:#' dt_counts <- fread("project_oct25/bulk_counts_long.csv")
1760912294087:#' dt_meta <- fread("project_oct25/sample_metadata.csv")
1760912294088:#' annotate_counts_dt(dt_counts, dt_meta)
1760912294089:annotate_counts_dt <- function(counts, meta) {
1760912294089:library(data.table)
1760912294090:# set keys
1760912294091:setkey(counts, sample_id)
1760912294091:setkey(meta, sample_id)
1760912294092:# join
1760912294093:joined_data <- counts[meta, nomatch = 0]
1760912294094:# total counts per patient
1760912294095:patient_tot <- joined_data[, .(total_count = sum(count)), by = patient_id]
1760912294096:# mean count per gene and condition
1760912294097:gene_means <- joined_data[, .(mean_count = mean(count)), by = .(gene, condition)]
1760912294098:# top 10 genes per condition
1760912294099:top10 <- gene_means[order(condition, -mean_count)][, head(.SD, 10), by = condition]
1760912294100:return(list(joined_data = joined_data,
1760912294100:patient_tot = patient_tot,
1760912294101:top10 = top10))
1760912294101:}
1760912294103:#' Task 5 (data.table) – Classify lab values vs reference intervals and summarize
1760912294103:#'
1760912294104:#' Join clinical lab values to reference ranges, classify each measurement as
1760912294104:#' "normal" or "out_of_range" using interval logic, then return summaries by patient and by lab.
1760912294105:#'
1760912294105:#' @param labs_dt A data.table containing at least: patient_id, lab, value.
1760912294107:#' @param ref_dt A data.table containing at least: lab, lower, upper.
1760912294108:#'
1760912294108:#' @return A list with elements:
1760912294110:#' \itemize{
1760912294115:#'  \item merged: data.table with status column ("normal"/"out_of_range")
1760912294119:#'  \item abnormal_by_patient: data.table with total_tests and out_of_range per patient_id
1760912294120:#'  \item abnormal_by_lab: data.table with total_tests and out_of_range per lab
1760912294121:#' }
1760912294122:#'
1760912294122:#' @examples
1760912294123:#' \dontrun{
1760912294124:#' res <- classify_labs_dt(labs_dt, ref_dt)
1760912294124:#' }
1760912294125:#' @export
1760912294125:classify_labs_dt <- function(labs_dt, ref_dt) {
1760912294126:stopifnot(data.table::is.data.table(labs_dt), data.table::is.data.table(ref_dt))
1760912294127:ref_unique <- unique(ref_dt[, .(lab, lower, upper)])
1760912294127:merged <- merge(labs_dt, ref_unique, by = "lab", all.x = TRUE)
1760912294128:merged[, status := fifelse(!is.na(lower) & value >= lower & value <= upper, "normal", "out_of_range")]
1760912294128:abnormal_by_patient <- merged[, .(total_tests = .N, out_of_range = sum(status == "out_of_range")), by = patient_id]
1760912294129:abnormal_by_lab <- merged[, .(total_tests = .N, out_of_range = sum(status == "out_of_range")), by = lab]
1760912294130:list(merged = merged, abnormal_by_patient = abnormal_by_patient, abnormal_by_lab = abnormal_by_lab)
1760912294130:}
1760912294132:#' Task 6 (data.table) – Nearest-time matching of vitals to lab draws and correlation by patient
1760912294132:#'
1760912294133:#' @description
1760912294133:#' For each lab measurement, attach the nearest HR and SBP reading (rolling join on patient_id/time),
1760912294134:#' compute time lags, and summarize per-patient correlation between CRP and nearest HR/SBP.
1760912294135:#'
1760912294135:#' @param labs_dt data.table with at least: patient_id, time_iso (POSIXct or coercible), lab, value.
1760912294135:#' @param vitals_dt data.table with at least: patient_id, time_iso, vital (e.g., "HR","SBP"), value.
1760912294136:#'
1760912294136:#' @return A list with elements:
1760912294137:#' \itemize{
1760912294138:#'  \item labs_with_vitals: data.table with nearest_HR, HR_time, nearest_SBP, SBP_time, hr_lag_minutes, sbp_lag_minutes
1760912294138:#'  \item cor_crp_hr: data.table patient_id × correlation_CRP_HR
1760912294139:#'  \item cor_crp_sbp: data.table patient_id × correlation_CRP_SBP
1760912294139:#' }
1760912294140:#'
1760912294140:#' @examples
1760912294141:#' \dontrun{
1760912294141:#' res <- match_vitals_dt(labs_dt, vitals_dt)
1760912294142:#' }
1760912294142:#' @export
1760912294143:match_vitals_dt <- function(labs_dt, vitals_dt) {
1760912294143:stopifnot(data.table::is.data.table(labs_dt), data.table::is.data.table(vitals_dt))
1760912294144:labs_dt[, time_iso := as.POSIXct(time_iso)]
1760912294144:vitals_dt[, time_iso := as.POSIXct(time_iso)]
1760912294145:setorder(labs_dt, patient_id, time_iso)
1760912294145:setorder(vitals_dt, patient_id, time_iso)
1760912294146:labs_dt[, lab_time := time_iso]
1760912294147:# HR
1760912294147:vitals_hr <- vitals_dt[vital == "HR", .(patient_id, time_iso, value)]
1760912294148:setnames(vitals_hr, "value", "nearest_HR")
1760912294148:vitals_hr[, hr_time := time_iso]
1760912294149:setkey(vitals_hr, patient_id, time_iso)
1760912294150:setkey(labs_dt, patient_id, time_iso)
1760912294150:labs_with_hr <- vitals_hr[labs_dt, roll = "nearest"]
1760912294151:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1760912294152:# SBP
1760912294152:vitals_sbp <- vitals_dt[vital == "SBP", .(patient_id, time_iso, value)]
1760912294153:setnames(vitals_sbp, "value", "nearest_SBP")
1760912294154:vitals_sbp[, sbp_time := time_iso]
1760912294154:setkey(vitals_sbp, patient_id, time_iso)
1760912294155:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1760912294155:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1760912294157:# Correlations for CRP
1760912294157:crp_data <- labs_with_vitals[lab == "CRP"]
1760912294158:cor_crp_hr <- crp_data[!is.na(nearest_HR), .(correlation_CRP_HR = cor(value, nearest_HR, use = "complete.obs")), by = patient_id]
1760912294158:cor_crp_sbp <- crp_data[!is.na(nearest_SBP), .(correlation_CRP_SBP = cor(value, nearest_SBP, use = "complete.obs")), by = patient_id]
1760912294159:list(labs_with_vitals = labs_with_vitals, cor_crp_hr = cor_crp_hr, cor_crp_sbp = cor_crp_sbp)
1760912294160:}
1760912294162:#' Task 7 (data.table) – Extract peaks on chr and return top N by score
1760912294162:#'
1760912294163:#' @param peaks_dt data.table with columns: chr, start, end, score (at least)
1760912294163:#' @param chr chromosome string (default "chr2")
1760912294164:#' @param start_min numeric start bound (default 2e6)
1760912294164:#' @param start_max numeric end bound (default 4e6)
1760912294165:#' @param top_n integer number of top peaks to return (default 50)
1760912294165:#'
1760912294166:#' @return data.table of top peaks
1760912294166:#' @examples
1760912294166:#' \dontrun{
1760912294167:#' top <- top_peaks_dt(peaks_dt)
1760912294168:#' }
1760912294168:#' @export
1760912294169:top_peaks_dt <- function(peaks_dt, chr = "chr2", start_min = 2e6, start_max = 4e6, top_n = 50) {
1760912294169:stopifnot(data.table::is.data.table(peaks_dt))
1760912294170:subset_peaks <- peaks_dt[chr == !!chr & start >= start_min & start <= start_max]
1760912294170:data.table::setorder(subset_peaks, -score)
1760912294171:head(subset_peaks, top_n)
1760912294171:}
1760912294173:#' Task 8 (data.table) – Per-condition robust summary stats and filter genes
1760912294173:#'
1760912294174:#' @param counts_dt data.table with columns sample_id, gene, count
1760912294174:#' @param meta_dt data.table with columns sample_id, condition
1760912294174:#'
1760912294175:#' @return list with stats_by_gene_condition and kept_genes
1760912294176:#' @examples
1760912294177:#' \dontrun{
1760912294178:#' res <- gene_stats_filter_dt(counts_dt, meta_dt)
1760912294178:#' }
1760912294179:#' @export
1760912294180:gene_stats_filter_dt <- function(counts_dt, meta_dt) {
1760912294181:stopifnot(data.table::is.data.table(counts_dt), data.table::is.data.table(meta_dt))
1760912294181:merged <- counts_dt[meta_dt, on = "sample_id"]
1760912294182:stats_by_gene_condition <- merged[, .(
1760912294183:mean_count = mean(count, na.rm = TRUE),
1760912294183:median_count = median(count, na.rm = TRUE),
1760912294184:Q1 = quantile(count, 0.25, type = 2),
1760912294185:Q3 = quantile(count, 0.75, type = 2)
1760912294185:), by = .(gene, condition)]
1760912294186:treated_means <- stats_by_gene_condition[condition == "treated", .(gene, treated_mean = mean_count)]
1760912294187:control_means <- stats_by_gene_condition[condition == "control", .(gene, control_mean = mean_count)]
1760912294187:means_wide <- merge(treated_means, control_means, by = "gene", all = FALSE)
1760912294188:kept_genes <- means_wide[treated_mean >= 2 * control_mean]
1760912294188:list(stats_by_gene_condition = stats_by_gene_condition, kept_genes = kept_genes)
1760912294189:}
1760912294190:#' Task 9 (data.table) – Convert wide → long → wide and compute mean per gene/condition
1760912294191:#'
1760912294192:#' @param counts_wide_dt data.table with first column gene and subsequent sample_id columns
1760912294192:#' @param meta_dt data.table with sample_id and condition
1760912294193:#'
1760912294193:#' @return data.table wide with mean_count per condition
1760912294194:#' @examples
1760912294194:#' \dontrun{
1760912294195:#' res <- wide_long_wide_dt(counts_wide_dt, meta_dt)
1760912294195:#' }
1760912294196:#' @export
1760912294196:wide_long_wide_dt <- function(counts_wide_dt, meta_dt) {
1760912294197:stopifnot(data.table::is.data.table(counts_wide_dt), data.table::is.data.table(meta_dt))
1760912294197:idvar <- names(counts_wide_dt)[1]
1760912294198:counts_long <- data.table::melt(counts_wide_dt, id.vars = idvar, variable.name = "sample_id", value.name = "count")
1760912294199:merged <- merge(counts_long, meta_dt, by = "sample_id", all.x = TRUE)
1760912294199:totals_per_sample <- merged[, .(total_count = sum(count, na.rm = TRUE)), by = sample_id]
1760912294200:merged <- merge(merged, totals_per_sample, by = "sample_id", all.x = TRUE)
1760912294200:gene_condition_means <- merged[, .(mean_count = mean(count, na.rm = TRUE)), by = .(gene = get(idvar), condition)]
1760912294201:counts_condition_wide <- data.table::dcast(gene_condition_means, gene ~ condition, value.var = "mean_count")
1760912294202:counts_condition_wide
1760912294203:}
1760912294204:#' Task 10 (data.table) – ATAC peaks overlap to genes and summarize overlap bp
1760912294205:#'
1760912294205:#' @param peaks_dt data.table with chr, start, end, (and optionally score)
1760912294206:#' @param genes_dt data.table with chr, start, end, gene
1760912294206:#'
1760912294207:#' @return list with overlaps, peaks_per_gene, overlap_sum_per_gene, top20_genes
1760912294208:#' @examples
1760912294208:#' \dontrun{
1760912294209:#' res <- atac_to_gene_dt(peaks_dt, genes_dt)
1760912294209:#' }
1760912294210:#' @export
1760912294210:atac_to_gene_dt <- function(peaks_dt, genes_dt) {
1760912294211:stopifnot(data.table::is.data.table(peaks_dt), data.table::is.data.table(genes_dt))
1760912294211:setkey(peaks_dt, chr, start, end)
1760912294212:setkey(genes_dt, chr, start, end)
1760912294212:overlaps <- foverlaps(peaks_dt, genes_dt, by.x = c("chr", "start", "end"), by.y = c("chr", "start", "end"), type = "any", nomatch = 0L)
1760912294213:overlaps[, overlap_bp := pmin(end, i.end) - pmax(start, i.start)]
1760912294214:overlaps <- overlaps[overlap_bp > 0]
1760912294214:peaks_per_gene <- overlaps[, .N, by = gene]; setnames(peaks_per_gene, "N", "num_peaks")
1760912294215:overlap_sum_per_gene <- overlaps[, .(total_overlap_bp = sum(overlap_bp)), by = gene]
1760912294215:top20_genes <- overlap_sum_per_gene[order(-total_overlap_bp)][1:20]
1760912294216:list(overlaps = overlaps, peaks_per_gene = peaks_per_gene, overlap_sum_per_gene = overlap_sum_per_gene, top20_genes = top20_genes)
1760912294217:}
1760912294218:#' Task 11 (data.table) – Map variants to genes and summarize HIGH-impact counts
1760912294218:#'
1760912294219:#' @param variants_dt data.table with columns: sample_id, chr, pos, impact (and others)
1760912294220:#' @param genes_dt data.table with columns: chr, start, end, gene
1760912294220:#'
1760912294221:#' @return list with high_counts_by_gene_sample, high_counts_by_gene, genes_with_high
1760912294222:#' @examples
1760912294222:#' \dontrun{
1760912294223:#' res <- variants_to_genes_dt(variants_dt, genes_dt)
1760912294223:#' }
1760912294224:#' @export
1760912294225:variants_to_genes_dt <- function(variants_dt, genes_dt) {
1760912294225:stopifnot(data.table::is.data.table(variants_dt), data.table::is.data.table(genes_dt))
1760912294226:variants_dt[, start := pos]
1760912294226:variants_dt[, end := pos]
1760912294227:setkey(variants_dt, chr, start, end)
1760912294227:setkey(genes_dt, chr, start, end)
1760912294228:overlaps <- foverlaps(variants_dt, genes_dt, type = "any", nomatch = 0L)
1760912294228:overlaps[, impact_upper := toupper(impact)]
1760912294229:high_overlaps <- overlaps[impact_upper == "HIGH"]
1760912294230:if (nrow(high_overlaps) == 0) {
1760912294230:return(list(high_counts_by_gene_sample = data.table::data.table(), high_counts_by_gene = data.table::data.table(), genes_with_high = character(0)))
1760912294231:}
1760912294231:high_counts_by_gene_sample <- high_overlaps[, .(high_variant_count = .N), by = .(gene, sample_id)]
1760912294232:high_counts_by_gene <- high_overlaps[, .(total_high_variants = .N), by = gene][order(-total_high_variants)]
1760912294233:genes_with_high <- unique(high_counts_by_gene$gene)
1760912294233:fwrite_flag <- FALSE
1760912294234:list(high_counts_by_gene_sample = high_counts_by_gene_sample, high_counts_by_gene = high_counts_by_gene, genes_with_high = genes_with_high)
1760912294235:}
1760912294236:#' Task 12 (data.table) – Combine cohorts safely and compute per-cohort means for top variable genes
1760912294237:#'
1760912294237:#' @param cohortA_dt data.table with sample info for cohort A (must include sample_id, condition)
1760912294238:#' @param cohortB_dt data.table with sample info for cohort B
1760912294238:#' @param counts_dt data.table with sample_id, gene, count
1760912294239:#' @param top_n integer number of top variable genes to select (default 100)
1760912294239:#'
1760912294240:#' @return list with combined_cohorts, mean_counts, top_genes
1760912294241:#' @examples
1760912294241:#' \dontrun{
1760912294242:#' res <- combine_cohorts_dt(cohortA_dt, cohortB_dt, counts_dt)
1760912294242:#' }
1760912294243:#' @export
1760912294244:combine_cohorts_dt <- function(cohortA_dt, cohortB_dt, counts_dt, top_n = 100) {
1760912294244:stopifnot(data.table::is.data.table(cohortA_dt), data.table::is.data.table(cohortB_dt), data.table::is.data.table(counts_dt))
1760912294245:cohortA_dt[, cohort := "A"]
1760912294246:cohortB_dt[, cohort := "B"]
1760912294247:combined_cohorts <- data.table::rbindlist(list(cohortA_dt, cohortB_dt), use.names = TRUE, fill = TRUE)
1760912294248:data.table::setorder(combined_cohorts, cohort, condition, sample_id)
1760912294249:merged_per_sampleid <- merge(counts_dt, combined_cohorts, by = "sample_id", all.x = TRUE)
1760912294250:gene_variance <- merged_per_sampleid[, .(variance = var(count, na.rm = TRUE)), by = gene]
1760912294251:top_genes <- gene_variance[order(-variance)][1:top_n, gene]
1760912294251:top_data <- merged_per_sampleid[gene %in% top_genes]
1760912294252:mean_counts <- top_data[, .(mean_count = mean(count, na.rm = TRUE)), by = .(gene, cohort, condition)]
1760912294254:list(combined_cohorts = combined_cohorts, mean_counts = mean_counts, top_genes = top_genes)
1760912294255:}
1760912294257:#FINAL REVISION
1760912294258:#' Combine integration and clustering data
1760912294258:#'
1760912294259:#' @description
1760912294259:#' Reads and merges integration and clustering tables by cell ID,
1760912294260:#' ensuring consistent formatting across both datasets.
1760912294261:#'
1760912294261:#' @param integration_file Path to the CSV file containing integration results.
1760912294262:#'   Must include columns: `cell`, `integration_cluster`.
1760912294263:#' @param clustering_file Path to the CSV file containing clustering results.
1760912294264:#'   Must include columns: `cell`, `cell_type`, `sample_type`.
1760912294265:#'
1760912294265:#' @return A `data.table` containing:
1760912294266:#'   - `cell_clean`: standardized cell ID
1760912294267:#'   - `integration_cluster`: cluster assignment
1760912294267:#'   - `cell_type`: predicted cell type
1760912294268:#'   - `sample_type`: tissue type (N/T)
1760912294269:#'
1760912294269:#' @examples
1760912294270:#' \dontrun{
1760912294270:#' combined_dt <- combine_integration_clustering_dt(
1760912294271:#'   "project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv",
1760912294271:#'   "project_oct25/nt_combined_clustering.output.csv"
1760912294272:#' )
1760912294273:#' head(combined_dt)
1760912294273:#' }
1760912294274:#'
1760912294275:#' @export
1760912294275:combine_integration_clustering_dt <- function(integration_file, clustering_file) {
1760912294276:integration_dt <- data.table::fread(integration_file)
1760912294276:clustering_dt  <- data.table::fread(clustering_file)
1760912294277:normalize_cell_id <- function(x) {
1760912294278:x <- as.character(x)
1760912294279:x <- trimws(x)
1760912294280:x <- gsub("_X_|_Y_", "_", x)
1760912294280:x <- gsub("_\\.", ".", x)
1760912294281:return(x)
1760912294282:}
1760912294283:integration_dt[, cell_clean := normalize_cell_id(cell)]
1760912294284:clustering_dt[, cell_clean  := normalize_cell_id(cell)]
1760912294285:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all = FALSE)
1760912294286:return(combined)
1760912294287:}
1760912294289:#' Count cells per cluster and cell type
1760912294291:#'
1760912294292:#' @description
1760912294294:#' Computes the number of cells of each cell type within each integration cluster.
1760912294295:#'
1760912294296:#' @param combined_dt A `data.table` containing at least the columns:
1760912294298:#'   - `integration_cluster`: integration cluster ID
1760912294299:#'   - `cell_type`: predicted cell type
1760912294301:#'
1760912294302:#' @return A `data.table` with columns:
1760912294303:#'   - `integration_cluster`
1760912294304:#'   - `cell_type`
1760912294305:#'   - `cell_count`: number of cells per (cluster, cell type)
1760912294306:#'
1760912294307:#' @examples
1760912294307:#' \dontrun{
1760912294308:#' dt <- data.table::fread("project_oct25/combined_data.csv")
1760912294310:#' res <- count_cells_per_cluster_dt(dt)
1760912294310:#' head(res)
1760912294311:#' }
1760912294312:#'
1760912294313:#' @export
1760912294314:count_cells_per_cluster_dt <- function(combined_dt) {
1760912294315:stopifnot(data.table::is.data.table(combined_dt))
1760912294317:# Calcola conteggi per cluster e tipo cellulare
1760912294319:counts <- combined_dt[, .N, by = .(integration_cluster, cell_type)]
1760912294321:data.table::setnames(counts, "N", "cell_count")
1760912294322:return(counts)
1760912294323:}
1760912304702:devtools::load_all()
1760912336140:?match_vitals_dt
1760912356375:??match_vitals_dt
1760912434549:devtools::document()
1760912452616:devtools::load_all()
1760912476798:?match_vitals_dt
1760912498116:?variants_to_genes_dt
1760964071250:library(data.table)
1760964071412:# ==========================================================
1760964071415:# 🧩 TASK 1 — Bulk RNA counts summary
1760964071416:# ==========================================================
1760964071418:#' Summarize bulk RNA counts with metadata (data.table version)
1760964071419:#'
1760964071419:#' Merges bulk RNA-seq count data with sample metadata, filters treated samples
1760964071420:#' whose gene names start with "GENE_00", and computes mean/median counts per gene,
1760964071421:#' as well as per-condition mean counts.
1760964071422:#'
1760964071422:#' @param counts_path Path to CSV file with columns: sample_id, gene, count.
1760964071423:#' @param meta_path Path to CSV file with columns: sample_id, condition.
1760964071424:#' @return List with:
1760964071424:#' \itemize{
1760964071425:#'   \item gene_mean_median: Mean and median counts by gene (treated only)
1760964071426:#'   \item gene_condition_means: Mean counts by gene and condition
1760964071432:#' }
1760964071433:#' @export
1760964071434:bulk_counts_summary_dt <- function(counts_path, meta_path) {
1760964071435:counts <- fread(counts_path)
1760964071436:meta <- fread(meta_path)
1760964071437:setkey(counts, sample_id)
1760964071437:setkey(meta, sample_id)
1760964071439:merged <- counts[meta, nomatch = 0]
1760964071439:filtered <- merged[condition == "treated" & grepl("^GENE_00", gene)]
1760964071441:gene_mean_median <- filtered[, .(
1760964071441:mean_count = mean(count),
1760964071442:median_count = median(count)
1760964071443:), by = gene]
1760964071444:gene_condition_means <- merged[, .(
1760964071446:mean_count = mean(count)
1760964071447:), by = .(gene, condition)]
1760964071448:list(
1760964071449:gene_mean_median = gene_mean_median,
1760964071449:gene_condition_means = gene_condition_means
1760964071450:)
1760964071451:}
1760964071452:# ==========================================================
1760964071453:# 🧩 TASK 2 — QC-style derived columns
1760964071453:# ==========================================================
1760964071454:#' Add QC-style derived columns (data.table version)
1760964071455:#'
1760964071456:#' Adds log2-transformed counts and a binary \code{high} flag based on gene-wise medians.
1760964071456:#'
1760964071457:#' @param counts_path Path to CSV file with columns: sample_id, gene, count.
1760964071457:#' @return Data.table with added columns: log2_count, high.
1760964071458:#' @export
1760964071459:bulk_counts_qc_dt <- function(counts_path) {
1760964071460:dt <- fread(counts_path)
1760964071460:dt[, log2_count := log2(count + 1)]
1760964071461:dt[, high := count > median(count), by = gene]
1760964071462:dt[]
1760964071462:}
1760964071463:# ==========================================================
1760964071464:# 🧩 TASK 3 — Subset by gene and sample
1760964071464:# ==========================================================
1760964071466:#' Subset counts data using secondary index
1760964071466:#'
1760964071467:#' Joins metadata and subsets for a specific gene and sample using fast indexing.
1760964071468:#'
1760964071469:#' @param counts data.table of bulk counts
1760964071469:#' @param meta data.table of sample metadata
1760964071470:#' @param gene_name Gene name to subset
1760964071471:#' @param sample_chosen Sample ID to subset
1760964071471:#' @return Subset of counts for the given gene and sample.
1760964071472:#' @export
1760964071472:subset_counts_dt <- function(counts, meta, gene_name, sample_chosen) {
1760964071473:setkey(meta, sample_id)
1760964071474:setindex(counts, gene, sample_id)
1760964071474:counts[gene == gene_name & sample_id == sample_chosen]
1760964071475:}
1760964071476:# ==========================================================
1760964071477:# 🧩 TASK 4 — Annotate counts and summarize
1760964071478:# ==========================================================
1760964071479:#' Annotate counts with metadata and compute summaries
1760964071479:#'
1760964071480:#' Joins counts and metadata, computes per-patient total counts,
1760964071481:#' mean counts per gene and condition, and identifies top 10 genes.
1760964071481:#'
1760964071482:#' @param counts data.table of bulk counts
1760964071483:#' @param meta data.table of sample metadata
1760964071483:#' @return List with joined data, patient totals, and top10 genes.
1760964071484:#' @export
1760964071485:annotate_counts_dt <- function(counts, meta) {
1760964071485:setkey(counts, sample_id)
1760964071486:setkey(meta, sample_id)
1760964071487:joined <- counts[meta, nomatch = 0]
1760964071488:patient_tot <- joined[, .(total_count = sum(count)), by = patient_id]
1760964071488:gene_means <- joined[, .(mean_count = mean(count)), by = .(gene, condition)]
1760964071489:top10 <- gene_means[order(condition, -mean_count)][, head(.SD, 10), by = condition]
1760964071490:list(joined = joined, patient_tot = patient_tot, top10 = top10)
1760964071490:}
1760964071492:# ==========================================================
1760964071493:# 🧩 TASK 5 — Classify lab values
1760964071493:# ==========================================================
1760964071494:#' Classify lab values against reference intervals
1760964071495:#'
1760964071496:#' Joins lab results and reference ranges, classifies as "normal" or "out_of_range",
1760964071496:#' and summarizes abnormalities per patient and per lab.
1760964071497:#'
1760964071497:#' @param labs_dt Data.table with columns: patient_id, lab, value.
1760964071498:#' @param ref_dt Data.table with columns: lab, lower, upper.
1760964071499:#' @return List with merged data, abnormal_by_patient, abnormal_by_lab.
1760964071499:#' @export
1760964071500:classify_labs_dt <- function(labs_dt, ref_dt) {
1760964071501:ref_unique <- unique(ref_dt[, .(lab, lower, upper)])
1760964071501:merged <- merge(labs_dt, ref_unique, by = "lab", all.x = TRUE)
1760964071502:merged[, status := fifelse(value >= lower & value <= upper, "normal", "out_of_range")]
1760964071503:abnormal_by_patient <- merged[, .(total_tests = .N, out_of_range = sum(status == "out_of_range")), by = patient_id]
1760964071504:abnormal_by_lab <- merged[, .(total_tests = .N, out_of_range = sum(status == "out_of_range")), by = lab]
1760964071505:list(merged = merged, abnormal_by_patient = abnormal_by_patient, abnormal_by_lab = abnormal_by_lab)
1760964071506:}
1760964071510:# ==========================================================
1760964071511:# 🧩 TASK 6 — Match vitals to labs
1760964071512:# ==========================================================
1760964071513:#' Nearest-time matching of vitals and labs
1760964071514:#'
1760964071514:#' Matches nearest HR/SBP readings to each lab time and computes correlations.
1760964071515:#'
1760964071516:#' @param labs_dt Lab data.table with time_iso
1760964071517:#' @param vitals_dt Vitals data.table with time_iso
1760964071518:#' @return List with labs_with_vitals and correlations (CRP vs HR/SBP)
1760964071519:#' @export
1760964071520:match_vitals_dt <- function(labs_dt, vitals_dt) {
1760964071521:labs_dt[, time_iso := as.POSIXct(time_iso)]
1760964071522:vitals_dt[, time_iso := as.POSIXct(time_iso)]
1760964071523:setorder(labs_dt, patient_id, time_iso)
1760964071525:setorder(vitals_dt, patient_id, time_iso)
1760964071526:labs_dt[, lab_time := time_iso]
1760964071528:# HR
1760964071529:vitals_hr <- vitals_dt[vital == "HR", .(patient_id, time_iso, value)]
1760964071530:setnames(vitals_hr, "value", "nearest_HR")
1760964071530:vitals_hr[, hr_time := time_iso]
1760964071532:setkey(vitals_hr, patient_id, time_iso)
1760964071533:setkey(labs_dt, patient_id, time_iso)
1760964071534:labs_with_hr <- vitals_hr[labs_dt, roll = "nearest"]
1760964071536:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1760964071538:# SBP
1760964071539:vitals_sbp <- vitals_dt[vital == "SBP", .(patient_id, time_iso, value)]
1760964071540:setnames(vitals_sbp, "value", "nearest_SBP")
1760964071542:vitals_sbp[, sbp_time := time_iso]
1760964071543:setkey(vitals_sbp, patient_id, time_iso)
1760964071544:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1760964071545:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1760964071547:# Correlations
1760964071549:crp <- labs_with_vitals[lab == "CRP"]
1760964071550:cor_hr <- crp[!is.na(nearest_HR), .(correlation_CRP_HR = cor(value, nearest_HR)), by = patient_id]
1760964071552:cor_sbp <- crp[!is.na(nearest_SBP), .(correlation_CRP_SBP = cor(value, nearest_SBP)), by = patient_id]
1760964071554:list(labs_with_vitals = labs_with_vitals, cor_crp_hr = cor_hr, cor_crp_sbp = cor_sbp)
1760964071555:}
1760964071559:# ==========================================================
1760964071560:# 🧩 TASK 7 — Top peaks by score
1760964071561:# ==========================================================
1760964071563:#' Extract peaks on chromosome and return top N by score
1760964071563:#'
1760964071565:#' Filters by genomic region and selects top peaks by score.
1760964071566:#'
1760964071567:#' @param peaks_dt Data.table of peaks (chr, start, end, score)
1760964071568:#' @param chr Chromosome string
1760964071569:#' @param start_min, start_max Range
1760964071570:#' @param top_n Number of top peaks
1760964071571:#' @return Data.table of top peaks
1760964071572:#' @export
1760964071574:top_peaks_dt <- function(peaks_dt, chr = "chr2", start_min = 2e6, start_max = 4e6, top_n = 50) {
1760964071575:subset <- peaks_dt[chr == !!chr & start >= start_min & start <= start_max]
1760964071576:setorder(subset, -score)
1760964071577:head(subset, top_n)
1760964071578:}
1760964071580:# ==========================================================
1760964071581:# 🧩 TASK 8 — Gene stats and filtering
1760964071582:# ==========================================================
1760964071584:#' Per-condition robust summary stats and gene filtering
1760964071585:#'
1760964071586:#' Computes mean, median, quartiles by gene and condition,
1760964071587:#' filters genes with treated_mean ≥ 2 × control_mean.
1760964071589:#'
1760964071590:#' @param counts_dt Counts data.table
1760964071591:#' @param meta_dt Metadata data.table
1760964071592:#' @return List with stats_by_gene_condition and kept_genes
1760964071593:#' @export
1760964071594:gene_stats_filter_dt <- function(counts_dt, meta_dt) {
1760964071595:merged <- counts_dt[meta_dt, on = "sample_id"]
1760964071597:stats <- merged[, .(
1760964071598:mean_count = mean(count),
1760964071599:median_count = median(count),
1760964071600:Q1 = quantile(count, 0.25),
1760964071602:Q3 = quantile(count, 0.75)
1760964071603:), by = .(gene, condition)]
1760964071604:treated <- stats[condition == "treated", .(gene, treated_mean = mean_count)]
1760964071605:control <- stats[condition == "control", .(gene, control_mean = mean_count)]
1760964071607:means <- merge(treated, control, by = "gene")
1760964071608:kept <- means[treated_mean >= 2 * control_mean]
1760964071610:list(stats_by_gene_condition = stats, kept_genes = kept)
1760964071611:}
1760964071613:# ==========================================================
1760964071614:# 🧩 TASK 9 — Wide → Long → Wide
1760964071615:# ==========================================================
1760964071618:#' Convert wide counts to long and back, computing mean per condition
1760964071619:#'
1760964071619:#' @param counts_wide_dt Wide counts table
1760964071621:#' @param meta_dt Metadata table
1760964071623:#' @return Data.table wide by condition with mean counts
1760964071623:#' @export
1760964071624:wide_long_wide_dt <- function(counts_wide_dt, meta_dt) {
1760964071626:idvar <- names(counts_wide_dt)[1]
1760964071627:long <- melt(counts_wide_dt, id.vars = idvar, variable.name = "sample_id", value.name = "count")
1760964071629:merged <- merge(long, meta_dt, by = "sample_id")
1760964071631:mean_dt <- merged[, .(mean_count = mean(count)), by = .(gene = get(idvar), condition)]
1760964071633:dcast(mean_dt, gene ~ condition, value.var = "mean_count")
1760964071634:}
1760964071637:# ==========================================================
1760964071639:# 🧩 TASK 10 — ATAC peaks to genes
1760964071640:# ==========================================================
1760964071641:#' Map ATAC peaks to genes and summarize overlaps
1760964071642:#'
1760964071643:#' Uses genomic overlap to assign peaks to genes and compute overlap statistics.
1760964071644:#'
1760964071645:#' @param peaks_dt Peaks data.table
1760964071646:#' @param genes_dt Gene annotations
1760964071648:#' @return List with overlap tables and top 20 genes by overlap
1760964071649:#' @export
1760964071649:atac_to_gene_dt <- function(peaks_dt, genes_dt) {
1760964071650:setkey(peaks_dt, chr, start, end)
1760964071651:setkey(genes_dt, chr, start, end)
1760964071651:overlaps <- foverlaps(peaks_dt, genes_dt, type = "any", nomatch = 0)
1760964071652:overlaps[, overlap_bp := pmin(end, i.end) - pmax(start, i.start)]
1760964071653:overlaps <- overlaps[overlap_bp > 0]
1760964071655:peaks_per_gene <- overlaps[, .N, by = gene]; setnames(peaks_per_gene, "N", "num_peaks")
1760964071656:overlap_sum <- overlaps[, .(total_overlap_bp = sum(overlap_bp)), by = gene]
1760964071657:top20 <- overlap_sum[order(-total_overlap_bp)][1:20]
1760964071658:list(overlaps = overlaps, peaks_per_gene = peaks_per_gene, overlap_sum_per_gene = overlap_sum, top20_genes = top20)
1760964071659:}
1760964071662:# ==========================================================
1760964071663:# 🧩 TASK 11 — Variants to genes
1760964071664:# ==========================================================
1760964071665:#' Map genetic variants to genes and count HIGH-impact variants
1760964071667:#'
1760964071667:#' @param variants_dt Variant data.table
1760964071668:#' @param genes_dt Gene annotations
1760964071670:#' @return List with counts and high-impact genes
1760964071671:#' @export
1760964071672:variants_to_genes_dt <- function(variants_dt, genes_dt) {
1760964071673:variants_dt[, `:=`(start = pos, end = pos)]
1760964071674:setkey(variants_dt, chr, start, end)
1760964071675:setkey(genes_dt, chr, start, end)
1760964071676:overlaps <- foverlaps(variants_dt, genes_dt, type = "any", nomatch = 0)
1760964071677:overlaps[, impact_upper := toupper(impact)]
1760964071679:high <- overlaps[impact_upper == "HIGH"]
1760964071680:high_gene_sample <- high[, .(high_variant_count = .N), by = .(gene, sample_id)]
1760964071681:high_gene <- high[, .(total_high_variants = .N), by = gene][order(-total_high_variants)]
1760964071682:genes_with_high <- unique(high_gene$gene)
1760964071683:list(high_counts_by_gene_sample = high_gene_sample, high_counts_by_gene = high_gene, genes_with_high = genes_with_high)
1760964071684:}
1760964071688:# ==========================================================
1760964071689:# 🧩 TASK 12 — Combine cohorts
1760964071690:# ==========================================================
1760964071691:#' Combine cohorts safely and compute per-cohort mean counts
1760964071692:#'
1760964071693:#' @param cohortA_dt Cohort A metadata
1760964071695:#' @param cohortB_dt Cohort B metadata
1760964071696:#' @param counts_dt Counts table
1760964071697:#' @param top_n Number of top variable genes
1760964071698:#' @return List with combined cohort info and top genes
1760964071699:#' @export
1760964071700:combine_cohorts_dt <- function(cohortA_dt, cohortB_dt, counts_dt, top_n = 100) {
1760964071701:cohortA_dt[, cohort := "A"]
1760964071702:cohortB_dt[, cohort := "B"]
1760964071704:combined <- rbindlist(list(cohortA_dt, cohortB_dt), use.names = TRUE, fill = TRUE)
1760964071705:merged <- merge(counts_dt, combined, by = "sample_id", all.x = TRUE)
1760964071706:var_dt <- merged[, .(variance = var(count)), by = gene]
1760964071707:top_genes <- var_dt[order(-variance)][1:top_n, gene]
1760964071708:top_data <- merged[gene %in% top_genes]
1760964071709:mean_counts <- top_data[, .(mean_count = mean(count)), by = .(gene, cohort, condition)]
1760964071711:list(combined_cohorts = combined, mean_counts = mean_counts, top_genes = top_genes)
1760964071712:}
1760964071714:# ==========================================================
1760964071715:# 🧩 FINAL REVISION TASKS (1.1 → 5.1)
1760964071716:# ==========================================================
1760964071718:#' Combine integration and clustering data
1760964071719:#'
1760964071720:#' Reads and merges integration and clustering tables by cell ID, ensuring consistent ID formatting.
1760964071721:#'
1760964071722:#' @export
1760964071723:combine_integration_clustering_dt <- function(integration_file, clustering_file) {
1760964071724:int <- fread(integration_file)
1760964071725:clu <- fread(clustering_file)
1760964071727:normalize <- function(x) gsub("_X_|_Y_", "_", trimws(as.character(x)))
1760964071728:int[, cell_clean := normalize(cell)]
1760964071729:clu[, cell_clean := normalize(cell)]
1760964071730:merge(int, clu, by = "cell_clean", all = FALSE)
1760964071732:}
1760964071733:#' Count cells per cluster and cell type
1760964071735:#' @export
1760964071736:count_cells_per_cluster_dt <- function(combined_dt) {
1760964071737:counts <- combined_dt[, .N, by = .(integration_cluster, cell_type)]
1760964071739:setnames(counts, "N", "cell_count")
1760964071740:counts
1760964071741:}
1760964071743:#' Count cells per cluster, cell type, and sample type
1760964071744:#' @export
1760964071745:add_sample_type_dt <- function(combined_dt) {
1760964071746:counts <- combined_dt[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760964071747:setnames(counts, "N", "cell_count")
1760964071748:counts
1760964071749:}
1760964071752:#' Compute total cell counts per cluster and sample type
1760964071753:#' @export
1760964071754:compute_totals_dt <- function(counts_dt) {
1760964071755:counts_dt[, .(total_cells = sum(cell_count)), by = .(integration_cluster, sample_type)]
1760964071756:}
1760964071758:#' Compute normalized percentages per cluster and tissue
1760964071760:#' @export
1760964071760:compute_percentages_dt <- function(counts_dt) {
1760964071762:totals <- counts_dt[, .(total_cells = sum(cell_count)), by = .(integration_cluster, sample_type)]
1760964071763:merged <- merge(counts_dt, totals, by = c("integration_cluster", "sample_type"))
1760964071764:merged[, percent := round((cell_count / total_cells) * 100, 2)]
1760964071764:merged[order(integration_cluster)]
1760964071765:}
1760964077131:devtools::document()
1760964096826:devtools::load_all()
1760964121620:?compute_totals_dt
1760964146495:?classify_labs_dt
1760974172427:library(data.table)
1760974181710:library(data.table)
1760974183404:library(microbenchmark)
1760974186177:library(ggplot2)
1760974193179:# carico le funzioni
1760974193183:source("R/df_functions.R")
1760974195226:source("R/dt_functions.R")
1760974196875:# carico i dati di test
1760974196878:counts <- fread("data/bulk_counts_long.csv")
1760974197729:meta   <- fread("data/sample_metadata.csv")
1760974236017:# carico i dati di test
1760974236021:counts <- fread("project_oct25/bulk_counts_long.csv")
1760974237487:meta   <- fread("project_oct25/sample_metadata.csv")
1760974238924:# esempio con una task (es. Task 1)
1760974238931:bench1 <- microbenchmark(
1760974238934:df_version = bulk_counts_summary_df(as.data.frame(counts), as.data.frame(meta)),
1760974238937:dt_version = bulk_counts_summary_dt(counts, meta),
1760974238939:times = 10
1760974238940:)
1760974262801:?microbenchmark
1760974312695:# esempio con una task (es. Task 1)
1760974312700:bench1 <- microbenchmark(
1760974312701:df_version = bulk_counts_summary_df(as.data.frame(counts), as.data.frame(meta)),
1760974312703:dt_version = bulk_counts_summary_dt(counts, meta),
1760974312704:times = 10
1760974312706:)
1760974450661:# esempio con una task (es. Task 1)
1760974450666:bench1 <- microbenchmark(
1760974450667:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760974450669:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760974450670:times = 10
1760974450672:)
1760974455092:View(bench1)
1760974472901:print(bench1)
1760974528583:autoplot(bench1)
1760974617476:# salvo i risultati numerici
1760974617478:bench_res <- as.data.frame(bench1)
1760974619364:write.csv(bench_res, "results/comparisons/benchmark_task1.csv", row.names = FALSE)
1760974670083:write.csv(bench_res, "Comparison_results/benchmark_task1.csv", row.names = FALSE)
1760974693828:library(data.table)
1760974694324:library(microbenchmark)
1760974694874:library(ggplot2)
1760974695525:# carico le funzioni
1760974695529:source("R/df_functions.R")
1760974697111:source("R/dt_functions.R")
1760974720478:# esempio con una task (es. Task 1)
1760974720482:bench1 <- microbenchmark(
1760974720485:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760974720489:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760974720493:times = 10
1760974720496:)
1760974723511:print(bench1)
1760974724414:autoplot(bench1)
1760974732329:write.csv(bench1, "Comparison_results/benchmark_task1.csv", row.names = FALSE)
1760974738735:View(bench1)
1760974808428:View(bench1)
1760974818265:View(bench1)
1760975067533:View(bench1)
1760978011373:autoplot(bench1)
1760978264285:View(bench1)
1760978493758:# Task 2
1760978493761:bench2 <- microbenchmark(
1760978493763:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1760978493764:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1760978493767:times = 10
1760978493768:)
1760979041954:library(data.table)
1760979041970:# ==========================================================
1760979041973:# 🧩 TASK 1 — Bulk RNA counts summary
1760979041975:# ==========================================================
1760979041977:#' Summarize bulk RNA counts with metadata (data.table version)
1760979041978:#'
1760979041979:#' Merges bulk RNA-seq count data with sample metadata, filters treated samples
1760979041981:#' whose gene names start with "GENE_00", and computes mean/median counts per gene,
1760979041982:#' as well as per-condition mean counts.
1760979041987:#'
1760979041995:#' @param counts_path Path to CSV file with columns: sample_id, gene, count.
1760979042008:#' @param meta_path Path to CSV file with columns: sample_id, condition.
1760979042013:#' @return List with:
1760979042018:#' \itemize{
1760979042020:#'   \item gene_mean_median: Mean and median counts by gene (treated only)
1760979042022:#'   \item gene_condition_means: Mean counts by gene and condition
1760979042024:#' }
1760979042026:#' @export
1760979042028:bulk_counts_summary_dt <- function(counts_path, meta_path) {
1760979042029:counts <- fread(counts_path)
1760979042031:meta <- fread(meta_path)
1760979042033:setkey(counts, sample_id)
1760979042034:setkey(meta, sample_id)
1760979042039:merged <- counts[meta, nomatch = 0]
1760979042042:filtered <- merged[condition == "treated" & grepl("^GENE_00", gene)]
1760979042045:gene_mean_median <- filtered[, .(
1760979042046:mean_count = mean(count),
1760979042048:median_count = median(count)
1760979042049:), by = gene]
1760979042051:gene_condition_means <- merged[, .(
1760979042061:mean_count = mean(count)
1760979042063:), by = .(gene, condition)]
1760979042066:list(
1760979042118:gene_mean_median = gene_mean_median,
1760979042119:gene_condition_means = gene_condition_means
1760979042132:)
1760979042166:}
1760979042169:# ==========================================================
1760979042173:# 🧩 TASK 2 — QC-style derived columns
1760979042176:# ==========================================================
1760979042183:#' Add QC-style derived columns (data.table version)
1760979042184:#'
1760979042187:#' Adds log2-transformed counts and a binary \code{high} flag based on gene-wise medians.
1760979042188:#'
1760979042190:#' @param counts_path Path to CSV file with columns: sample_id, gene, count.
1760979042191:#' @return Data.table with added columns: log2_count, high.
1760979042195:#' @export
1760979042196:bulk_counts_qc_dt <- function(counts_path) {
1760979042198:dt <- fread(counts_path)
1760979042199:dt[, log2_count := log2(count + 1)]
1760979042200:dt[, high := count > median(count), by = gene]
1760979042202:dt[]
1760979042203:}
1760979042206:# ==========================================================
1760979042207:# 🧩 TASK 3 — Subset by gene and sample
1760979042208:# ==========================================================
1760979042212:#' Subset counts data using secondary index
1760979042213:#'
1760979042214:#' Joins metadata and subsets for a specific gene and sample using fast indexing.
1760979042215:#'
1760979042216:#' @param counts data.table of bulk counts
1760979042216:#' @param meta data.table of sample metadata
1760979042217:#' @param gene_name Gene name to subset
1760979042217:#' @param sample_chosen Sample ID to subset
1760979042218:#' @return Subset of counts for the given gene and sample.
1760979042219:#' @export
1760979042224:subset_counts_dt <- function(counts, meta, gene_name, sample_chosen) {
1760979042229:setkey(meta, sample_id)
1760979042234:setindex(counts, gene, sample_id)
1760979042236:counts[gene == gene_name & sample_id == sample_chosen]
1760979042237:}
1760979042239:# ==========================================================
1760979042240:# 🧩 TASK 4 — Annotate counts and summarize
1760979042241:# ==========================================================
1760979042243:#' Annotate counts with metadata and compute summaries
1760979042244:#'
1760979042248:#' Joins counts and metadata, computes per-patient total counts,
1760979042250:#' mean counts per gene and condition, and identifies top 10 genes.
1760979042251:#'
1760979042251:#' @param counts data.table of bulk counts
1760979042252:#' @param meta data.table of sample metadata
1760979042253:#' @return List with joined data, patient totals, and top10 genes.
1760979042254:#' @export
1760979042255:annotate_counts_dt <- function(counts, meta) {
1760979042256:setkey(counts, sample_id)
1760979042257:setkey(meta, sample_id)
1760979042257:joined <- counts[meta, nomatch = 0]
1760979042259:patient_tot <- joined[, .(total_count = sum(count)), by = patient_id]
1760979042260:gene_means <- joined[, .(mean_count = mean(count)), by = .(gene, condition)]
1760979042260:top10 <- gene_means[order(condition, -mean_count)][, head(.SD, 10), by = condition]
1760979042261:list(joined = joined, patient_tot = patient_tot, top10 = top10)
1760979042262:}
1760979042264:# ==========================================================
1760979042264:# 🧩 TASK 5 — Classify lab values
1760979042265:# ==========================================================
1760979042266:#' Classify lab values against reference intervals
1760979042266:#'
1760979042267:#' Joins lab results and reference ranges, classifies as "normal" or "out_of_range",
1760979042268:#' and summarizes abnormalities per patient and per lab.
1760979042269:#'
1760979042269:#' @param labs_dt Data.table with columns: patient_id, lab, value.
1760979042270:#' @param ref_dt Data.table with columns: lab, lower, upper.
1760979042270:#' @return List with merged data, abnormal_by_patient, abnormal_by_lab.
1760979042271:#' @export
1760979042272:classify_labs_dt <- function(labs_dt, ref_dt) {
1760979042272:ref_unique <- unique(ref_dt[, .(lab, lower, upper)])
1760979042273:merged <- merge(labs_dt, ref_unique, by = "lab", all.x = TRUE)
1760979042273:merged[, status := fifelse(value >= lower & value <= upper, "normal", "out_of_range")]
1760979042274:abnormal_by_patient <- merged[, .(total_tests = .N, out_of_range = sum(status == "out_of_range")), by = patient_id]
1760979042275:abnormal_by_lab <- merged[, .(total_tests = .N, out_of_range = sum(status == "out_of_range")), by = lab]
1760979042275:list(merged = merged, abnormal_by_patient = abnormal_by_patient, abnormal_by_lab = abnormal_by_lab)
1760979042276:}
1760979042277:# ==========================================================
1760979042278:# 🧩 TASK 6 — Match vitals to labs
1760979042278:# ==========================================================
1760979042279:#' Nearest-time matching of vitals and labs
1760979042280:#'
1760979042280:#' Matches nearest HR/SBP readings to each lab time and computes correlations.
1760979042281:#'
1760979042282:#' @param labs_dt Lab data.table with time_iso
1760979042283:#' @param vitals_dt Vitals data.table with time_iso
1760979042284:#' @return List with labs_with_vitals and correlations (CRP vs HR/SBP)
1760979042284:#' @export
1760979042285:match_vitals_dt <- function(labs_dt, vitals_dt) {
1760979042286:labs_dt[, time_iso := as.POSIXct(time_iso)]
1760979042287:vitals_dt[, time_iso := as.POSIXct(time_iso)]
1760979042288:setorder(labs_dt, patient_id, time_iso)
1760979042288:setorder(vitals_dt, patient_id, time_iso)
1760979042289:labs_dt[, lab_time := time_iso]
1760979042291:# HR
1760979042291:vitals_hr <- vitals_dt[vital == "HR", .(patient_id, time_iso, value)]
1760979042292:setnames(vitals_hr, "value", "nearest_HR")
1760979042293:vitals_hr[, hr_time := time_iso]
1760979042294:setkey(vitals_hr, patient_id, time_iso)
1760979042295:setkey(labs_dt, patient_id, time_iso)
1760979042295:labs_with_hr <- vitals_hr[labs_dt, roll = "nearest"]
1760979042296:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1760979042298:# SBP
1760979042299:vitals_sbp <- vitals_dt[vital == "SBP", .(patient_id, time_iso, value)]
1760979042301:setnames(vitals_sbp, "value", "nearest_SBP")
1760979042302:vitals_sbp[, sbp_time := time_iso]
1760979042303:setkey(vitals_sbp, patient_id, time_iso)
1760979042304:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1760979042306:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1760979042308:# Correlations
1760979042309:crp <- labs_with_vitals[lab == "CRP"]
1760979042311:cor_hr <- crp[!is.na(nearest_HR), .(correlation_CRP_HR = cor(value, nearest_HR)), by = patient_id]
1760979042312:cor_sbp <- crp[!is.na(nearest_SBP), .(correlation_CRP_SBP = cor(value, nearest_SBP)), by = patient_id]
1760979042315:list(labs_with_vitals = labs_with_vitals, cor_crp_hr = cor_hr, cor_crp_sbp = cor_sbp)
1760979042316:}
1760979042318:# ==========================================================
1760979042319:# 🧩 TASK 7 — Top peaks by score
1760979042319:# ==========================================================
1760979042320:#' Extract peaks on chromosome and return top N by score
1760979042321:#'
1760979042322:#' Filters by genomic region and selects top peaks by score.
1760979042323:#'
1760979042325:#' @param peaks_dt Data.table of peaks (chr, start, end, score)
1760979042326:#' @param chr Chromosome string
1760979042327:#' @param start_min, start_max Range
1760979042328:#' @param top_n Number of top peaks
1760979042329:#' @return Data.table of top peaks
1760979042329:#' @export
1760979042330:top_peaks_dt <- function(peaks_dt, chr = "chr2", start_min = 2e6, start_max = 4e6, top_n = 50) {
1760979042332:subset <- peaks_dt[chr == !!chr & start >= start_min & start <= start_max]
1760979042332:setorder(subset, -score)
1760979042334:head(subset, top_n)
1760979042334:}
1760979042336:# ==========================================================
1760979042337:# 🧩 TASK 8 — Gene stats and filtering
1760979042338:# ==========================================================
1760979042340:#' Per-condition robust summary stats and gene filtering
1760979042341:#'
1760979042341:#' Computes mean, median, quartiles by gene and condition,
1760979042342:#' filters genes with treated_mean ≥ 2 × control_mean.
1760979042343:#'
1760979042343:#' @param counts_dt Counts data.table
1760979042344:#' @param meta_dt Metadata data.table
1760979042345:#' @return List with stats_by_gene_condition and kept_genes
1760979042346:#' @export
1760979042347:gene_stats_filter_dt <- function(counts_dt, meta_dt) {
1760979042348:merged <- counts_dt[meta_dt, on = "sample_id"]
1760979042348:stats <- merged[, .(
1760979042349:mean_count = mean(count),
1760979042349:median_count = median(count),
1760979042350:Q1 = quantile(count, 0.25),
1760979042351:Q3 = quantile(count, 0.75)
1760979042352:), by = .(gene, condition)]
1760979042352:treated <- stats[condition == "treated", .(gene, treated_mean = mean_count)]
1760979042354:control <- stats[condition == "control", .(gene, control_mean = mean_count)]
1760979042355:means <- merge(treated, control, by = "gene")
1760979042356:kept <- means[treated_mean >= 2 * control_mean]
1760979042356:list(stats_by_gene_condition = stats, kept_genes = kept)
1760979042357:}
1760979042359:# ==========================================================
1760979042360:# 🧩 TASK 9 — Wide → Long → Wide
1760979042361:# ==========================================================
1760979042363:#' Convert wide counts to long and back, computing mean per condition
1760979042364:#'
1760979042365:#' @param counts_wide_dt Wide counts table
1760979042365:#' @param meta_dt Metadata table
1760979042366:#' @return Data.table wide by condition with mean counts
1760979042367:#' @export
1760979042367:wide_long_wide_dt <- function(counts_wide_dt, meta_dt) {
1760979042368:idvar <- names(counts_wide_dt)[1]
1760979042369:long <- melt(counts_wide_dt, id.vars = idvar, variable.name = "sample_id", value.name = "count")
1760979042370:merged <- merge(long, meta_dt, by = "sample_id")
1760979042370:mean_dt <- merged[, .(mean_count = mean(count)), by = .(gene = get(idvar), condition)]
1760979042371:dcast(mean_dt, gene ~ condition, value.var = "mean_count")
1760979042372:}
1760979042374:# ==========================================================
1760979042374:# 🧩 TASK 10 — ATAC peaks to genes
1760979042375:# ==========================================================
1760979042376:#' Map ATAC peaks to genes and summarize overlaps
1760979042377:#'
1760979042377:#' Uses genomic overlap to assign peaks to genes and compute overlap statistics.
1760979042378:#'
1760979042378:#' @param peaks_dt Peaks data.table
1760979042379:#' @param genes_dt Gene annotations
1760979042380:#' @return List with overlap tables and top 20 genes by overlap
1760979042381:#' @export
1760979042382:atac_to_gene_dt <- function(peaks_dt, genes_dt) {
1760979042383:setkey(peaks_dt, chr, start, end)
1760979042383:setkey(genes_dt, chr, start, end)
1760979042384:overlaps <- foverlaps(peaks_dt, genes_dt, type = "any", nomatch = 0)
1760979042385:overlaps[, overlap_bp := pmin(end, i.end) - pmax(start, i.start)]
1760979042386:overlaps <- overlaps[overlap_bp > 0]
1760979042386:peaks_per_gene <- overlaps[, .N, by = gene]; setnames(peaks_per_gene, "N", "num_peaks")
1760979042387:overlap_sum <- overlaps[, .(total_overlap_bp = sum(overlap_bp)), by = gene]
1760979042388:top20 <- overlap_sum[order(-total_overlap_bp)][1:20]
1760979042389:list(overlaps = overlaps, peaks_per_gene = peaks_per_gene, overlap_sum_per_gene = overlap_sum, top20_genes = top20)
1760979042390:}
1760979042392:# ==========================================================
1760979042392:# 🧩 TASK 11 — Variants to genes
1760979042393:# ==========================================================
1760979042394:#' Map genetic variants to genes and count HIGH-impact variants
1760979042395:#'
1760979042396:#' @param variants_dt Variant data.table
1760979042397:#' @param genes_dt Gene annotations
1760979042397:#' @return List with counts and high-impact genes
1760979042398:#' @export
1760979042399:variants_to_genes_dt <- function(variants_dt, genes_dt) {
1760979042400:variants_dt[, `:=`(start = pos, end = pos)]
1760979042400:setkey(variants_dt, chr, start, end)
1760979042401:setkey(genes_dt, chr, start, end)
1760979042402:overlaps <- foverlaps(variants_dt, genes_dt, type = "any", nomatch = 0)
1760979042402:overlaps[, impact_upper := toupper(impact)]
1760979042403:high <- overlaps[impact_upper == "HIGH"]
1760979042404:high_gene_sample <- high[, .(high_variant_count = .N), by = .(gene, sample_id)]
1760979042404:high_gene <- high[, .(total_high_variants = .N), by = gene][order(-total_high_variants)]
1760979042405:genes_with_high <- unique(high_gene$gene)
1760979042406:list(high_counts_by_gene_sample = high_gene_sample, high_counts_by_gene = high_gene, genes_with_high = genes_with_high)
1760979042406:}
1760979042408:# ==========================================================
1760979042408:# 🧩 TASK 12 — Combine cohorts
1760979042409:# ==========================================================
1760979042410:#' Combine cohorts safely and compute per-cohort mean counts
1760979042410:#'
1760979042411:#' @param cohortA_dt Cohort A metadata
1760979042411:#' @param cohortB_dt Cohort B metadata
1760979042412:#' @param counts_dt Counts table
1760979042412:#' @param top_n Number of top variable genes
1760979042413:#' @return List with combined cohort info and top genes
1760979042413:#' @export
1760979042414:combine_cohorts_dt <- function(cohortA_dt, cohortB_dt, counts_dt, top_n = 100) {
1760979042414:cohortA_dt[, cohort := "A"]
1760979042415:cohortB_dt[, cohort := "B"]
1760979042416:combined <- rbindlist(list(cohortA_dt, cohortB_dt), use.names = TRUE, fill = TRUE)
1760979042416:merged <- merge(counts_dt, combined, by = "sample_id", all.x = TRUE)
1760979042417:var_dt <- merged[, .(variance = var(count)), by = gene]
1760979042418:top_genes <- var_dt[order(-variance)][1:top_n, gene]
1760979042419:top_data <- merged[gene %in% top_genes]
1760979042419:mean_counts <- top_data[, .(mean_count = mean(count)), by = .(gene, cohort, condition)]
1760979042420:list(combined_cohorts = combined, mean_counts = mean_counts, top_genes = top_genes)
1760979042421:}
1760979042422:# ==========================================================
1760979042423:# 🧩 FINAL REVISION TASKS (1.1 → 5.1)
1760979042424:# ==========================================================
1760979042425:#' Combine integration and clustering data
1760979042425:#'
1760979042426:#' Reads and merges integration and clustering tables by cell ID, ensuring consistent ID formatting.
1760979042427:#'
1760979042428:#' @export
1760979042428:combine_integration_clustering_dt <- function(integration_file, clustering_file) {
1760979042429:int <- fread(integration_file)
1760979042429:clu <- fread(clustering_file)
1760979042430:normalize <- function(x) gsub("_X_|_Y_", "_", trimws(as.character(x)))
1760979042431:int[, cell_clean := normalize(cell)]
1760979042431:clu[, cell_clean := normalize(cell)]
1760979042432:merge(int, clu, by = "cell_clean", all = FALSE)
1760979042433:}
1760979042434:#' Count cells per cluster and cell type
1760979042434:#' @export
1760979042435:count_cells_per_cluster_dt <- function(combined_dt) {
1760979042436:counts <- combined_dt[, .N, by = .(integration_cluster, cell_type)]
1760979042437:setnames(counts, "N", "cell_count")
1760979042438:counts
1760979042438:}
1760979042440:#' Count cells per cluster, cell type, and sample type
1760979042440:#' @export
1760979042441:add_sample_type_dt <- function(combined_dt) {
1760979042442:counts <- combined_dt[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760979042443:setnames(counts, "N", "cell_count")
1760979042443:counts
1760979042444:}
1760979042445:#' Compute total cell counts per cluster and sample type
1760979042445:#' @export
1760979042446:compute_totals_dt <- function(counts_dt) {
1760979042447:counts_dt[, .(total_cells = sum(cell_count)), by = .(integration_cluster, sample_type)]
1760979042447:}
1760979042448:#' Compute normalized percentages per cluster and tissue
1760979042449:#' @export
1760979042449:compute_percentages_dt <- function(counts_dt) {
1760979042450:totals <- counts_dt[, .(total_cells = sum(cell_count)), by = .(integration_cluster, sample_type)]
1760979042450:merged <- merge(counts_dt, totals, by = c("integration_cluster", "sample_type"))
1760979042451:merged[, percent := round((cell_count / total_cells) * 100, 2)]
1760979042452:merged[order(integration_cluster)]
1760979042452:}
1760979053655:devtools::document()
1760979094940:devtools::load_all()
1760979115295:# Task 2
1760979115298:bench2 <- microbenchmark(
1760979115302:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1760979115305:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1760979115308:times = 10
1760979115312:)
1760979115934:autoplot(bench2)
1760979167464:# ==========================================================
1760979167468:# df_functions.R
1760979167473:# Generalized and reusable base R (data.frame) functions
1760979167481:# for bulk RNA-seq processing and summarization
1760979167483:# ==========================================================
1760979167489:# ----------------------------------------------------------
1760979167492:# TASK 1 – Merge, filter, summarize, and compute per-condition means
1760979167494:# ----------------------------------------------------------
1760979167495:bulk_counts_summary_df <- function(counts_path, meta_path) {
1760979167499:counts <- read.csv(counts_path)
1760979167500:meta   <- read.csv(meta_path)
1760979167506:merged_data <- merge(counts, meta, by = "sample_id")
1760979167507:treated_data <- subset(merged_data,
1760979167508:condition == "treated" & grepl("^GENE_00", gene))
1760979167513:gene_summary <- aggregate(
1760979167514:count ~ gene,
1760979167515:data = treated_data,
1760979167516:FUN  = function(x) c(mean = mean(x), median = median(x))
1760979167518:)
1760979167520:gene_summary_df <- data.frame(
1760979167521:gene = gene_summary$gene,
1760979167522:mean_count   = gene_summary$count[, "mean"],
1760979167523:median_count = gene_summary$count[, "median"]
1760979167525:)
1760979167527:gene_condition_means <- aggregate(
1760979167528:count ~ gene + condition,
1760979167529:data = merged_data,
1760979167531:FUN = mean,
1760979167532:na.rm = TRUE
1760979167533:)
1760979167535:gene_condition_means <- gene_condition_means[
1760979167536:order(gene_condition_means$gene, gene_condition_means$condition), ]
1760979167538:return(list(
1760979167539:filtered_summary = gene_summary_df,
1760979167540:per_condition_means = gene_condition_means
1760979167541:))
1760979167542:}
1760979167543:# ----------------------------------------------------------
1760979167544:# TASK 2 – Add log2(count + 1) and binary flags
1760979167545:# ----------------------------------------------------------
1760979167546:bulk_counts_qc_df <- function(counts_path) {
1760979167547:counts <- read.csv(counts_path, stringsAsFactors = FALSE)
1760979167548:counts$log2_count <- log2(counts$count + 1)
1760979167549:counts$high <- counts$count > 100
1760979167551:medians_by_gene <- tapply(counts$count, counts$gene, median)
1760979167551:counts$high <- counts$count > medians_by_gene[counts$gene]
1760979167553:return(counts)
1760979167554:}
1760979167555:# ----------------------------------------------------------
1760979167556:# TASK 3 – Normalization by gene-wise mean
1760979167557:# ----------------------------------------------------------
1760979167557:subset_counts_df <- function(counts_path) {
1760979167558:counts <- read.csv(counts_path)
1760979167559:mean_by_gene <- tapply(counts$count, counts$gene, mean, na.rm = TRUE)
1760979167560:counts$norm_count <- counts$count / mean_by_gene[counts$gene]
1760979167563:return(counts)
1760979167564:}
1760979167565:# ----------------------------------------------------------
1760979167566:# TASK 4 – Filter genes by thresholded normalized expression
1760979167567:# ----------------------------------------------------------
1760979167568:annotate_counts_df <- function(counts_path, threshold = 1.5) {
1760979167568:counts <- read.csv(counts_path)
1760979167570:mean_by_gene <- tapply(counts$count, counts$gene, mean, na.rm = TRUE)
1760979167570:counts$norm_count <- counts$count / mean_by_gene[counts$gene]
1760979167571:counts_filt <- subset(counts, norm_count > threshold)
1760979167572:return(counts_filt)
1760979167573:}
1760979167575:# ----------------------------------------------------------
1760979167576:# TASK 5 – Summary table by condition and gene class
1760979167576:# ----------------------------------------------------------
1760979167577:classify_labs_df <- function(counts_path, meta_path) {
1760979167578:counts <- read.csv(counts_path)
1760979167578:meta   <- read.csv(meta_path)
1760979167580:merged <- merge(counts, meta, by = "sample_id")
1760979167581:merged$gene_class <- ifelse(grepl("^GENE_00", merged$gene), "A", "B")
1760979167582:summary_df <- aggregate(count ~ condition + gene_class,
1760979167583:data = merged,
1760979167583:FUN = mean)
1760979167584:return(summary_df)
1760979167585:}
1760979167587:# ----------------------------------------------------------
1760979167587:# TASK 6 – Compute fold change between treated and control
1760979167588:# ----------------------------------------------------------
1760979167588:match_vitals_df <- function(counts_path, meta_path) {
1760979167589:counts <- read.csv(counts_path)
1760979167589:meta   <- read.csv(meta_path)
1760979167590:merged <- merge(counts, meta, by = "sample_id")
1760979167592:means <- aggregate(count ~ gene + condition, data = merged, mean)
1760979167592:spread <- reshape(means, timevar = "condition", idvar = "gene", direction = "wide")
1760979167593:spread$fold_change <- spread$count.treated / spread$count.control
1760979167594:return(spread)
1760979167595:}
1760979167596:# ----------------------------------------------------------
1760979167597:# TASK 7 – Compute coefficient of variation (CV)
1760979167597:# ----------------------------------------------------------
1760979167598:top_peaks_df <- function(counts_path) {
1760979167598:counts <- read.csv(counts_path)
1760979167599:cv_df <- aggregate(count ~ gene, data = counts,
1760979167599:FUN = function(x) sd(x) / mean(x))
1760979167600:names(cv_df)[2] <- "cv"
1760979167601:return(cv_df)
1760979167601:}
1760979167603:# ----------------------------------------------------------
1760979167603:# TASK 8 – Identify most variable genes
1760979167604:# ----------------------------------------------------------
1760979167604:gene_stats_filter_df <- function(counts_path, top_n = 10) {
1760979167605:counts <- read.csv(counts_path)
1760979167605:cv_df <- aggregate(count ~ gene, data = counts,
1760979167606:FUN = function(x) sd(x) / mean(x))
1760979167607:names(cv_df)[2] <- "cv"
1760979167607:top_genes <- head(cv_df[order(-cv_df$cv), ], top_n)
1760979167608:return(top_genes)
1760979167609:}
1760979167610:# ----------------------------------------------------------
1760979167611:# TASK 9 – Compute correlation matrix across samples
1760979167611:# ----------------------------------------------------------
1760979167612:wide_long_wide_df <- function(counts_path) {
1760979167613:counts <- read.csv(counts_path)
1760979167614:mat <- reshape(counts, timevar = "sample_id", idvar = "gene", direction = "wide")
1760979167614:mat <- mat[, -1]
1760979167615:corr <- cor(mat, use = "pairwise.complete.obs")
1760979167615:return(corr)
1760979167616:}
1760979167617:# ----------------------------------------------------------
1760979167618:# TASK 10 – PCA on normalized data
1760979167618:# ----------------------------------------------------------
1760979167619:atac_to_gene_df <- function(counts_path) {
1760979167619:counts <- read.csv(counts_path)
1760979167620:mat <- reshape(counts, timevar = "sample_id", idvar = "gene", direction = "wide")
1760979167621:mat <- mat[, -1]
1760979167621:mat <- scale(mat)
1760979167622:pca_res <- prcomp(mat)
1760979167622:return(pca_res)
1760979167623:}
1760979167624:# ----------------------------------------------------------
1760979167624:# TASK 11 – Plot gene expression distribution
1760979167625:# ----------------------------------------------------------
1760979167625:variants_to_genes_df <- function(counts_path) {
1760979167626:counts <- read.csv(counts_path)
1760979167626:hist(counts$count,
1760979167627:main = "Gene Expression Distribution",
1760979167627:xlab = "Count",
1760979167628:col = "lightblue", border = "white")
1760979167629:}
1760979167630:# ----------------------------------------------------------
1760979167630:# TASK 12 – Compute summary statistics
1760979167631:# ----------------------------------------------------------
1760979167631:combine_cohorts_df <- function(counts_path) {
1760979167632:counts <- read.csv(counts_path)
1760979167633:summary_stats <- data.frame(
1760979167633:min = min(counts$count),
1760979167634:max = max(counts$count),
1760979167634:mean = mean(counts$count),
1760979167635:median = median(counts$count),
1760979167635:sd = sd(counts$count)
1760979167636:)
1760979167636:return(summary_stats)
1760979167637:}
1760979174280:# Task 2
1760979174285:bench2 <- microbenchmark(
1760979174287:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1760979174289:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1760979174291:times = 10
1760979174292:)
1760979175431:autoplot(bench2)
1760979176079:# Task 3
1760979176082:bench2 <- microbenchmark(
1760979176084:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1760979176085:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1760979176086:times = 10
1760979176087:)
1760979312533:# Task 3
1760979312543:bench3 <- microbenchmark(
1760979312551:df_version = subset_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979312553:dt_version = subset_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv")
1760979312556:times = 10
1760979336950:# Task 3
1760979336952:bench3 <- microbenchmark(
1760979336953:df_version = subset_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979336955:dt_version = subset_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979336957:times = 10
1760979336959:)
1760979397849:# ==========================================================
1760979397853:# df_functions.R
1760979397856:# Generalized and reusable base R (data.frame) functions
1760979397860:# for bulk RNA-seq processing and summarization
1760979397862:# ==========================================================
1760979397864:# ----------------------------------------------------------
1760979397865:# TASK 1 – Merge, filter, summarize, and compute per-condition means
1760979397866:# ----------------------------------------------------------
1760979397867:bulk_counts_summary_df <- function(counts_path, meta_path) {
1760979397868:counts <- read.csv(counts_path)
1760979397869:meta   <- read.csv(meta_path)
1760979397870:merged_data <- merge(counts, meta, by = "sample_id")
1760979397871:treated_data <- subset(merged_data,
1760979397872:condition == "treated" & grepl("^GENE_00", gene))
1760979397876:gene_summary <- aggregate(
1760979397877:count ~ gene,
1760979397879:data = treated_data,
1760979397880:FUN  = function(x) c(mean = mean(x), median = median(x))
1760979397881:)
1760979397883:gene_summary_df <- data.frame(
1760979397884:gene = gene_summary$gene,
1760979397885:mean_count   = gene_summary$count[, "mean"],
1760979397887:median_count = gene_summary$count[, "median"]
1760979397888:)
1760979397890:gene_condition_means <- aggregate(
1760979397890:count ~ gene + condition,
1760979397892:data = merged_data,
1760979397893:FUN = mean,
1760979397894:na.rm = TRUE
1760979397896:)
1760979397898:gene_condition_means <- gene_condition_means[
1760979397899:order(gene_condition_means$gene, gene_condition_means$condition), ]
1760979397901:return(list(
1760979397901:filtered_summary = gene_summary_df,
1760979397903:per_condition_means = gene_condition_means
1760979397903:))
1760979397904:}
1760979397906:# ----------------------------------------------------------
1760979397907:# TASK 2 – Add log2(count + 1) and binary flags
1760979397908:# ----------------------------------------------------------
1760979397908:bulk_counts_qc_df <- function(counts_path) {
1760979397909:counts <- read.csv(counts_path, stringsAsFactors = FALSE)
1760979397911:counts$log2_count <- log2(counts$count + 1)
1760979397911:counts$high <- counts$count > 100
1760979397912:medians_by_gene <- tapply(counts$count, counts$gene, median)
1760979397913:counts$high <- counts$count > medians_by_gene[counts$gene]
1760979397914:return(counts)
1760979397915:}
1760979397916:# ----------------------------------------------------------
1760979397917:# TASK 3 – Normalization by gene-wise mean
1760979397917:# ----------------------------------------------------------
1760979397918:subset_counts_df <- function(counts_path) {
1760979397919:counts <- read.csv(counts_path)
1760979397920:mean_by_gene <- tapply(counts$count, counts$gene, mean, na.rm = TRUE)
1760979397920:counts$norm_count <- counts$count / mean_by_gene[counts$gene]
1760979397922:return(counts)
1760979397922:}
1760979397923:# ----------------------------------------------------------
1760979397924:# TASK 4 – Filter genes by thresholded normalized expression
1760979397925:# ----------------------------------------------------------
1760979397925:annotate_counts_df <- function(counts_path, threshold = 1.5) {
1760979397926:counts <- read.csv(counts_path)
1760979397927:mean_by_gene <- tapply(counts$count, counts$gene, mean, na.rm = TRUE)
1760979397928:counts$norm_count <- counts$count / mean_by_gene[counts$gene]
1760979397929:counts_filt <- subset(counts, norm_count > threshold)
1760979397930:return(counts_filt)
1760979397930:}
1760979397931:# ----------------------------------------------------------
1760979397932:# TASK 5 – Summary table by condition and gene class
1760979397932:# ----------------------------------------------------------
1760979397933:classify_labs_df <- function(counts_path, meta_path) {
1760979397934:counts <- read.csv(counts_path)
1760979397934:meta   <- read.csv(meta_path)
1760979397935:merged <- merge(counts, meta, by = "sample_id")
1760979397936:merged$gene_class <- ifelse(grepl("^GENE_00", merged$gene), "A", "B")
1760979397937:summary_df <- aggregate(count ~ condition + gene_class,
1760979397938:data = merged,
1760979397938:FUN = mean)
1760979397939:return(summary_df)
1760979397939:}
1760979397941:# ----------------------------------------------------------
1760979397942:# TASK 6 – Compute fold change between treated and control
1760979397942:# ----------------------------------------------------------
1760979397943:match_vitals_df <- function(counts_path, meta_path) {
1760979397943:counts <- read.csv(counts_path)
1760979397944:meta   <- read.csv(meta_path)
1760979397945:merged <- merge(counts, meta, by = "sample_id")
1760979397946:means <- aggregate(count ~ gene + condition, data = merged, mean)
1760979397947:spread <- reshape(means, timevar = "condition", idvar = "gene", direction = "wide")
1760979397948:spread$fold_change <- spread$count.treated / spread$count.control
1760979397949:return(spread)
1760979397949:}
1760979397951:# ----------------------------------------------------------
1760979397951:# TASK 7 – Compute coefficient of variation (CV)
1760979397952:# ----------------------------------------------------------
1760979397952:top_peaks_df <- function(counts_path) {
1760979397953:counts <- read.csv(counts_path)
1760979397953:cv_df <- aggregate(count ~ gene, data = counts,
1760979397954:FUN = function(x) sd(x) / mean(x))
1760979397954:names(cv_df)[2] <- "cv"
1760979397955:return(cv_df)
1760979397956:}
1760979397957:# ----------------------------------------------------------
1760979397957:# TASK 8 – Identify most variable genes
1760979397958:# ----------------------------------------------------------
1760979397958:gene_stats_filter_df <- function(counts_path, top_n = 10) {
1760979397959:counts <- read.csv(counts_path)
1760979397959:cv_df <- aggregate(count ~ gene, data = counts,
1760979397960:FUN = function(x) sd(x) / mean(x))
1760979397961:names(cv_df)[2] <- "cv"
1760979397962:top_genes <- head(cv_df[order(-cv_df$cv), ], top_n)
1760979397962:return(top_genes)
1760979397963:}
1760979397964:# ----------------------------------------------------------
1760979397965:# TASK 9 – Compute correlation matrix across samples
1760979397965:# ----------------------------------------------------------
1760979397966:wide_long_wide_df <- function(counts_path) {
1760979397966:counts <- read.csv(counts_path)
1760979397967:mat <- reshape(counts, timevar = "sample_id", idvar = "gene", direction = "wide")
1760979397967:mat <- mat[, -1]
1760979397968:corr <- cor(mat, use = "pairwise.complete.obs")
1760979397969:return(corr)
1760979397969:}
1760979397970:# ----------------------------------------------------------
1760979397971:# TASK 10 – PCA on normalized data
1760979397971:# ----------------------------------------------------------
1760979397972:atac_to_gene_df <- function(counts_path) {
1760979397973:counts <- read.csv(counts_path)
1760979397973:mat <- reshape(counts, timevar = "sample_id", idvar = "gene", direction = "wide")
1760979397974:mat <- mat[, -1]
1760979397974:mat <- scale(mat)
1760979397975:pca_res <- prcomp(mat)
1760979397975:return(pca_res)
1760979397976:}
1760979397977:# ----------------------------------------------------------
1760979397977:# TASK 11 – Plot gene expression distribution
1760979397978:# ----------------------------------------------------------
1760979397978:variants_to_genes_df <- function(counts_path) {
1760979397979:counts <- read.csv(counts_path)
1760979397979:hist(counts$count,
1760979397980:main = "Gene Expression Distribution",
1760979397980:xlab = "Count",
1760979397981:col = "lightblue", border = "white")
1760979397981:}
1760979397983:# ----------------------------------------------------------
1760979397983:# TASK 12 – Compute summary statistics
1760979397984:# ----------------------------------------------------------
1760979397984:combine_cohorts_df <- function(counts_path) {
1760979397985:counts <- read.csv(counts_path)
1760979397986:summary_stats <- data.frame(
1760979397986:min = min(counts$count),
1760979397987:max = max(counts$count),
1760979397987:mean = mean(counts$count),
1760979397988:median = median(counts$count),
1760979397988:sd = sd(counts$count)
1760979397989:)
1760979397989:return(summary_stats)
1760979397990:}
1760979412830:devtools::document()
1760979423407:devtools::load_all()
1760979429802:# Task 3
1760979429807:bench3 <- microbenchmark(
1760979429809:df_version = subset_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979429810:dt_version = subset_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979429812:times = 10
1760979429813:)
1760979613702:# Task 4
1760979613707:bench4 <- microbenchmark(
1760979613708:df_version = annotate_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979613710:dt_version = annotate_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979613711:times = 10
1760979613712:)
1760979748574:# carico le funzioni
1760979748577:source("R/df_functions.R")
1760979749579:source("R/dt_functions.R")
1760979757118:# Task 1
1760979757120:bench1 <- microbenchmark(
1760979757122:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979757124:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979757125:times = 10
1760979757127:)
1760979758805:autoplot(bench1)
1760979760503:# Task 2
1760979760508:bench2 <- microbenchmark(
1760979760510:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1760979760512:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1760979760515:times = 10
1760979760518:)
1760979761917:autoplot(bench2)
1760979764392:# Task 3
1760979764396:bench3 <- microbenchmark(
1760979764398:df_version = subset_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979764400:dt_version = subset_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979764404:times = 10
1760979764407:)
1760979821306:# Task 3
1760979821321:bench3 <- microbenchmark(
1760979821324:df_version = subset_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979821326:dt_version = subset_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979821329:times = 10
1760979821331:)
1760979821915:autoplot(bench3)
1760979833477:library(data.table)
1760979833876:library(microbenchmark)
1760979834328:library(ggplot2)
1760979834755:# carico le funzioni
1760979834759:source("R/df_functions.R")
1760979835535:source("R/dt_functions.R")
1760979838555:# Task 1
1760979838559:bench1 <- microbenchmark(
1760979838562:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979838565:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979838567:times = 10
1760979838570:)
1760979840006:autoplot(bench1)
1760979840363:# Task 2
1760979840364:bench2 <- microbenchmark(
1760979840365:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1760979840366:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1760979840367:times = 10
1760979840368:)
1760979841836:autoplot(bench2)
1760979842252:# Task 3
1760979842253:bench3 <- microbenchmark(
1760979842254:df_version = subset_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979842255:dt_version = subset_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979842256:times = 10
1760979842257:)
1760979844784:# Task 4
1760979844788:bench4 <- microbenchmark(
1760979844790:df_version = annotate_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979844792:dt_version = annotate_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979844795:times = 10
1760979844797:)
1760979966732:library(data.table)
1760979967827:library(microbenchmark)
1760979968314:library(ggplot2)
1760979968876:# carico le funzioni
1760979968889:source("R/df_functions.R")
1760979969356:source("R/dt_functions.R")
1760979970478:# Task 1
1760979970481:bench1 <- microbenchmark(
1760979970482:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979970484:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760979970486:times = 10
1760979970488:)
1760979972060:autoplot(bench1)
1760979974115:# Task 2
1760979974118:bench2 <- microbenchmark(
1760979974120:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1760979974122:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1760979974123:times = 10
1760979974125:)
1760979976495:autoplot(bench2)
1760979978247:# Task 3
1760979978250:bench3 <- microbenchmark(
1760979978252:df_version = subset_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv","GENE_0051","S20"),
1760979978253:dt_version = subset_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv","GENE_0051","S20"),
1760979978255:times = 10
1760979978257:)
1760980019600:?setkey
1760980343156:library(data.table)
1760980343587:library(microbenchmark)
1760980344044:library(ggplot2)
1760980344673:# carico le funzioni
1760980344677:source("R/df_functions.R")
1760980345210:source("R/dt_functions.R")
1760980349056:# Task 3
1760980349062:bench3 <- microbenchmark(
1760980349064:df_version = subset_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv","GENE_0051","S20"),
1760980349065:dt_version = subset_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv","GENE_0051","S20"),
1760980349067:times = 10
1760980349069:)
1760981864682:library(data.table)
1760981864685:# ==========================================================
1760981864686:# 🧩 TASK 1 — Bulk RNA counts summary
1760981864687:# ==========================================================
1760981864693:#' Summarize bulk RNA counts with metadata (data.table version)
1760981864695:#'
1760981864696:#' Merges bulk RNA-seq count data with sample metadata, filters treated samples
1760981864699:#' whose gene names start with "GENE_00", and computes mean/median counts per gene,
1760981864701:#' as well as per-condition mean counts.
1760981864701:#'
1760981864702:#' @param counts_path Path to CSV file with columns: sample_id, gene, count.
1760981864703:#' @param meta_path Path to CSV file with columns: sample_id, condition.
1760981864704:#' @return List with:
1760981864705:#' \itemize{
1760981864706:#'   \item gene_mean_median: Mean and median counts by gene (treated only)
1760981864706:#'   \item gene_condition_means: Mean counts by gene and condition
1760981864707:#' }
1760981864708:#' @export
1760981864709:bulk_counts_summary_dt <- function(counts_path, meta_path) {
1760981864710:counts <- fread(counts_path)
1760981864711:meta <- fread(meta_path)
1760981864712:setkey(counts, sample_id)
1760981864713:setkey(meta, sample_id)
1760981864714:merged <- counts[meta, nomatch = 0]
1760981864715:filtered <- merged[condition == "treated" & grepl("^GENE_00", gene)]
1760981864716:gene_mean_median <- filtered[, .(
1760981864718:mean_count = mean(count),
1760981864720:median_count = median(count)
1760981864721:), by = gene]
1760981864723:gene_condition_means <- merged[, .(
1760981864724:mean_count = mean(count)
1760981864725:), by = .(gene, condition)]
1760981864727:list(
1760981864728:gene_mean_median = gene_mean_median,
1760981864729:gene_condition_means = gene_condition_means
1760981864730:)
1760981864731:}
1760981864732:# ==========================================================
1760981864733:# 🧩 TASK 2 — QC-style derived columns
1760981864734:# ==========================================================
1760981864735:#' Add QC-style derived columns (data.table version)
1760981864736:#'
1760981864736:#' Adds log2-transformed counts and a binary \code{high} flag based on gene-wise medians.
1760981864737:#'
1760981864738:#' @param counts_path Path to CSV file with columns: sample_id, gene, count.
1760981864738:#' @return Data.table with added columns: log2_count, high.
1760981864739:#' @export
1760981864740:bulk_counts_qc_dt <- function(counts_path) {
1760981864740:dt <- fread(counts_path)
1760981864741:dt[, log2_count := log2(count + 1)]
1760981864742:dt[, high := count > median(count), by = gene]
1760981864742:dt[]
1760981864743:}
1760981864744:# ==========================================================
1760981864745:# 🧩 TASK 3 — Subset by gene and sample
1760981864745:# ==========================================================
1760981864746:#' Subset counts data using secondary index
1760981864747:#'
1760981864747:#' Joins metadata and subsets for a specific gene and sample using fast indexing.
1760981864748:#'
1760981864749:#' @param counts data.table of bulk counts
1760981864749:#' @param meta data.table of sample metadata
1760981864750:#' @param gene_name Gene name to subset
1760981864750:#' @param sample_chosen Sample ID to subset
1760981864751:#' @return Subset of counts for the given gene and sample.
1760981864752:#' @export
1760981864752:subset_counts_dt <- function(counts_path, meta_path, gene_name, sample_chosen) {
1760981864753:counts <- fread(counts_path)
1760981864754:meta <- fread(meta_path)
1760981864757:setkey(meta, sample_id)
1760981864758:setindex(counts, gene, sample_id)
1760981864758:counts[gene == gene_name & sample_id == sample_chosen]
1760981864759:}
1760981864761:# ==========================================================
1760981864761:# 🧩 TASK 4 — Annotate counts and summarize
1760981864762:# ==========================================================
1760981864763:#' Annotate counts with metadata and compute summaries
1760981864764:#'
1760981864765:#' Joins counts and metadata, computes per-patient total counts,
1760981864765:#' mean counts per gene and condition, and identifies top 10 genes.
1760981864766:#'
1760981864766:#' @param counts data.table of bulk counts
1760981864767:#' @param meta data.table of sample metadata
1760981864768:#' @return List with joined data, patient totals, and top10 genes.
1760981864768:#' @export
1760981864769:annotate_counts_dt <- function(counts, meta) {
1760981864769:setkey(counts, sample_id)
1760981864770:setkey(meta, sample_id)
1760981864770:joined <- counts[meta, nomatch = 0]
1760981864771:patient_tot <- joined[, .(total_count = sum(count)), by = patient_id]
1760981864772:gene_means <- joined[, .(mean_count = mean(count)), by = .(gene, condition)]
1760981864773:top10 <- gene_means[order(condition, -mean_count)][, head(.SD, 10), by = condition]
1760981864774:list(joined = joined, patient_tot = patient_tot, top10 = top10)
1760981864774:}
1760981864776:# ==========================================================
1760981864776:# 🧩 TASK 5 — Classify lab values
1760981864777:# ==========================================================
1760981864778:#' Classify lab values against reference intervals
1760981864779:#'
1760981864779:#' Joins lab results and reference ranges, classifies as "normal" or "out_of_range",
1760981864780:#' and summarizes abnormalities per patient and per lab.
1760981864782:#'
1760981864783:#' @param labs_dt Data.table with columns: patient_id, lab, value.
1760981864783:#' @param ref_dt Data.table with columns: lab, lower, upper.
1760981864784:#' @return List with merged data, abnormal_by_patient, abnormal_by_lab.
1760981864785:#' @export
1760981864786:classify_labs_dt <- function(labs_dt, ref_dt) {
1760981864788:ref_unique <- unique(ref_dt[, .(lab, lower, upper)])
1760981864789:merged <- merge(labs_dt, ref_unique, by = "lab", all.x = TRUE)
1760981864790:merged[, status := fifelse(value >= lower & value <= upper, "normal", "out_of_range")]
1760981864791:abnormal_by_patient <- merged[, .(total_tests = .N, out_of_range = sum(status == "out_of_range")), by = patient_id]
1760981864792:abnormal_by_lab <- merged[, .(total_tests = .N, out_of_range = sum(status == "out_of_range")), by = lab]
1760981864793:list(merged = merged, abnormal_by_patient = abnormal_by_patient, abnormal_by_lab = abnormal_by_lab)
1760981864794:}
1760981864796:# ==========================================================
1760981864796:# 🧩 TASK 6 — Match vitals to labs
1760981864797:# ==========================================================
1760981864798:#' Nearest-time matching of vitals and labs
1760981864799:#'
1760981864800:#' Matches nearest HR/SBP readings to each lab time and computes correlations.
1760981864800:#'
1760981864801:#' @param labs_dt Lab data.table with time_iso
1760981864802:#' @param vitals_dt Vitals data.table with time_iso
1760981864802:#' @return List with labs_with_vitals and correlations (CRP vs HR/SBP)
1760981864803:#' @export
1760981864804:match_vitals_dt <- function(labs_dt, vitals_dt) {
1760981864805:labs_dt[, time_iso := as.POSIXct(time_iso)]
1760981864806:vitals_dt[, time_iso := as.POSIXct(time_iso)]
1760981864807:setorder(labs_dt, patient_id, time_iso)
1760981864808:setorder(vitals_dt, patient_id, time_iso)
1760981864809:labs_dt[, lab_time := time_iso]
1760981864810:# HR
1760981864812:vitals_hr <- vitals_dt[vital == "HR", .(patient_id, time_iso, value)]
1760981864813:setnames(vitals_hr, "value", "nearest_HR")
1760981864814:vitals_hr[, hr_time := time_iso]
1760981864814:setkey(vitals_hr, patient_id, time_iso)
1760981864817:setkey(labs_dt, patient_id, time_iso)
1760981864818:labs_with_hr <- vitals_hr[labs_dt, roll = "nearest"]
1760981864819:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1760981864821:# SBP
1760981864822:vitals_sbp <- vitals_dt[vital == "SBP", .(patient_id, time_iso, value)]
1760981864823:setnames(vitals_sbp, "value", "nearest_SBP")
1760981864824:vitals_sbp[, sbp_time := time_iso]
1760981864825:setkey(vitals_sbp, patient_id, time_iso)
1760981864827:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1760981864828:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1760981864830:# Correlations
1760981864831:crp <- labs_with_vitals[lab == "CRP"]
1760981864833:cor_hr <- crp[!is.na(nearest_HR), .(correlation_CRP_HR = cor(value, nearest_HR)), by = patient_id]
1760981864834:cor_sbp <- crp[!is.na(nearest_SBP), .(correlation_CRP_SBP = cor(value, nearest_SBP)), by = patient_id]
1760981864836:list(labs_with_vitals = labs_with_vitals, cor_crp_hr = cor_hr, cor_crp_sbp = cor_sbp)
1760981864837:}
1760981864840:# ==========================================================
1760981864841:# 🧩 TASK 7 — Top peaks by score
1760981864841:# ==========================================================
1760981864843:#' Extract peaks on chromosome and return top N by score
1760981864844:#'
1760981864845:#' Filters by genomic region and selects top peaks by score.
1760981864846:#'
1760981864848:#' @param peaks_dt Data.table of peaks (chr, start, end, score)
1760981864849:#' @param chr Chromosome string
1760981864851:#' @param start_min, start_max Range
1760981864853:#' @param top_n Number of top peaks
1760981864854:#' @return Data.table of top peaks
1760981864855:#' @export
1760981864856:top_peaks_dt <- function(peaks_dt, chr = "chr2", start_min = 2e6, start_max = 4e6, top_n = 50) {
1760981864857:subset <- peaks_dt[chr == !!chr & start >= start_min & start <= start_max]
1760981864859:setorder(subset, -score)
1760981864860:head(subset, top_n)
1760981864862:}
1760981864864:# ==========================================================
1760981864865:# 🧩 TASK 8 — Gene stats and filtering
1760981864867:# ==========================================================
1760981864869:#' Per-condition robust summary stats and gene filtering
1760981864875:#'
1760981864880:#' Computes mean, median, quartiles by gene and condition,
1760981864881:#' filters genes with treated_mean ≥ 2 × control_mean.
1760981864883:#'
1760981864885:#' @param counts_dt Counts data.table
1760981864886:#' @param meta_dt Metadata data.table
1760981864888:#' @return List with stats_by_gene_condition and kept_genes
1760981864890:#' @export
1760981864891:gene_stats_filter_dt <- function(counts_dt, meta_dt) {
1760981864893:merged <- counts_dt[meta_dt, on = "sample_id"]
1760981864894:stats <- merged[, .(
1760981864896:mean_count = mean(count),
1760981864898:median_count = median(count),
1760981864900:Q1 = quantile(count, 0.25),
1760981864901:Q3 = quantile(count, 0.75)
1760981864903:), by = .(gene, condition)]
1760981864905:treated <- stats[condition == "treated", .(gene, treated_mean = mean_count)]
1760981864907:control <- stats[condition == "control", .(gene, control_mean = mean_count)]
1760981864909:means <- merge(treated, control, by = "gene")
1760981864911:kept <- means[treated_mean >= 2 * control_mean]
1760981864912:list(stats_by_gene_condition = stats, kept_genes = kept)
1760981864914:}
1760981864916:# ==========================================================
1760981864918:# 🧩 TASK 9 — Wide → Long → Wide
1760981864919:# ==========================================================
1760981864921:#' Convert wide counts to long and back, computing mean per condition
1760981864922:#'
1760981864923:#' @param counts_wide_dt Wide counts table
1760981864924:#' @param meta_dt Metadata table
1760981864925:#' @return Data.table wide by condition with mean counts
1760981864926:#' @export
1760981864928:wide_long_wide_dt <- function(counts_wide_dt, meta_dt) {
1760981864929:idvar <- names(counts_wide_dt)[1]
1760981864930:long <- melt(counts_wide_dt, id.vars = idvar, variable.name = "sample_id", value.name = "count")
1760981864931:merged <- merge(long, meta_dt, by = "sample_id")
1760981864932:mean_dt <- merged[, .(mean_count = mean(count)), by = .(gene = get(idvar), condition)]
1760981864934:dcast(mean_dt, gene ~ condition, value.var = "mean_count")
1760981864935:}
1760981864940:# ==========================================================
1760981864941:# 🧩 TASK 10 — ATAC peaks to genes
1760981864943:# ==========================================================
1760981864947:#' Map ATAC peaks to genes and summarize overlaps
1760981864948:#'
1760981864949:#' Uses genomic overlap to assign peaks to genes and compute overlap statistics.
1760981864950:#'
1760981864951:#' @param peaks_dt Peaks data.table
1760981864953:#' @param genes_dt Gene annotations
1760981864954:#' @return List with overlap tables and top 20 genes by overlap
1760981864955:#' @export
1760981864956:atac_to_gene_dt <- function(peaks_dt, genes_dt) {
1760981864957:setkey(peaks_dt, chr, start, end)
1760981864958:setkey(genes_dt, chr, start, end)
1760981864959:overlaps <- foverlaps(peaks_dt, genes_dt, type = "any", nomatch = 0)
1760981864960:overlaps[, overlap_bp := pmin(end, i.end) - pmax(start, i.start)]
1760981864962:overlaps <- overlaps[overlap_bp > 0]
1760981864963:peaks_per_gene <- overlaps[, .N, by = gene]; setnames(peaks_per_gene, "N", "num_peaks")
1760981864964:overlap_sum <- overlaps[, .(total_overlap_bp = sum(overlap_bp)), by = gene]
1760981864965:top20 <- overlap_sum[order(-total_overlap_bp)][1:20]
1760981864967:list(overlaps = overlaps, peaks_per_gene = peaks_per_gene, overlap_sum_per_gene = overlap_sum, top20_genes = top20)
1760981864969:}
1760981864972:# ==========================================================
1760981864973:# 🧩 TASK 11 — Variants to genes
1760981864974:# ==========================================================
1760981864976:#' Map genetic variants to genes and count HIGH-impact variants
1760981864978:#'
1760981864979:#' @param variants_dt Variant data.table
1760981864980:#' @param genes_dt Gene annotations
1760981864981:#' @return List with counts and high-impact genes
1760981864982:#' @export
1760981864983:variants_to_genes_dt <- function(variants_dt, genes_dt) {
1760981864984:variants_dt[, `:=`(start = pos, end = pos)]
1760981864985:setkey(variants_dt, chr, start, end)
1760981864986:setkey(genes_dt, chr, start, end)
1760981864987:overlaps <- foverlaps(variants_dt, genes_dt, type = "any", nomatch = 0)
1760981864988:overlaps[, impact_upper := toupper(impact)]
1760981864989:high <- overlaps[impact_upper == "HIGH"]
1760981864990:high_gene_sample <- high[, .(high_variant_count = .N), by = .(gene, sample_id)]
1760981864991:high_gene <- high[, .(total_high_variants = .N), by = gene][order(-total_high_variants)]
1760981864992:genes_with_high <- unique(high_gene$gene)
1760981864993:list(high_counts_by_gene_sample = high_gene_sample, high_counts_by_gene = high_gene, genes_with_high = genes_with_high)
1760981864994:}
1760981864996:# ==========================================================
1760981864997:# 🧩 TASK 12 — Combine cohorts
1760981864998:# ==========================================================
1760981864999:#' Combine cohorts safely and compute per-cohort mean counts
1760981865000:#'
1760981865001:#' @param cohortA_dt Cohort A metadata
1760981865001:#' @param cohortB_dt Cohort B metadata
1760981865002:#' @param counts_dt Counts table
1760981865003:#' @param top_n Number of top variable genes
1760981865004:#' @return List with combined cohort info and top genes
1760981865005:#' @export
1760981865006:combine_cohorts_dt <- function(cohortA_dt, cohortB_dt, counts_dt, top_n = 100) {
1760981865007:cohortA_dt[, cohort := "A"]
1760981865008:cohortB_dt[, cohort := "B"]
1760981865008:combined <- rbindlist(list(cohortA_dt, cohortB_dt), use.names = TRUE, fill = TRUE)
1760981865009:merged <- merge(counts_dt, combined, by = "sample_id", all.x = TRUE)
1760981865010:var_dt <- merged[, .(variance = var(count)), by = gene]
1760981865010:top_genes <- var_dt[order(-variance)][1:top_n, gene]
1760981865011:top_data <- merged[gene %in% top_genes]
1760981865012:mean_counts <- top_data[, .(mean_count = mean(count)), by = .(gene, cohort, condition)]
1760981865012:list(combined_cohorts = combined, mean_counts = mean_counts, top_genes = top_genes)
1760981865013:}
1760981865014:# ==========================================================
1760981865015:# 🧩 FINAL REVISION TASKS (1.1 → 5.1)
1760981865015:# ==========================================================
1760981865016:#' Combine integration and clustering data
1760981865017:#'
1760981865017:#' Reads and merges integration and clustering tables by cell ID, ensuring consistent ID formatting.
1760981865018:#'
1760981865018:#' @export
1760981865019:combine_integration_clustering_dt <- function(integration_file, clustering_file) {
1760981865019:int <- fread(integration_file)
1760981865020:clu <- fread(clustering_file)
1760981865020:normalize <- function(x) gsub("_X_|_Y_", "_", trimws(as.character(x)))
1760981865021:int[, cell_clean := normalize(cell)]
1760981865022:clu[, cell_clean := normalize(cell)]
1760981865022:merge(int, clu, by = "cell_clean", all = FALSE)
1760981865023:}
1760981865024:#' Count cells per cluster and cell type
1760981865025:#' @export
1760981865025:count_cells_per_cluster_dt <- function(combined_dt) {
1760981865026:counts <- combined_dt[, .N, by = .(integration_cluster, cell_type)]
1760981865027:setnames(counts, "N", "cell_count")
1760981865027:counts
1760981865028:}
1760981865029:#' Count cells per cluster, cell type, and sample type
1760981865030:#' @export
1760981865030:add_sample_type_dt <- function(combined_dt) {
1760981865031:counts <- combined_dt[, .N, by = .(integration_cluster, cell_type, sample_type)]
1760981865032:setnames(counts, "N", "cell_count")
1760981865032:counts
1760981865033:}
1760981865034:#' Compute total cell counts per cluster and sample type
1760981865034:#' @export
1760981865035:compute_totals_dt <- function(counts_dt) {
1760981865035:counts_dt[, .(total_cells = sum(cell_count)), by = .(integration_cluster, sample_type)]
1760981865036:}
1760981865037:#' Compute normalized percentages per cluster and tissue
1760981865037:#' @export
1760981865038:compute_percentages_dt <- function(counts_dt) {
1760981865038:totals <- counts_dt[, .(total_cells = sum(cell_count)), by = .(integration_cluster, sample_type)]
1760981865039:merged <- merge(counts_dt, totals, by = c("integration_cluster", "sample_type"))
1760981865039:merged[, percent := round((cell_count / total_cells) * 100, 2)]
1760981865040:merged[order(integration_cluster)]
1760981865040:}
1760981871980:View(add_sample_type_dt)
1760981953780:# COMPARATIVE ANALYSIS: data.frame vs data.table
1760981953788:library(data.table)
1760981953792:library(microbenchmark)
1760981953795:library(ggplot2)
1760981953801:# carico le funzioni
1760981953803:source("R/df_functions.R")
1760981953808:source("R/dt_functions.R")
1760981953822:# Task 1
1760981953823:bench1 <- microbenchmark(
1760981953824:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760981953825:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760981953826:times = 10
1760981953827:)
1760981955069:autoplot(bench1)
1760981955329:# Task 2
1760981955329:bench2 <- microbenchmark(
1760981955330:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1760981955330:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1760981955331:times = 10
1760981955332:)
1760981956526:autoplot(bench2)
1760981956775:# Task 3
1760981956775:bench3 <- microbenchmark(
1760981956776:df_version = subset_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv","GENE_0051","S20"),
1760981956776:dt_version = subset_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv","GENE_0051","S20"),
1760981956777:times = 10
1760981956778:)
1760990173196:# COMPARATIVE ANALYSIS: data.frame vs data.table
1760990173209:library(data.table)
1760990173212:library(microbenchmark)
1760990173215:library(ggplot2)
1760990173218:# carico le funzioni
1760990173220:source("R/df_functions.R")
1760990173229:source("R/dt_functions.R")
1760990173239:# Task 1
1760990173240:bench1 <- microbenchmark(
1760990173242:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760990173243:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760990173244:times = 10
1760990173244:)
1760990174557:autoplot(bench1)
1760990174784:# Task 2
1760990174784:bench2 <- microbenchmark(
1760990174785:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1760990174786:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1760990174787:times = 10
1760990174788:)
1760990175989:autoplot(bench2)
1760990176364:# Task 3
1760990176364:bench3 <- microbenchmark(
1760990176365:df_version = subset_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv","GENE_0051","S20"),
1760990176366:dt_version = subset_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv","GENE_0051","S20"),
1760990176367:times = 10
1760990176368:)
1760990187164:# Task 4
1760990187167:bench4 <- microbenchmark(
1760990187174:df_version = annotate_counts_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760990187182:dt_version = annotate_counts_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760990187192:times = 10
1760990187198:)
1760990188583:autoplot(bench4)
1760990192100:# Task 5
1760990192105:bench5 <- microbenchmark(
1760990192106:df_version = classify_labs_df("project_oct25/clinical_labs.csv", "project_oct25/lab_reference_ranges.csv"),
1760990192107:dt_version = classify_labs_dt("project_oct25/clinical_labs.csv", "project_oct25/lab_reference_ranges.csv"),
1760990192109:times = 10
1760990192111:)
1760990193235:autoplot(bench5)
1760990193885:# Task 6
1760990193889:bench6 <- microbenchmark(
1760990193890:df_version = match_vitals_df("project_oct25/clinical_labs.csv", "project_oct25/vitals_time_series.csv"),
1760990193892:dt_version = match_vitals_dt("project_oct25/clinical_labs.csv", "project_oct25/vitals_time_series.csv"),
1760990193893:times = 10
1760990193895:)
1760990194715:autoplot(bench6)
1760990196022:# Task 7
1760990196026:bench7 <- microbenchmark(
1760990196028:df_version = top_peaks_df("project_oct25/atac_peaks.bed.csv"),
1760990196030:dt_version = top_peaks_dt("project_oct25/atac_peaks.bed.csv"),
1760990196031:times = 10
1760990196033:)
1760990197273:autoplot(bench7)
1760990197888:# Task 8
1760990197892:bench8 <- microbenchmark(
1760990197894:df_version = gene_stats_filter_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760990197895:dt_version = gene_stats_filter_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1760990197896:times = 10
1760990197897:)
1760990205897:autoplot(bench8)
1760990206604:# Task 9
1760990206607:bench9 <- microbenchmark(
1760990206610:df_version = wide_long_wide_df("project_oct25/bulk_counts_wide.csv"),
1760990206612:dt_version = wide_long_wide_dt("project_oct25/bulk_counts_wide.csv"),
1760990206616:times = 10
1760990206619:)
1760990207163:autoplot(bench9)
1760990207792:# Task 10
1760990207796:bench10 <- microbenchmark(
1760990207799:df_version = atac_to_gene_df("project_oct25/atac_peaks.bed.csv", "project_oct25/gene_annotation.bed.csv"),
1760990207805:dt_version = atac_to_gene_dt("project_oct25/atac_peaks.bed.csv", "project_oct25/gene_annotation.bed.csv"),
1760990207810:times = 10
1760990207811:)
1760990208557:autoplot(bench10)
1760990212548:# Task 11
1760990212551:bench11 <- microbenchmark(
1760990212555:df_version = variants_to_genes_df("project_oct25/variants.csv", "project_oct25/gene_annotation.bed.csv"),
1760990212556:dt_version = variants_to_genes_dt("project_oct25/variants.csv", "project_oct25/gene_annotation.bed.csv"),
1760990212558:times = 10
1760990212559:)
1760990213604:autoplot(bench11)
1760990214400:# Task 12
1760990214406:bench12 <- microbenchmark(
1760990214407:df_version = combine_cohorts_df("project_oct25/cohortA_samples.csv", "project_oct25/cohortB_samples.csv","project_oct25/bulk_counts_long.csv"),
1760990214409:dt_version = combine_cohorts_dt("project_oct25/cohortA_samples.csv", "project_oct25/cohortB_samples.csv","project_oct25/bulk_counts_long.csv"),
1760990214410:times = 10
1760990214411:)
1760990215462:autoplot(bench12)
1760990216073:# salvo i risultati numerici
1760990216076:write.csv(bench1, "Comparison_results/benchmark_task1.csv", row.names = FALSE)
1761067536254:?function
1761067542610:?function
1761067632115:?function
1761067654558:?list
1761067658914:?list
1761068065657:library(data.table)
1761068066106:library(microbenchmark)
1761068066593:library(ggplot2)
1761068067814:# carico le funzioni
1761068067818:source("R/df_functions.R")
1761068068778:source("R/dt_functions.R")
1761068070017:# Task 1
1761068070020:bench1 <- microbenchmark(
1761068070023:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761068070024:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761068070026:times = 10
1761068070028:)
1761068110170:# carico le funzioni
1761068110173:source("R/df_functions.R")
1761068111367:source("R/dt_functions.R")
1761068112266:# Task 1
1761068112270:bench1 <- microbenchmark(
1761068112272:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761068112274:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761068112276:times = 10
1761068112279:)
1761068118199:autoplot(bench1)
1761068186478:# 1. Import
1761068186483:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1761068187167:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1761068189099:View(bulk_counts)
1761068189932:View(sample_meta)
1761068208654:View(sample_meta)
1761068654348:library(data.table)
1761068660053:a <- bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761068662417:View(a)
1761068726530:library(data.table)
1761068726962:library(microbenchmark)
1761068727347:library(ggplot2)
1761068727980:# carico le funzioni
1761068727984:source("R/df_functions.R")
1761068728539:source("R/dt_functions.R")
1761068734255:bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761068754493:a,b,c <- bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761068762347:a <- bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761068768249:# 1. Import
1761068768252:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1761068768777:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1761068769538:# 2. Join counts + metadata by sample_id
1761068769540:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1761068769544:#effettua una modifica in place (non crea una copia)
1761068769545:#questo permette join molto più rapidi
1761068769548:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1761068769940:setkey(sample_meta, sample_id)
1761068770271:join_data <- bulk_counts[sample_meta, nomatch = 0]
1761068777942:# 3. Filter for treated samples and GENE_00* genes
1761068777947:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1761068780017:# 4. Compute mean and median per gene
1761068780022:gene_mean_median <- filtered_data[, .(
1761068780024:mean_count   = mean(count),
1761068780027:median_count = median(count)
1761068780029:), by = gene]
1761068783582:# Calcola la media dei conteggi per ogni combinazione (gene, condition)
1761068783585:# tutto in una singola pipeline: unisco metadata e counts e poi raggruppo
1761068783587:gene_condition_means <- bulk_counts[
1761068783589:sample_meta,                # uso sample_meta come "i" (lookup)
1761068783590:on = "sample_id"            # join su sample_id (non serve setkey se usi on=)
1761068783592:][ , .(
1761068783593:mean_count = mean(count)   # media dei conteggi (ignora NA se ci sono)
1761068783596:), by = .(gene, condition) ]               # raggruppa per gene e per condition
1761068794537:View(gene_condition_means)
1761068795939:View(a)
1761069278228:library(data.table)
1761069278642:library(microbenchmark)
1761069299072:library(data.table)
1761069299515:library(microbenchmark)
1761069300899:library(ggplot2)
1761069301876:# carico le funzioni
1761069301884:source("R/df_functions.R")
1761069302634:source("R/dt_functions.R")
1761069319326:result <- bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761069321784:View(result)
1761069328732:result$filtered
1761069330550:result$gene_m_m
1761069332085:result$gene_c_m
1761069419680:filtered <- result$filtered
1761069420274:gene_m_m <- result$gene_m_m
1761069420818:gene_c_m <- result$gene_c_m
1761069422093:View(filtered)
1761069424390:View(gene_c_m)
1761069425873:View(gene_m_m)
1761069431804:# 1. Import
1761069431808:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1761069432190:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1761069432445:# 2. Join counts + metadata by sample_id
1761069432448:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1761069432449:#effettua una modifica in place (non crea una copia)
1761069432451:#questo permette join molto più rapidi
1761069432452:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1761069432697:setkey(sample_meta, sample_id)
1761069432918:join_data <- bulk_counts[sample_meta, nomatch = 0]
1761069433204:# 3. Filter for treated samples and GENE_00* genes
1761069433208:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1761069433467:# 4. Compute mean and median per gene
1761069433471:gene_mean_median <- filtered_data[, .(
1761069433472:mean_count   = mean(count),
1761069433474:median_count = median(count)
1761069433475:), by = gene]
1761069433717:# Calcola la media dei conteggi per ogni combinazione (gene, condition)
1761069433721:# tutto in una singola pipeline: unisco metadata e counts e poi raggruppo
1761069433723:gene_condition_means <- bulk_counts[
1761069433726:sample_meta,                # uso sample_meta come "i" (lookup)
1761069433730:on = "sample_id"            # join su sample_id (non serve setkey se usi on=)
1761069433731:][ , .(
1761069433733:mean_count = mean(count)   # media dei conteggi (ignora NA se ci sono)
1761069433734:), by = .(gene, condition) ]               # raggruppa per gene e per condition
1761069450785:View(gene_mean_median)
1761069453809:View(gene_condition_means)
1761069455342:View(filtered_data)
1761070341198:("R/df_functions.R")
1761070345580:library(data.table)
1761070353634:library(data.table)
1761070354077:library(microbenchmark)
1761070354508:library(ggplot2)
1761070357557:source("R/dt_functions.R")
1761070364800:#CON FUNCTION:
1761070364802:result <- bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761070368733:View(result)
1761070369778:View(result)
1761070372587:filtered <- result$filtered_data
1761070373173:gene_m_m <- result$gene_mean_median
1761070373688:gene_c_m <- result$gene_condition_means
1761070564287:library(data.table)
1761070564733:library(microbenchmark)
1761070565244:library(ggplot2)
1761070567635:source("R/dt_functions.R")
1761070582026:#CON FUNCTION:
1761070582031:result <- bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761070584290:View(result)
1761070678508:#CON FUNCTION:
1761070678512:result <- bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761070680065:View(result)
1761070925586:# Task 1
1761070925591:bench1 <- microbenchmark(
1761070925594:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761070925595:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761070925597:times = 10
1761070925599:)
1761070941472:# carico le funzioni
1761070941477:source("R/df_functions.R")
1761070941941:source("R/dt_functions.R")
1761070942706:# Task 1
1761070942713:bench1 <- microbenchmark(
1761070942717:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761070942720:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761070942732:times = 10
1761070942743:)
1761070945287:autoplot(bench1)
1761076831938:# 1 Carico la libreria
1761076831941:library(data.table)
1761076832742:# 2 Leggo il file come data.table
1761076832746:counts <- fread("project_oct25/bulk_counts_long.csv")
1761076833847:# PARTE 1: Aggiungo la colonna log2 dei conteggi
1761076833850:# -----------------------------------------------------
1761076833852:# := modifica la tabella "in place" (senza crearne una copia)
1761076833856:counts[, log2_count := log2(count)]  #modifica o calcola qualcosa in questa tabella
1761076834867:#Aggiungo la colonna binaria 'high' (count > 100)
1761076834870:counts[, high := count > 100]
1761076835644:# -----------------------------------------------------
1761076835646:# PARTE 3: Sovrascrivo 'high' in modo gene-wise, con questo criterio := (in place)
1761076835649:#per ogni gene verifica se il valore di count è maggiore della mediana di count per quel gene
1761076835651:# (count > median(count) per ciascun gene)
1761076835652:# -----------------------------------------------------
1761076835653:counts[, high := count > median(count), by = gene]  #x ogni gene separatamente
1761076838169:View(counts)
1761076843844:# 1 Carico la libreria
1761076843847:library(data.table)
1761076846318:View(counts)
1761076853426:# 2 Leggo il file come data.table
1761076853429:counts <- fread("project_oct25/bulk_counts_long.csv")
1761076855287:View(counts)
1761076893177:# 1 Carico la libreria
1761076893179:library(data.table)
1761076894060:# 2 Leggo il file come data.table
1761076894069:counts <- fread("project_oct25/bulk_counts_long.csv")
1761076894920:# PARTE 1: Aggiungo la colonna log2 dei conteggi
1761076894926:# -----------------------------------------------------
1761076894929:# := modifica la tabella "in place" (senza crearne una copia)
1761076894931:counts[, log2_count := log2(count)]  #modifica o calcola qualcosa in questa tabella
1761076895221:#Aggiungo la colonna binaria 'high' (count > 100)
1761076895244:counts[, high := count > 100]
1761076895335:# -----------------------------------------------------
1761076895337:# PARTE 3: Sovrascrivo 'high' in modo gene-wise, con questo criterio := (in place)
1761076895338:#per ogni gene verifica se il valore di count è maggiore della mediana di count per quel gene
1761076895339:# (count > median(count) per ciascun gene)
1761076895340:# -----------------------------------------------------
1761076895341:counts[, high := count > median(count), by = gene]  #x ogni gene separatamente
1761076897287:View(counts)
1761077280155:# 1 Carico la libreria
1761077280160:library(data.table)
1761077280842:# 2 Leggo i file CSV come data.table
1761077280845:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1761077282131:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1761077283148:# PARTE 1: Imposto la chiave su sample_metadata
1761077283150:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1761077283151:setkey(sample_meta, sample_id)
1761077284022:# PARTE 2: Faccio una join tra metadata e counts
1761077284027:# Dopo aver impostato la chiave, la join è automatica e più veloce
1761077284029:join_data <- sample_meta[bulk_counts, on = "sample_id"] #prende meta e attacca counts in base al sample ID
1761077285159:# PARTE 4: Benchmark — confronto prima e dopo l’indice
1761077285162:# Esempio: voglio estrarre tutte le righe per un certo gene
1761077285163:gene_call <- "GENE_0051"
1761077285978:sample_chosen <- "S20"
1761077288107:# Prima (senza usare l’indice)
1761077288112:system.time({
1761077288113:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1761077288115:})
1761077291924:# PARTE 3: Creo un indice secondario su (gene, sample_id)
1761077291928:# L’indice serve per accelerare query che filtrano per gene e sample
1761077291930:setindex(bulk_counts, gene, sample_id)
1761077292844:# Dopo (l’indice ora è attivo)
1761077292847:system.time({
1761077292849:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1761077292850:})
1761077297158:View(subset_no_index)
1761077415745:result <- subset_counts_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv","GENE_0051","S20")
1761077426851:("R/dt_functions.R")
1761077430950:result <- subset_counts_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv","GENE_0051","S20")
1761077437073:source("R/dt_functions.R")
1761077441037:result <- subset_counts_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv","GENE_0051","S20")
1761077450201:result
1761077478755:?system.time
1761077565746:source("R/dt_functions.R")
1761077590634:result <- subset_counts_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv","GENE_0051","S20")
1761077623396:#CON FUNCTION:
1761077623399:result <- bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761077625649:View(result)
1761077663922:filtered_data <- result$filtered_data
1761077665952:View(filtered_data)
1761077722296:source("R/dt_functions.R")
1761077750284:result <- subset_counts_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv","GENE_0051","S20")
1761077861253:# 1 Carico la libreria
1761077861258:library(data.table)
1761077861714:# 2 Leggo i file CSV come data.table
1761077861718:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1761077862231:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1761077862918:# PARTE 1: Imposto la chiave su sample_metadata
1761077862922:# setkey() serve per ordinare la tabella e prepararla a join più veloci
1761077862924:setkey(sample_meta, sample_id)
1761077863503:# PARTE 2: Faccio una join tra metadata e counts
1761077863506:# Dopo aver impostato la chiave, la join è automatica e più veloce
1761077863508:join_data <- sample_meta[bulk_counts, on = "sample_id"] #prende meta e attacca counts in base al sample ID
1761077864592:# PARTE 4: Benchmark — confronto prima e dopo l’indice
1761077864596:# Esempio: voglio estrarre tutte le righe per un certo gene
1761077864598:gene_call <- "GENE_0051"
1761077865236:sample_chosen <- "S20"
1761077866165:# Prima (senza usare l’indice)
1761077866167:a <- system.time({
1761077866168:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1761077866171:})
1761077870425:a
1761077919951:source("R/dt_functions.R")
1761077932745:result <- subset_counts_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv","GENE_0051","S20")
1761077935324:View(result)
1761078020283:# 2 Leggo i file CSV come data.table
1761078020304:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1761078021439:View(bulk_counts)
1761078280256:result <- subset_counts_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv","GENE_0051","S20")
1761078291649:source("R/dt_functions.R")
1761078296608:result <- subset_counts_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv","GENE_0051","S20")
1761078298906:View(result)
1761078745004:source("R/dt_functions.R")
1761078757764:result <- annotate_counts_dt <- function("project_oct25/bulk_counts_long.csv" , "project_oct25/sample_metadata.csv")
1761079011088:result <- annotate_counts_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761079013691:View(result)
1761079028814:library(data.table)
1761079029248:# 1. Import
1761079029250:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1761079029757:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1761079030518:# 2. Join counts + metadata
1761079030524:setkey(bulk_counts, sample_id)
1761079030845:setkey(sample_meta, sample_id)
1761079031055:join_data <- bulk_counts[sample_meta, nomatch = 0]
1761079032029:# 3. Total counts per patient
1761079032033:patient_tot <- join_data[, .(total_count = sum(count)), by = patient_id]
1761079032399:# 4. Mean count per gene and condition
1761079032403:gene_means <- join_data[, .(mean_count = mean(count)), by = .(gene, condition)]
1761079033901:# 5. Top 10 genes (highest mean) within each condition
1761079033904:top10 <- gene_means[
1761079033907:order(condition, -mean_count)
1761079033909:][, head(.SD, 10), by = condition]
1761079041903:View(result)
1761079119565:# 1 Carico i file
1761079119569:labs <- fread("project_oct25/clinical_labs.csv")
1761079119869:ref  <- fread("project_oct25/lab_reference_ranges.csv")
1761079121169:View(labs)
1761079121843:View(ref)
1761079987913:# Carico la libreria
1761079987917:library(data.table)
1761079993421:# Carico la libreria
1761079993424:library(data.table)
1761079999418:# Carico la libreria
1761079999421:library(data.table)
1761080014238:# Carico la libreria
1761080014245:library(data.table)
1761080016232:# Leggo il file dei picchi ATAC
1761080016236:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1761080017666:View(peaks)
1761080414288:source("R/dt_functions.R")
1761080417309:result <- top_peaks_dt("project_oct25/atac_peaks.bed.csv","chr2",2000000,4000000)
1761080421475:# Leggo il file dei picchi ATAC
1761080421479:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1761080421927:# Filtro i picchi su chr2 e nella finestra 2–4 Mb
1761080421932:# Nota: 1 Mb = 1.000.000 basi
1761080421934:subset_peaks <- peaks[chr == "chr2" & start >= 2000000 & start <= 4000000]
1761080422608:#Ordino i picchi per punteggio decrescente
1761080422611:subset_peaks <- setorder(subset_peaks, -score)
1761080423517:#Prendo i primi 50 picchi
1761080423523:top50_peaks <- head(subset_peaks, 50)
1761080427093:View(peaks)
1761080432275:View(top50_peaks)
1761080433579:View(result)
1761080528335:source("R/dt_functions.R")
1761080535359:result <- top_peaks_dt("project_oct25/atac_peaks.bed.csv","chr2", 2000000,4000000)
1761080554333:source("R/dt_functions.R")
1761080558705:result <- top_peaks_dt("project_oct25/atac_peaks.bed.csv","chr2", 2000000,4000000)
1761080563640:View(result)
1761080566191:View(top50_peaks)
1761081043839:# Leggiamo i dati (matrice larga: una riga per gene, una colonna per campione)
1761081043843:counts_wide <- fread("project_oct25/bulk_counts_wide.csv")
1761081045499:View(counts_wide)
1761081082161:# Leggiamo i file
1761081082165:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1761081083156:genes <- fread("project_oct25/gene_annotation.bed.csv")
1761081086447:View(genes)
1761081087347:View(peaks)
1761081635804:# leggo i file
1761081635809:variants <- fread("project_oct25/variants.csv")
1761081636117:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1761081639705:View(genes)
1761081640447:View(variants)
1761082071174:# Leggiamo i file, specificando i percorsi
1761082071180:cohortA <- fread("project_oct25/cohortA_samples.csv")
1761082071506:cohortB <- fread("project_oct25/cohortB_samples.csv")
1761082071824:counts  <- fread("project_oct25/bulk_counts_long.csv")
1761082073613:View(counts)
1761082074274:View(cohortB)
1761082074880:View(cohortA)
1761082210363:# Aggiungiamo una colonna 'cohort' per tenere traccia della provenienza
1761082210366:cohortA[, cohort := "A"]
1761082210901:cohortB[, cohort := "B"]
1761082216235:# Carichiamo la libreria
1761082216238:library(data.table)
1761082226528:# Carichiamo la libreria
1761082226536:library(data.table)
1761082227075:# Leggiamo i file, specificando i percorsi
1761082227084:cohortA <- fread("project_oct25/cohortA_samples.csv")
1761082227782:cohortB <- fread("project_oct25/cohortB_samples.csv")
1761082228275:counts  <- fread("project_oct25/bulk_counts_long.csv")
1761082228736:# Aggiungiamo una colonna 'cohort' per tenere traccia della provenienza
1761082228738:cohortA[, cohort := "A"]
1761082229265:cohortB[, cohort := "B"]
1761082229882:# Uniamo le due coorti
1761082229886:# use.names = TRUE --> allinea le colonne con lo stesso nome
1761082229888:# fill = TRUE      --> se mancano colonne in uno dei due file, le crea e le riempie con NA
1761082229890:combined_cohorts <- rbindlist(list(cohortA, cohortB), use.names = TRUE, fill = TRUE)
1761082230436:# Ordiniamo per coorte, condizione e sample_id
1761082230438:setorder(combined_cohorts, cohort, condition, sample_id)
1761082231182:# Uniamo per sample_id
1761082231188:merged_per_sampleid <- merge(counts, combined_cohorts, by = "sample_id", all.x = TRUE)
1761082231694:# PARTE 3: Troviamo i 100 geni più variabili
1761082231697:# Calcoliamo la varianza dei conteggi per ciascun gene
1761082231699:gene_variance <- merged_per_sampleid[, .(variance = var(count, na.rm = TRUE)), by = gene]
1761082232346:# Ordiniamo per varianza decrescente e prendiamo i primi 100
1761082232350:top100_genes <- gene_variance[order(-variance)][1:100, gene]
1761082232976:print(head(top100_genes, 5))
1761082233985:# Calcoliamo la media dei conteggi per coorte e condizione
1761082233987:#           solo per i top 100 geni
1761082233989:top100_data <- merged_per_sampleid[gene %in% top100_genes]
1761082234654:mean_counts <- top100_data[, .(
1761082234667:mean_count = mean(count, na.rm = TRUE)
1761082234675:), by = .(gene, cohort, condition)]
1761082241319:View(top100_data)
1761082378171:View(top100_data)
1761082435475:View(mean_counts)
1761082577040:# Ordiniamo per varianza decrescente e prendiamo i primi 100
1761082577045:top100_genes <- gene_variance[order(-variance)][1:100, gene]
1761082578532:print(head(top100_genes, 5))
1761082587775:# Calcoliamo la media dei conteggi per coorte e condizione
1761082587777:#           solo per i top 100 geni
1761082587780:top100_data <- merged_per_sampleid[gene %in% top100_genes]
1761082589132:View(top100_data)
1761083624624:library(data.table)
1761083624891:# 1. Import
1761083624893:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1761083625047:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1761083625291:# 2. Join counts + metadata by sample_id
1761083625292:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1761083625295:#effettua una modifica in place (non crea una copia)
1761083625296:#questo permette join molto più rapidi
1761083625297:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1761083625411:setkey(sample_meta, sample_id)
1761083625512:join_data <- bulk_counts[sample_meta, nomatch = 0]
1761083625679:# 3. Filter for treated samples and GENE_00* genes
1761083625681:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1761083625856:# 4. Compute mean and median per gene
1761083625859:gene_mean_median <- filtered_data[, .(
1761083625861:mean_count   = mean(count),
1761083625862:median_count = median(count)
1761083625863:), by = gene]
1761083626073:# Calcola la media dei conteggi per ogni combinazione (gene, condition)
1761083626076:# tutto in una singola pipeline: unisco metadata e counts e poi raggruppo
1761083626079:gene_condition_means <- bulk_counts[
1761083626081:sample_meta,                # uso sample_meta come "i" (lookup)
1761083626082:on = "sample_id"            # join su sample_id (non serve setkey se usi on=)
1761083626088:][ , .(
1761083626091:mean_count = mean(count)   # media dei conteggi (ignora NA se ci sono)
1761083626092:), by = .(gene, condition) ]               # raggruppa per gene e per condition
1761083626259:#CON FUNCTION:
1761083626262:result <- bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761083626446:filtered_data <- result$filtered_data
1761083626664:gene_mean_median <- result$gene_mean_median
1761083626823:gene_condition_means <- result$gene_condition_means
1761083639850:# 1. Import
1761083639854:counts <- read.csv("project_oct25/bulk_counts_long.csv")
1761083640367:meta   <- read.csv("project_oct25/sample_metadata.csv")
1761083658722:# 2. Join counts + metadata by sample_id
1761083658726:merged_data <- merge(counts, meta, by = "sample_id")
1761083659106:# 3. Filter for treated samples and GENE_00* genes
1761083659110:treated_data <- subset(merged_data,
1761083659112:condition == "treated" & grepl("^GENE_00", gene))
1761083660204:# 4. Compute mean and median per gene
1761083660207:gene_summary <- aggregate(
1761083660209:count ~ gene,
1761083660211:data = treated_data,
1761083660212:FUN  = function(x) c(mean = mean(x), median = median(x))
1761083660214:)
1761083661024:# 5. Simplify format
1761083661029:gene_summary_df <- data.frame(
1761083661031:gene = gene_summary$gene,
1761083661033:mean_count   = gene_summary$count[, "mean"],
1761083661034:median_count = gene_summary$count[, "median"]
1761083661036:)
1761083661736:# 6 Calcolo della media dei conteggi per ciascun gene e condizione
1761083661738:# aggregate() calcola una funzione (mean) per gruppi
1761083661742:gene_condition_means_f <- aggregate(
1761083661744:count ~ gene + condition,   # formula: raggruppa per gene e condition
1761083661746:data = merged_data,         # tabella di partenza
1761083661747:FUN = mean,                 # funzione da applicare
1761083661748:na.rm = TRUE                # ignora eventuali valori mancanti
1761083661750:)
1761083662431:# 7 Ordina i risultati per gene e condition (per leggibilità)
1761083662434:gene_condition_means_f <- gene_condition_means_f[order(gene_condition_means_f$gene,
1761083662436:gene_condition_means_f$condition), ]
1761083707480:View(filtered_data)
1761083708672:View(treated_data)
1761083857012:library(data.table)
1761083857332:library(microbenchmark)
1761083857940:library(ggplot2)
1761083859021:# carico le funzioni
1761083859022:source("R/df_functions.R")
1761083859835:source("R/dt_functions.R")
1761083863912:# Task 1
1761083863916:bench1 <- microbenchmark(
1761083863920:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761083863921:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761083863923:times = 10
1761083863926:)
1761083867547:autoplot(bench1)
1761084017608:?setindex
1761084198357:# 1 Carico la libreria
1761084198362:library(data.table)
1761084198633:# 2 Leggo il file come data.table
1761084198638:counts <- fread("project_oct25/bulk_counts_long.csv")
1761084198811:# PARTE 1: Aggiungo la colonna log2 dei conteggi
1761084198815:# -----------------------------------------------------
1761084198817:# := modifica la tabella "in place" (senza crearne una copia)
1761084198818:counts[, log2_count := log2(count)]  #modifica o calcola qualcosa in questa tabella
1761084198993:#Aggiungo la colonna binaria 'high' (count > 100)
1761084198996:counts[, high := count > 100]
1761084199174:# -----------------------------------------------------
1761084199178:# PARTE 3: Sovrascrivo 'high' in modo gene-wise, con questo criterio := (in place)
1761084199180:#per ogni gene verifica se il valore di count è maggiore della mediana di count per quel gene
1761084199182:# (count > median(count) per ciascun gene)
1761084199184:# -----------------------------------------------------
1761084199185:counts[, high := count > median(count), by = gene]  #x ogni gene separatamente
1761084208355:View(counts)
1761084254079:# 1. Import
1761084254084:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1761084254399:# 2. Add log2(count + 1) column
1761084254403:counts$log2_count <- log2(counts$count + 1)
1761084254649:# 3. Add binary flag 'high' (count > 100)
1761084254654:counts$high <- counts$count > 100
1761084254904:# 4. Overwrite 'high' using gene-wise median threshold
1761084254906:#    Qui usiamo tapply() per calcolare la mediana per gene,
1761084254909:#    poi combiniamo i risultati in un vettore logico della stessa lunghezza
1761084254909:medians_by_gene <- tapply(counts$count, counts$gene, median)
1761084255224:counts$high <- counts$count > medians_by_gene[counts$gene]
1761084259069:View(counts)
1761084278946:# 1. Import
1761084278948:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1761084279153:# 2. Add log2(count + 1) column
1761084279156:counts$log2_count <- log2(counts$count + 1)
1761084279366:# 3. Add binary flag 'high' (count > 100)
1761084279370:counts$high <- counts$count > 100
1761084279591:# 4. Overwrite 'high' using gene-wise median threshold
1761084279595:#    Qui usiamo tapply() per calcolare la mediana per gene,
1761084279597:#    poi combiniamo i risultati in un vettore logico della stessa lunghezza
1761084279599:medians_by_gene <- tapply(counts$count, counts$gene, median)
1761084279807:counts$high <- counts$count > medians_by_gene[counts$gene]
1761084281042:View(counts)
1761084302047:library(data.table)
1761084302311:library(microbenchmark)
1761084302657:library(ggplot2)
1761084302811:# carico le funzioni
1761084302815:source("R/df_functions.R")
1761084303172:source("R/dt_functions.R")
1761084304058:# Task 1
1761084304061:bench1 <- microbenchmark(
1761084304063:df_version = bulk_counts_summary_df("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761084304065:dt_version = bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv", "project_oct25/sample_metadata.csv"),
1761084304067:times = 10
1761084304069:)
1761084305556:autoplot(bench1)
1761084307366:# Task 2
1761084307368:bench2 <- microbenchmark(
1761084307370:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1761084307370:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1761084307371:times = 10
1761084307372:)
1761084370667:# carico le funzioni
1761084370671:source("R/df_functions.R")
1761084374817:# Task 2
1761084374821:bench2 <- microbenchmark(
1761084374824:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1761084374827:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1761084374829:times = 10
1761084374832:)
1761084476283:# carico le funzioni
1761084476288:source("R/df_functions.R")
1761084478848:2
1761084482401:2
1761084485547:# Task 2
1761084485565:bench2 <- microbenchmark(
1761084485575:df_version = bulk_counts_qc_df("project_oct25/bulk_counts_long.csv"),
1761084485582:dt_version = bulk_counts_qc_dt("project_oct25/bulk_counts_long.csv"),
1761084485598:times = 10
1761084485603:)
1761084487686:autoplot(bench2)
1761125021606:# Carichiamo la libreria
1761125021608:library(data.table)
1761125022187:# Leggiamo i file, specificando i percorsi
1761125022188:cohortA <- fread("project_oct25/cohortA_samples.csv")
1761125022714:cohortB <- fread("project_oct25/cohortB_samples.csv")
1761125023135:counts  <- fread("project_oct25/bulk_counts_long.csv")
1761125023678:# Aggiungiamo una colonna 'cohort' per tenere traccia della provenienza
1761125023680:cohortA[, cohort := "A"]
1761125024352:cohortB[, cohort := "B"]
1761125025167:# Uniamo le due coorti
1761125025175:# use.names = TRUE --> allinea le colonne con lo stesso nome
1761125025177:# fill = TRUE      --> se mancano colonne in uno dei due file, le crea e le riempie con NA
1761125025181:combined_cohorts <- rbindlist(list(cohortA, cohortB), use.names = TRUE, fill = TRUE)
1761125026114:# Ordiniamo per coorte, condizione e sample_id
1761125026117:setorder(combined_cohorts, cohort, condition, sample_id)
1761125026912:# Uniamo per sample_id
1761125026914:merged_per_sampleid <- merge(counts, combined_cohorts, by = "sample_id", all.x = TRUE)
1761125027994:# PARTE 3: Troviamo i 100 geni più variabili
1761125028002:# Calcoliamo la varianza dei conteggi per ciascun gene
1761125028004:gene_variance <- merged_per_sampleid[, .(variance = var(count, na.rm = TRUE)), by = gene]
1761125028736:n_top <- min(100, nrow(gene_variance))
1761125041155:# Ordiniamo per varianza decrescente e prendiamo i primi 100
1761125041164:top100_genes <- gene_variance[order(-variance)][1:100, gene]
1761125045492:print(head(top100_genes, 5))
1761125048624:# Calcoliamo la media dei conteggi per coorte e condizione
1761125048625:#           solo per i top 100 geni
1761125048630:top100_data <- merged_per_sampleid[gene %in% top100_genes]
1761125050337:View(top100_data)
1761125192687:View(top100_data)
1761125394184:# ==========================================================
1761125394186:# TASK 1 – data.frame version
1761125394188:# Stesso obiettivo ma usando solo funzioni base R
1761125394189:# ==========================================================
1761125394192:# 1. Import
1761125394193:counts <- read.csv("project_oct25/bulk_counts_long.csv")
1761125394209:meta   <- read.csv("project_oct25/sample_metadata.csv")
1761125394211:# 2. Join counts + metadata by sample_id
1761125394212:merged_data <- merge(counts, meta, by = "sample_id")
1761125394269:# 3. Filter for treated samples and GENE_00* genes
1761125394269:treated_data <- subset(merged_data,
1761125394271:condition == "treated" & grepl("^GENE_00", gene))
1761125394278:# 4. Compute mean and median per gene
1761125394278:gene_summary <- aggregate(
1761125394279:count ~ gene,
1761125394280:data = treated_data,
1761125394281:FUN  = function(x) c(mean = mean(x), median = median(x))
1761125394281:)
1761125394298:# 5. Simplify format
1761125394299:gene_summary_df <- data.frame(
1761125394300:gene = gene_summary$gene,
1761125394301:mean_count   = gene_summary$count[, "mean"],
1761125394302:median_count = gene_summary$count[, "median"]
1761125394302:)
1761125394306:# 6 Calcolo della media dei conteggi per ciascun gene e condizione
1761125394306:# aggregate() calcola una funzione (mean) per gruppi
1761125394307:gene_condition_means_f <- aggregate(
1761125394307:count ~ gene + condition,   # formula: raggruppa per gene e condition
1761125394308:data = merged_data,         # tabella di partenza
1761125394309:FUN = mean,                 # funzione da applicare
1761125394309:na.rm = TRUE                # ignora eventuali valori mancanti
1761125394310:)
1761125394380:# 7 Ordina i risultati per gene e condition (per leggibilità)
1761125394381:gene_condition_means_f <- gene_condition_means_f[order(gene_condition_means_f$gene,
1761125394382:gene_condition_means_f$condition), ]
1761125428878:#Goal: Filter, summarize, and group bulk counts. Data: bulk_counts_long.csv, sample_metadata.csv Tasks:
1761125428880:#• Keep counts for samples in condition == "treated" and genes starting with "GENE_00".
1761125428884:#• Compute mean and median count by gene (valore centrale).
1761125428886:#• Join sample metadata and compute per-condition mean counts by gene in one pipeline.
1761125428889:library(data.table)
1761125428895:# 1. Import
1761125428896:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1761125428909:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1761125428914:# 2. Join counts + metadata by sample_id
1761125428916:#imposta sample_id come chiave sull'oggetto counts e meta quindi counts viene ordinato per sample_id
1761125428918:#effettua una modifica in place (non crea una copia)
1761125428920:#questo permette join molto più rapidi
1761125428922:setkey(bulk_counts, sample_id) #setkey ordina la tabella e rende più veloce l'unione di tabelle
1761125428930:setkey(sample_meta, sample_id)
1761125428933:join_data <- bulk_counts[sample_meta, nomatch = 0]
1761125428950:#In data.table la forma X[i] può essere usata per i join:
1761125428951:#X = tabella da cui prendi i dati (qui counts)
1761125428952:#i = tabella che serve come query/indice (qui meta)
1761125428954:#Quando ci sono chiavi compatibili (sample_id), counts[meta] interpreta meta come la tabella di lookup
1761125428956:#e per ciascuna riga di meta estrae le righe corrispondenti da counts
1761125428957:#nomatch = 0 significa: escludi le righe di meta che non trovano corrispondenza in counts.
1761125428958:#Questo equivale a un inner join (solo righe with match).
1761125428961:# 3. Filter for treated samples and GENE_00* genes
1761125428962:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1761125428970:#filtrare stringhe in base a un pattern (cioè una “regola” di testo).
1761125428971:#Quindi grepl("^GENE_00", gene) restituisce:
1761125428974:#TRUE per tutti i geni che iniziano con GENE_00
1761125428975:#FALSE per tutti gli altri.
1761125428977:# 4. Compute mean and median per gene
1761125428979:gene_mean_median <- filtered_data[, .(
1761125428980:mean_count   = mean(count),
1761125428981:median_count = median(count)
1761125428983:), by = gene]
1761125429001:# Punto 5 corretto: join + per-condition mean by gene (una pipeline)
1761125429003:# Calcola la media dei conteggi per ogni combinazione (gene, condition)
1761125429004:# tutto in una singola pipeline: unisco metadata e counts e poi raggruppo
1761125429005:gene_condition_means <- bulk_counts[
1761125429006:sample_meta,                # uso sample_meta come "i" (lookup)
1761125429008:on = "sample_id"            # join su sample_id (non serve setkey se usi on=)
1761125429009:][ , .(
1761125429012:mean_count = mean(count)   # media dei conteggi (ignora NA se ci sono)
1761125429014:), by = .(gene, condition) ]               # raggruppa per gene e per condition
1761125429080:#CON FUNCTION:
1761125429089:result <- bulk_counts_summary_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761125525349:# ==========================================================
1761125525353:# TASK 2 – data.frame version
1761125525355:# ==========================================================
1761125525359:# 1. Import
1761125525360:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1761125525374:# 2. Add log2(count + 1) column
1761125525375:counts$log2_count <- log2(counts$count + 1)
1761125525377:# 3. Add binary flag 'high' (count > 100)
1761125525377:counts$high <- counts$count > 100
1761125525379:# 4. Overwrite 'high' using gene-wise median threshold
1761125525379:#    Qui usiamo tapply() per calcolare la mediana per gene,
1761125525380:#    poi combiniamo i risultati in un vettore logico della stessa lunghezza
1761125525380:medians_by_gene <- tapply(counts$count, counts$gene, median)
1761125525422:counts$high <- counts$count > medians_by_gene[counts$gene]
1761125551746:#Goal: Add QC-style derived columns without copying. Data: bulk_counts_long.csv
1761125551751:#Tasks:
1761125551754:#• Add la log2 counts column and a binary flag high if count > 100.
1761125551756:#• Overwrite high to use a gene-wise threshold (e.g., count > median(count) by=gene).
1761125551758:# 1 Carico la libreria
1761125551759:library(data.table)
1761125551761:# 2 Leggo il file come data.table
1761125551761:counts <- fread("project_oct25/bulk_counts_long.csv")
1761125551768:# PARTE 1: Aggiungo la colonna log2 dei conteggi
1761125551769:# -----------------------------------------------------
1761125551770:# := modifica la tabella "in place" (senza crearne una copia)
1761125551771:counts[, log2_count := log2(count)]  #modifica o calcola qualcosa in questa tabella
1761125551773:#:= significa che la modifica è in place
1761125551774:#calcola il log in base due dei valori nella colonna count per stabilizzare la varianza
1761125551775:#rende i dati più confrontabili tra geni
1761125551775:# posso aggiungere +1 dopo count per evitare log2(0), che non è definito)
1761125551777:#Aggiungo la colonna binaria 'high' (count > 100)
1761125551778:counts[, high := count > 100]
1761125551780:#se il count è >100 restituisce TRUE altrimenti FALSE
1761125551780:#quindi crea una nuova colonna high con valori booleani
1761125551781:#per classificare i geni in highly expressed o no usando 100 come soglia
1761125551782:# -----------------------------------------------------
1761125551783:# PARTE 3: Sovrascrivo 'high' in modo gene-wise, con questo criterio := (in place)
1761125551784:#per ogni gene verifica se il valore di count è maggiore della mediana di count per quel gene
1761125551785:# (count > median(count) per ciascun gene)
1761125551786:# -----------------------------------------------------
1761125551788:counts[, high := count > median(count), by = gene]  #x ogni gene separatamente
1761125571904:# ==========================================================
1761125571909:# TASK 4 – data.frame version
1761125571910:# ==========================================================
1761125571913:# 1. Import
1761125571916:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1761125571933:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1761125571936:# 2. Join
1761125571936:merged_data <- merge(counts, meta, by = "sample_id")
1761125571971:# 3. Total counts per patient
1761125571974:patient_totals <- aggregate(count ~ patient_id, data = merged_data, FUN = sum)
1761125571987:names(patient_totals)[2] <- "total_count"
1761125571988:# 4. Mean count per gene and condition
1761125571989:gene_means <- aggregate(count ~ gene + condition, data = merged_data, FUN = mean)
1761125572019:names(gene_means)[3] <- "mean_count"
1761125572022:# 5. Top 10 genes by condition
1761125572024:conditions <- unique(gene_means$condition)
1761125572026:top10_by_condition <- data.frame()
1761125572028:for (cond in conditions) {
1761125572029:subset_cond <- subset(gene_means, condition == cond)
1761125572029:subset_cond <- subset_cond[order(-subset_cond$mean_count), ]
1761125572030:top10 <- head(subset_cond, 10)
1761125572031:top10_by_condition <- rbind(top10_by_condition, top10)
1761125572032:}
1761125591172:#Goal: Annotate counts with sample and patient info. Data: bulk_counts_long.csv, sample_metadata.csv Tasks:
1761125591176:#• Join and compute per-patient total counts.
1761125591178:#• Find the top 10 genes by average count within each condition.
1761125591182:library(data.table)
1761125591186:# 1. Import
1761125591188:bulk_counts <- fread("project_oct25/bulk_counts_long.csv")
1761125591195:sample_meta   <- fread("project_oct25/sample_metadata.csv")
1761125591199:# 2. Join counts + metadata
1761125591200:setkey(bulk_counts, sample_id)
1761125591201:setkey(sample_meta, sample_id)
1761125591202:join_data <- bulk_counts[sample_meta, nomatch = 0]
1761125591207:# 3. Total counts per patient
1761125591208:patient_tot <- join_data[, .(total_count = sum(count)), by = patient_id]
1761125591211:# 4. Mean count per gene and condition
1761125591212:gene_means <- join_data[, .(mean_count = mean(count)), by = .(gene, condition)]
1761125591216:# 5. Top 10 genes (highest mean) within each condition
1761125591217:top10 <- gene_means[
1761125591218:order(condition, -mean_count)
1761125591219:][, head(.SD, 10), by = condition]
1761125591222:#by = condition → significa: “ripeti il comando successivo separatamente per ogni valore di condition”.
1761125591223:#.SD → significa “Subset of Data”: è la porzione della tabella relativa al gruppo attuale
1761125591223:#head(.SD, 10) → prende le prime 10 righe del gruppo (cioè i 10 geni con i valori più alti di mean_count).
1761125591225:result <- annotate_counts_dt("project_oct25/bulk_counts_long.csv","project_oct25/sample_metadata.csv")
1761125636124:# 1. Import
1761125636129:labs <- read.csv("project_oct25/clinical_labs.csv")
1761125636135:ref  <- read.csv("project_oct25/lab_reference_ranges.csv")
1761125636141:# 2. Keep unique reference intervals
1761125636142:ref_unique <- unique(ref[, c("lab", "lower", "upper")])
1761125636145:# 3. Join
1761125636146:merged_labs <- merge(labs, ref_unique, by = "lab")
1761125636151:# 4. Classify as normal/out_of_range
1761125636153:merged_labs$status <- ifelse(merged_labs$value >= merged_labs$lower &
1761125636154:merged_labs$value <= merged_labs$upper,
1761125636155:"normal", "out_of_range")
1761125636157:# 5. Summaries
1761125636157:abnormal_by_patient <- aggregate(status ~ patient_id, data = merged_labs,
1761125636158:FUN = function(x) {
1761125636159:total <- length(x)
1761125636159:out   <- sum(x == "out_of_range")
1761125636160:c(total_tests = total, out_of_range = out)
1761125636161:})
1761125636169:# split matrix-like column into two numeric columns
1761125636170:abnormal_by_patient$total_tests  <- abnormal_by_patient$status[, "total_tests"]
1761125636171:abnormal_by_patient$out_of_range <- abnormal_by_patient$status[, "out_of_range"]
1761125636172:abnormal_by_patient$status <- NULL
1761125636173:abnormal_by_lab <- aggregate(status ~ lab, data = merged_labs,
1761125636174:FUN = function(x) {
1761125636175:total <- length(x)
1761125636175:out   <- sum(x == "out_of_range")
1761125636176:c(total_tests = total, out_of_range = out)
1761125636177:})
1761125636183:abnormal_by_lab$total_tests  <- abnormal_by_lab$status[, "total_tests"]
1761125636184:abnormal_by_lab$out_of_range <- abnormal_by_lab$status[, "out_of_range"]
1761125636185:abnormal_by_lab$status <- NULL
1761125702133:#Goal: Classify values against reference intervals.
1761125702136:#Data: clinical_labs.csv, lab_reference_ranges.csv, plus sample_metadata.csv (for sex proxy if you want to extend)
1761125702137:#Tasks:
1761125702138:#• Treat reference ranges as intervals and label each lab as "normal" vs "out_of_range" using a non-equi join
1761125702138:#(value >= lower & value <= upper).
1761125702139:#• Count abnormal rates by patient and by lab.
1761125702144:library(data.table)
1761125702149:# 1 Carico i file
1761125702151:labs <- fread("project_oct25/clinical_labs.csv")
1761125702154:ref  <- fread("project_oct25/lab_reference_ranges.csv")
1761125702157:# Unisco le tabelle per aggiungere i range di riferimento
1761125702157:# Dato che i range sono uguali per M e F, li prendo una sola volta
1761125702158:ref_unique <- unique(ref[, .(lab, lower, upper)])
1761125702163:#unique returns a data table with duplicated rows removed.
1761125702164:#unique è una funzione che prende la tabella lab_ref e controlla quali sono le differenze nelle colonne lab,
1761125702165:#lower e upper e le salva in ref_unique
1761125702167:# Uso una join per aggiungere a ogni valore clinico i limiti lower e upper del test corrispondente
1761125702168:merged_labs <- merge(labs, ref_unique, by = "lab")
1761125702170:# -----------------------------------------------------
1761125702171:# PARTE 2: Classifico i valori come "normal" o "out_of_range"
1761125702172:# -----------------------------------------------------
1761125702173:merged_labs[, status := ifelse(value >= lower & value <= upper, "normal", "out_of_range")]
1761125702177:#all'interno di merged labs, a dx, metti status con questa condizione,
1761125702177:#rispettivamente, se out o normale e le salva in una colonna che è status
1761125702179:# -----------------------------------------------------
1761125702180:# PARTE 3: Calcolo la percentuale di risultati fuori range per paziente
1761125702181:# -----------------------------------------------------
1761125702181:abnormal_by_patient <- merged_labs[, .(
1761125702182:total_tests = .N,                                 # numero totale di test per paziente
1761125702183:out_of_range = sum(status == "out_of_range")      # quanti sono fuori range
1761125702183:), by = patient_id]
1761125702186:# -----------------------------------------------------
1761125702186:# PARTE 4: Calcolo i risultati fuori range per tipo di test
1761125702187:# -----------------------------------------------------
1761125702188:abnormal_by_lab <- merged_labs[, .(
1761125702188:total_tests = .N,
1761125702189:out_of_range = sum(status == "out_of_range")
1761125702190:), by = lab]
1761125716280:# ==========================================================
1761125716282:# TASK 6 – data.frame version
1761125716284:# ==========================================================
1761125716288:# 1. Import
1761125716291:labs   <- read.csv("project_oct25/clinical_labs.csv")
1761125716294:vitals <- read.csv("project_oct25/vitals_time_series.csv")
1761125716299:# 2. Convert to POSIXct
1761125716300:labs$time_iso   <- as.POSIXct(labs$time_iso)
1761125716302:vitals$time_iso <- as.POSIXct(vitals$time_iso)
1761125716306:# 3. Join nearest HR/SBP manually (loop-based)
1761125716307:nearest_match <- function(lab_df, vitals_df, vital_type) {
1761125716308:vitals_sub <- vitals_df[vitals_df$vital == vital_type, ]
1761125716309:results <- list()
1761125716310:for (i in seq_len(nrow(lab_df))) {
1761125716312:pid <- lab_df$patient_id[i]
1761125716313:time <- lab_df$time_iso[i]
1761125716314:v_sub <- vitals_sub[vitals_sub$patient_id == pid, ]
1761125716315:if (nrow(v_sub) > 0) {
1761125716316:idx <- which.min(abs(difftime(v_sub$time_iso, time, units = "mins")))
1761125716317:results[[i]] <- v_sub[idx, c("value", "time_iso")]
1761125716318:} else {
1761125716318:results[[i]] <- data.frame(value = NA, time_iso = NA)
1761125716319:}
1761125716320:}
1761125716320:out <- do.call(rbind, results)
1761125716321:names(out) <- c(paste0("nearest_", vital_type), paste0(vital_type, "_time"))
1761125716322:return(out)
1761125716322:}
1761125716324:# 4. Attach nearest HR and SBP
1761125716324:hr_data  <- nearest_match(labs, vitals, "HR")
1761125716504:sbp_data <- nearest_match(labs, vitals, "SBP")
1761125716661:labs_with_vitals <- cbind(labs, hr_data, sbp_data)
1761125716662:labs_with_vitals$hr_lag_minutes  <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$HR_time, units = "mins"))
1761125716663:labs_with_vitals$sbp_lag_minutes <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$SBP_time, units = "mins"))
1761125716664:# 5. Correlation per patient (CRP only) — robust version in base R
1761125716665:crp_data <- subset(labs_with_vitals, lab == "CRP")
1761125716666:# Split by patient_id
1761125716667:patients_list <- split(crp_data, crp_data$patient_id)
1761125716672:# Function to compute correlation safely
1761125716673:safe_cor <- function(df, col_x = "value", col_y = "nearest_HR") {
1761125716674:if (nrow(df) < 2) return(NA_real_)           # meno di 2 osservazioni -> NA
1761125716674:x <- df[[col_x]]
1761125716675:y <- df[[col_y]]
1761125716676:# keep only pairs non-NA
1761125716676:ok <- !is.na(x) & !is.na(y)
1761125716677:if (sum(ok) < 2) return(NA_real_)            # meno di 2 coppie valide -> NA
1761125716678:return(cor(x[ok], y[ok], use = "complete.obs"))
1761125716678:}
1761125716679:# Calcola correlazione CRP vs HR per ogni paziente
1761125716680:cor_crp_hr <- data.frame(
1761125716680:patient_id = names(patients_list),
1761125716681:correlation_CRP_HR = sapply(patients_list, safe_cor, col_x = "value", col_y = "nearest_HR"),
1761125716681:row.names = NULL,
1761125716682:stringsAsFactors = FALSE
1761125716682:)
1761125716710:# Calcola correlazione CRP vs SBP per ogni paziente
1761125716711:cor_crp_sbp <- data.frame(
1761125716712:patient_id = names(patients_list),
1761125716712:correlation_CRP_SBP = sapply(patients_list, safe_cor, col_x = "value", col_y = "nearest_SBP"),
1761125716713:row.names = NULL,
1761125716714:stringsAsFactors = FALSE
1761125716715:)
1761125732661:# =====================================================
1761125732667:# Goal: Nearest-time matching of vitals to lab draws. Data: clinical_labs.csv, vitals_time_series.csv Tasks:
1761125732671:#• For each lab measurement, attach the nearest HR and SBP reading using a rolling join on (patient_id, time)
1761125732671:#and report the time lag in minutes.
1761125732672:#• Summarize correlation between CRP and nearest HR/SBP by patient.
1761125732673:#si lavora su dati di pazienti, si introducono misurazioni reali nel tempo,
1761125732674:#si usano strumenti “temporali” come il rolling join per trovare misure vicine nel tempo.
1761125732675:#TASK 6: Nearest-time matching of vitals to lab draws
1761125732676:# =====================================================
1761125732677:library(data.table)
1761125732678:# 1. Carico i dati
1761125732679:labs <- fread("project_oct25/clinical_labs.csv")
1761125732681:vitals <- fread("project_oct25/vitals_time_series.csv")
1761125732685:# 2. Preparo le tabelle e converte le date in un formato tempo che R può confrontare
1761125732686:labs[, time_iso := as.POSIXct(time_iso)]
1761125732689:vitals[, time_iso := as.POSIXct(time_iso)]
1761125732691:#ordina i dati per paziente e per tempo, serve per i join temporali
1761125732691:setorder(labs, patient_id, time_iso)
1761125732692:setorder(vitals, patient_id, time_iso)
1761125732694:# Salvo il tempo del laboratorio, creando una nuova colonna lab_time con l'orario del prelievo
1761125732695:labs[, lab_time := time_iso]
1761125732696:#imposto le chiavi, importante per il join
1761125732697:setkey(labs, patient_id, time_iso)
1761125732698:setkey(vitals, patient_id, time_iso)
1761125732699:# 3. Trovo l'HR più vicino
1761125732700:vitals_hr <- vitals[vital == "HR", .(patient_id, time_iso, value)] #prendo solo le righe dei HR
1761125732704:setnames(vitals_hr, "value", "nearest_HR") #rinomino la colonna value in nearest HR
1761125732705:# SALVO IL TEMPO DELL'HR PRIMA DEL JOIN!
1761125732706:vitals_hr[, hr_time := time_iso] #salvo l'ora della misura HR
1761125732707:setkey(vitals_hr, patient_id, time_iso)
1761125732709:labs_with_hr <- vitals_hr[labs, roll = "nearest"] #rolling join
1761125732710:#per ogni esame di lab, trova il battito HR più vicino nel tempo x lo stesso paziente
1761125732711:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1761125732713:#calcola la differenza temporale in minuti tra prelievo e battito
1761125732714:# 4. Trovo l'SBP più vicino, esattamente lo stesso per pressione
1761125732714:vitals_sbp <- vitals[vital == "SBP", .(patient_id, time_iso, value)]
1761125732725:setnames(vitals_sbp, "value", "nearest_SBP")
1761125732727:# SALVO IL TEMPO DELL'SBP PRIMA DEL JOIN!
1761125732727:vitals_sbp[, sbp_time := time_iso]
1761125732729:setkey(vitals_sbp, patient_id, time_iso)
1761125732730:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1761125732732:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1761125732734:# 6. Analisi CRP: filtra solo le righe dove il lab è CRP
1761125732735:crp_data <- labs_with_vitals[lab == "CRP"]
1761125732739:#per ogni paziente (by sample id) calcola la correlazione tra CRP e battito e CRP e pressione
1761125732739:#complete.obs: ignora le righe con dati mancanti
1761125732740:cor_crp_hr <- crp_data[!is.na(nearest_HR), .(
1761125732740:correlation_CRP_HR = cor(value, nearest_HR, use = "complete.obs")
1761125732741:), by = patient_id]
1761125732745:cor_crp_sbp <- crp_data[!is.na(nearest_SBP), .(
1761125732746:correlation_CRP_SBP = cor(value, nearest_SBP, use = "complete.obs")
1761125732746:), by = patient_id]
1761125787646:# ==========================================================
1761125787650:# TASK 7 – data.frame version
1761125787653:# ==========================================================
1761125787656:peaks <- read.csv("project_oct25/atac_peaks.bed.csv", stringsAsFactors = FALSE)
1761125787683:subset_peaks <- subset(peaks, chr == "chr2" & start >= 2000000 & start <= 4000000)
1761125787685:subset_peaks <- subset_peaks[order(-subset_peaks$score), ]
1761125787687:top50_peaks <- head(subset_peaks, 50)
1761125787689:cat("\n--- Top 50 picchi su chr2 (2–4 Mb) ---\n")
1761125787690:print(top50_peaks)
1761125801338:#Goal: Slice genomics windows efficiently. Data: atac_peaks.bed.csv
1761125801342:#Tasks:
1761125801344:#• Extract peaks on chr2 with start between 2 and 4 Mb.
1761125801350:#• Among those peaks, return the top 50 by score after setorder() (descending)
1761125801356:# Carico la libreria
1761125801357:library(data.table)
1761125801359:# Leggo il file dei picchi ATAC
1761125801360:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1761125801366:# Filtro i picchi su chr2 e nella finestra 2–4 Mb
1761125801368:# Nota: 1 Mb = 1.000.000 basi
1761125801368:subset_peaks <- peaks[chr == "chr2" & start >= 2000000 & start <= 4000000]
1761125801371:#Ordino i picchi per punteggio decrescente
1761125801372:subset_peaks <- setorder(subset_peaks, -score)
1761125801373:#Prendo i primi 50 picchi
1761125801374:top50_peaks <- head(subset_peaks, 50)
1761125801376:result <- top_peaks_dt("project_oct25/atac_peaks.bed.csv","chr2", 2000000,4000000)
1761125835816:# ==========================================================
1761125835821:# TASK 8 – data.frame version
1761125835826:# ==========================================================
1761125835830:counts <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1761125835846:meta   <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1761125835849:merged <- merge(counts, meta, by = "sample_id")
1761125835881:stats_by_gene_condition <- aggregate(count ~ gene + condition, data = merged,
1761125835882:FUN = function(x) c(mean = mean(x), median = median(x),
1761125835883:Q1 = quantile(x, 0.25, type = 2),
1761125835883:Q3 = quantile(x, 0.75, type = 2)))
1761125836420:stats_df <- data.frame(
1761125836421:gene = stats_by_gene_condition$gene,
1761125836422:condition = stats_by_gene_condition$condition,
1761125836422:mean_count = stats_by_gene_condition$count[, "mean"],
1761125836423:median_count = stats_by_gene_condition$count[, "median"],
1761125836424:Q1 = stats_by_gene_condition$count[, "Q1.25%"],
1761125836424:Q3 = stats_by_gene_condition$count[, "Q3.75%"]
1761125836425:)
1761125836427:treated <- subset(stats_df, condition == "treated")[, c("gene", "mean_count")]
1761125836428:control <- subset(stats_df, condition == "control")[, c("gene", "mean_count")]
1761125836429:names(treated)[2] <- "treated_mean"
1761125836430:names(control)[2] <- "control_mean"
1761125836431:means_wide <- merge(treated, control, by = "gene")
1761125836433:kept_genes <- subset(means_wide, treated_mean >= 2 * control_mean)
1761125848296:#Goal: Multi-column operations per group.
1761125848302:#Data: bulk_counts_long.csv, sample_metadata.csv
1761125848304:#Tasks:
1761125848307:#• Compute per-condition robust summary stats for each gene: mean, median, Q1/Q3.
1761125848309:#• Return only genes where treated mean ‚â• 2√ó control mean.
1761125848312:library(data.table)
1761125848313:counts <- fread("project_oct25/bulk_counts_long.csv")
1761125848319:meta   <- fread("project_oct25/sample_metadata.csv")
1761125848324:#unione di counts e metadata per avere la colonna 'condition' insieme ai conteggi
1761125848325:merged <- counts[meta, on = "sample_id"]
1761125848331:#Calcoliamo le statistiche per gene e condition: mean, median, Q1 (25%) e Q3 (75%)
1761125848332:stats_by_gene_condition <- merged[, .(
1761125848333:mean_count   = mean(count),
1761125848334:median_count = median(count),
1761125848335:Q1           = quantile(count, 0.25, type = 2),
1761125848336:Q3           = quantile(count, 0.75, type = 2)
1761125848336:), by = .(gene, condition)]
1761125849130:#Per applicare la regola "treated mean >= 2 * control mean" serve una tabella wide con le medie:
1761125849131:#separiamo le medie per condition e poi facciamo un merge per gene.
1761125849131:treated_means <- stats_by_gene_condition[condition == "treated", .(gene, treated_mean = mean_count)]
1761125849135:control_means <- stats_by_gene_condition[condition == "control", .(gene, control_mean = mean_count)]
1761125849138:#Uniamo le due tabelle delle medie per avere una riga per gene con entrambe le medie
1761125849139:means_wide <- merge(treated_means, control_means, by = "gene", all = FALSE)
1761125849142:# all = FALSE -> keep only genes present in both (necessario per confronto)
1761125849144:#Applichiamo il filtro: kept genes dove treated_mean >= 2 * control_mean
1761125849145:kept_genes <- means_wide[treated_mean >= 2 * control_mean]
1761125899771:# ==========================================================
1761125899774:# TASK 9 – data.frame version
1761125899777:# ==========================================================
1761125899780:counts_wide <- read.csv("project_oct25/bulk_counts_wide.csv", stringsAsFactors = FALSE)
1761125899806:counts_long <- reshape(counts_wide, varying = names(counts_wide)[-1],
1761125899811:v.names = "count", timevar = "sample_id",
1761125899812:times = names(counts_wide)[-1], idvar = "gene",
1761125899814:direction = "long")
1761125899898:meta <- read.csv("project_oct25/sample_metadata.csv", stringsAsFactors = FALSE)
1761125899900:merged <- merge(counts_long, meta, by = "sample_id")
1761125899964:totals_per_sample <- aggregate(count ~ sample_id, data = merged, sum)
1761125899981:names(totals_per_sample)[2] <- "total_count"
1761125899983:merged <- merge(merged, totals_per_sample, by = "sample_id")
1761125900044:gene_condition_means <- aggregate(count ~ gene + condition, data = merged, mean)
1761125900082:counts_condition_wide <- reshape(gene_condition_means,
1761125900083:timevar = "condition", idvar = "gene",
1761125900083:direction = "wide")
1761125900089:cat("\n--- Tabella finale: media dei conteggi per gene e condizione ---\n")
1761125900090:print(head(counts_condition_wide, 10))
1761125917260:#Goal: Go wide‚ to long‚ to wide for downstream plotting. Data: bulk_counts_wide.csv
1761125917266:#Tasks:
1761125917269:# • Convert the matrix to long, add per-sample totals, then back to a gene per condition table with mean counts.
1761125917271:# =====================================================
1761125917271:# TASK 9: Go wide → long → wide for downstream plotting
1761125917272:# =====================================================
1761125917274:# Carichiamo le librerie
1761125917274:library(data.table)
1761125917276:# Leggiamo i dati (matrice larga: una riga per gene, una colonna per campione)
1761125917277:counts_wide <- fread("project_oct25/bulk_counts_wide.csv")
1761125917282:# PARTE 1: Convertiamo da formato wide → long
1761125917283:# -----------------------------------------------------
1761125917285:# Supponiamo che la prima colonna si chiami "gene"
1761125917286:counts_long <- melt(counts_wide, id.vars = "gene",
1761125917287:variable.name = "sample_id", value.name = "count")
1761125917289:#melt()	scioglie la tabella da larga a lunga.
1761125917290:#counts_wide	è la tabella di partenza (quella larga).
1761125917291:#id.vars = "gene"	dice a R: mantieni la colonna “gene” così com’è (non la trasformare).
1761125917291:#Tutte le altre colonne (sample_1, sample_2, ecc.) verranno “sciolte”.
1761125917292:#variable.name = "sample_id"	dà un nome alla nuova colonna che conterrà i nomi delle vecchie colonne (cioè i nomi dei campioni)
1761125917293:#value.name = "count"	dà un nome alla colonna che conterrà i valori numerici (cioè i conteggi per gene e campione).
1761125917294:# Aggiungiamo le informazioni di condizione per ogni sample
1761125917295:# Carichiamo i metadati
1761125917296:meta <- fread("project_oct25/sample_metadata.csv")
1761125917298:# Uniamo metadati ai conteggi
1761125917299:merged <- merge(counts_long, meta, by = "sample_id")
1761125917311:# Calcoliamo i totali per campione
1761125917312:totals_per_sample <- merged[, .(total_count = sum(count)), by = sample_id]
1761125917315:# Aggiungiamo questi totali alla tabella principale
1761125917315:merged <- merge(merged, totals_per_sample, by = "sample_id")
1761125917320:# Torniamo da long → wide,
1761125917321:#           ma ora con colonne per condizione (treated, control)
1761125917322:#           e valori = media dei conteggi per gene
1761125917322:gene_condition_means <- merged[, .(mean_count = mean(count)),
1761125917323:by = .(gene, condition)]
1761125917326:# Da long a wide: una riga per gene, colonne = condizioni
1761125917327:counts_condition_wide <- dcast(gene_condition_means,
1761125917328:gene ~ condition,
1761125917328:value.var = "mean_count")
1761125923992:View(merged)
1761125934909:peaks <- read.csv("project_oct25/atac_peaks.bed.csv", stringsAsFactors = FALSE)
1761125934941:genes <- read.csv("project_oct25/gene_annotation.bed.csv", stringsAsFactors = FALSE)
1761125934950:# overlap calcolato “a mano”
1761125934953:overlaps_list <- lapply(1:nrow(peaks), function(i) {
1761125934954:p <- peaks[i, ]
1761125934955:gsub <- subset(genes, chr == p$chr & start <= p$end & end >= p$start)
1761125934956:if (nrow(gsub) == 0) return(NULL)
1761125934957:gsub$overlap_bp <- pmin(p$end, gsub$end) - pmax(p$start, gsub$start)
1761125934958:gsub <- gsub[gsub$overlap_bp > 0, ]
1761125934959:gsub$peak_id <- i
1761125934960:gsub
1761125934961:})
1761125936794:overlaps <- do.call(rbind, overlaps_list)
1761125936933:peaks_per_gene <- aggregate(overlap_bp ~ gene, data = overlaps, FUN = length)
1761125936941:names(peaks_per_gene)[2] <- "num_peaks"
1761125936942:overlap_sum_per_gene <- aggregate(overlap_bp ~ gene, data = overlaps, sum)
1761125936950:names(overlap_sum_per_gene)[2] <- "total_overlap_bp"
1761125936951:top20_genes <- head(overlap_sum_per_gene[order(-overlap_sum_per_gene$total_overlap_bp), ], 20)
1761125950295:#Goal: ATAC-to-gene mapping.
1761125950298:#Data: atac_peaks.bed.csv, gene_annotation.bed.csv
1761125950306:#Tasks:
1761125950312:#• setkey() both on (chr, start, end) and intersect peaks with gene bodies.
1761125950314:#• Count peaks per gene.
1761125950314:#• Compute overlap length (bp) per peak-gene pair and then sum per gene.
1761125950315:#• Return the top 20 genes by total overlapped bp.
1761125950317:# Carichiamo la libreria
1761125950318:library(data.table)
1761125950322:# Leggiamo i file
1761125950323:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1761125950327:genes <- fread("project_oct25/gene_annotation.bed.csv")
1761125950330:# Imposta le chiavi per (chr, start, end)
1761125950330:setkey(peaks, chr, start, end)
1761125950332:setkey(genes, chr, start, end)
1761125950334:# Trova intersezioni tra picchi e geni
1761125950335:# (non-equi join: regioni che si sovrappongono)
1761125950335:# La condizione di overlap:
1761125950336:# start_peak <= end_gene e end_peak >= start_gene
1761125950337:overlaps <- foverlaps(peaks, genes,
1761125950337:by.x = c("chr", "start", "end"),
1761125950338:by.y = c("chr", "start", "end"),
1761125950339:type = "any", nomatch = 0L)
1761125950348:# Calcola la lunghezza di overlap (in basi)
1761125950349:# L'overlap fra due intervalli è: min(end1, end2) - max(start1, start2)
1761125950349:overlaps[, overlap_bp := pmin(end, i.end) - pmax(start, i.start)]
1761125950352:# Mantieni solo le righe con overlap positivo
1761125950352:overlaps <- overlaps[overlap_bp > 0]
1761125950354:# Conta quanti picchi per gene
1761125950355:peaks_per_gene <- overlaps[, .N, by = gene]
1761125950359:setnames(peaks_per_gene, "N", "num_peaks")
1761125950362:# Somma la lunghezza totale di overlap per gene
1761125950363:overlap_sum_per_gene <- overlaps[, .(total_overlap_bp = sum(overlap_bp)), by = gene]
1761125950365:# Ordina per overlap totale (decrescente) e prendi top 20
1761125950366:# -----------------------------------------------------
1761125950367:top20_genes <- overlap_sum_per_gene[order(-total_overlap_bp)][1:20]
1761125967749:# =========================================================
1761125967752:# TASK 11 (versione base R con data.frame)
1761125967753:# Goal:
1761125967754:# - Mappare varianti (SNP) ai geni
1761125967756:# - Contare varianti ad alto impatto (HIGH) per gene e per sample
1761125967758:# =========================================================
1761125967763:# 1️⃣ Carico i dati -----------------------------------------------------------
1761125967765:variants <- read.csv("project_oct25/variants.csv")
1761125967773:genes    <- read.csv("project_oct25/gene_annotation.bed.csv")
1761125967778:# 2️⃣ Creo intervalli 1-bp per le varianti -----------------------------------
1761125967779:# Ogni variante è un punto, quindi creo due colonne identiche (start, end)
1761125967780:variants$start <- variants$pos
1761125967782:variants$end   <- variants$pos
1761125967784:# 3 Trovo le varianti che si sovrappongono a ciascun gene ------------------
1761125967785:# (equivalente a foverlaps)
1761125967787:# Facciamo un ciclo semplice: per ogni variante controlliamo se rientra nell’intervallo del gene
1761125967788:# Questo è molto meno efficiente, ma chiaro e comprensibile
1761125967789:overlaps_list <- list()
1761125967790:for (i in seq_len(nrow(variants))) {
1761125967791:var_chr   <- variants$chr[i]
1761125967791:var_start <- variants$start[i]
1761125967792:var_end   <- variants$end[i]
1761125967794:# Trova i geni sullo stesso cromosoma che si sovrappongono a quella variante?????
1761125967794:#???????OVERLAPPING_GENES 0 OBS
1761125967795:overlapping_genes <- subset(genes,
1761125967796:chr == var_chr &
1761125967797:start <= var_end &
1761125967797:end >= var_start)
1761125967799:# Se ci sono geni che si sovrappongono, li aggiungo alla lista
1761125967799:if (nrow(overlapping_genes) > 0) {
1761125967800:tmp <- data.frame(
1761125967801:sample_id = variants$sample_id[i],
1761125967801:gene = overlapping_genes$gene,
1761125967802:chr = var_chr,
1761125967802:pos = var_start,
1761125967803:impact = variants$impact[i],
1761125967804:stringsAsFactors = FALSE
1761125967804:)
1761125967805:overlaps_list[[length(overlaps_list) + 1]] <- tmp
1761125967806:}
1761125967806:}
1761125968403:# Combino tutti i risultati in un unico data.frame
1761125968403:if (length(overlaps_list) > 0) {
1761125968404:overlaps <- do.call(rbind, overlaps_list)
1761125968405:} else {
1761125968405:overlaps <- data.frame()
1761125968406:}
1761125968492:# 4️⃣ Normalizzo la colonna impact a maiuscolo --------------------------------
1761125968493:if (nrow(overlaps) > 0) {
1761125968494:overlaps$impact_upper <- toupper(overlaps$impact)
1761125968495:}
1761125968497:# 5️⃣ Filtro solo le varianti di alto impatto ---------------------------------
1761125968498:high_overlaps <- subset(overlaps, impact_upper == "HIGH")
1761125968500:# 6️⃣ Conteggio delle varianti HIGH per gene e per sample ---------------------
1761125968501:if (nrow(high_overlaps) > 0) {
1761125968501:high_counts_by_gene_sample <- aggregate(
1761125968502:x = list(high_variant_count = high_overlaps$impact_upper),
1761125968503:by = list(gene = high_overlaps$gene, sample_id = high_overlaps$sample_id),
1761125968504:FUN = length
1761125968505:)
1761125968505:} else {
1761125968506:high_counts_by_gene_sample <- data.frame()
1761125968507:}
1761125968512:# 7️⃣ Conteggio totale delle varianti HIGH per gene --------------------------
1761125968513:if (nrow(high_overlaps) > 0) {
1761125968513:high_counts_by_gene <- aggregate(
1761125968514:x = list(total_high_variants = high_overlaps$impact_upper),
1761125968515:by = list(gene = high_overlaps$gene),
1761125968516:FUN = length
1761125968517:)
1761125968518:# Ordina in modo decrescente
1761125968519:high_counts_by_gene <- high_counts_by_gene[order(-high_counts_by_gene$total_high_variants), ]
1761125968521:# Geni con almeno una variante HIGH
1761125968523:genes_with_high <- unique(high_counts_by_gene$gene)
1761125968530:} else {
1761125968533:high_counts_by_gene <- data.frame()
1761125968535:genes_with_high <- character(0)
1761125968536:}
1761125968544:# 8️⃣ Salvo i risultati su file CSV ------------------------------------------
1761125968545:write.csv(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv", row.names = FALSE)
1761125968549:write.csv(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv", row.names = FALSE)
1761125968551:write.csv(data.frame(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv", row.names = FALSE)
1761125968558:cat("\nAnalisi completata. File salvati in project_oct25/.\n")
1761125982740:#Goal: Map SNPs to genes.
1761125982742:#Data: variants.csv, gene_annotation.bed.csv
1761125982743:#Tasks:
1761125982744:#• Convert variant positions to 1-bp intervals (pos, pos)
1761125982745:#and find overlaps with gene intervals.
1761125982746:#• Summarize counts of HIGH impact variants by gene and by sample.
1761125982747:#• List genes with HIGH-impact variants across all samples.
1761125982750:#Obiettivo:
1761125982751:#mappare le varianti (SNP) sui geni
1761125982753:#contare le varianti ad alto impatto (HIGH) per gene e per campione
1761125982755:#ottenere la lista dei geni che presentano almeno una variante HIGH in qualsiasi campione
1761125982759:# carico la libreria
1761125982762:library(data.table)
1761125982765:# leggo i file
1761125982766:variants <- fread("project_oct25/variants.csv")
1761125982769:genes    <- fread("project_oct25/gene_annotation.bed.csv")
1761125982773:# Creo intervalli 1-bp per le varianti: start = pos, end = pos
1761125982773:#    (foverlaps lavora con intervalli start-end)
1761125982774:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1761125982776:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1761125982779:# 5) imposto le chiavi per foverlaps: (chr, start, end), requisito per foverlaps utile per velocizzare
1761125982779:setkey(variants, chr, start, end)
1761125982781:setkey(genes,    chr, start, end)
1761125982786:# 6) eseguo l'overlap: trovo per ogni variante i geni che si sovrappongono
1761125982787:#    nomatch = 0L rimuove le varianti senza overlap, che non sovrappongono alcun gene
1761125982788:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1761125982797:#type any cioè prende qualsiasi sovrapposizione (parziale o completa)
1761125982799:# 7) filtro le varianti di alto impatto (impact == "HIGH")
1761125982800:#    normalizzo il valore di impact a maiuscole per sicurezza
1761125982801:overlaps[, impact_upper := toupper(impact)] #normalizzo il campo impact
1761125982803:#overlaps	È il nome della tabella su cui stai lavorando (una data.table).
1761125982803:#[,]	In data.table, serve per dire “fai qualcosa su questa tabella”.
1761125982804:#impact_upper := ...	Con := stai creando una nuova colonna chiamata impact_upper, oppure sovrascrivendo se già esiste.
1761125982804:#toupper(impact)	È una funzione di R che trasforma tutto il testo in maiuscolo prendendo i valori della colonna impact.
1761125982806:high_overlaps <- overlaps[impact_upper == "HIGH"] #seleziono solo le varianti con impact HIGH
1761125982810:# 8) conto le varianti HIGH per gene e per sample_id
1761125982811:#conta quante varianti ci sono per coppia gene x sample_id
1761125982811:#.N è il conteggio delle righe del gruppo
1761125982812:high_counts_by_gene_sample <- high_overlaps[, .(
1761125982813:high_variant_count = .N
1761125982814:), by = .(gene, sample_id)]
1761125982817:# 9) conto le varianti HIGH per gene (tutte le sample aggregate)
1761125982817:high_counts_by_gene <- high_overlaps[, .(
1761125982818:total_high_variants = .N
1761125982819:), by = gene][order(-total_high_variants)]
1761125982821:#conta quanti HIGH per gene complessivamente e ordina decrescente i geni
1761125982822:# 10) lista dei geni che hanno almeno una variante HIGH (unique gene)
1761125982823:#Estrae i geni con almeno una variante HIGH
1761125982824:genes_with_high <- unique(high_counts_by_gene$gene)
1761125982824:print(genes_with_high)
1761125982827:# 11) (Opzionale) salvo i risultati su file CSV nella cartella project_oct25
1761125982827:fwrite(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv")
1761125982830:fwrite(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv")
1761125982831:fwrite(data.table(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv")
1761126022986:# =========================================================
1761126022992:# TASK 11 (versione base R con data.frame)
1761126022995:# Goal:
1761126022996:# - Mappare varianti (SNP) ai geni
1761126023000:# - Contare varianti ad alto impatto (HIGH) per gene e per sample
1761126023001:# =========================================================
1761126023004:# 1️⃣ Carico i dati -----------------------------------------------------------
1761126023005:variants <- read.csv("project_oct25/variants.csv")
1761126023012:genes    <- read.csv("project_oct25/gene_annotation.bed.csv")
1761126023016:# 2️⃣ Creo intervalli 1-bp per le varianti -----------------------------------
1761126023017:# Ogni variante è un punto, quindi creo due colonne identiche (start, end)
1761126023018:variants$start <- variants$pos
1761126023020:variants$end   <- variants$pos
1761126023022:# 3 Trovo le varianti che si sovrappongono a ciascun gene ------------------
1761126023023:# (equivalente a foverlaps)
1761126023024:# Facciamo un ciclo semplice: per ogni variante controlliamo se rientra nell’intervallo del gene
1761126023025:# Questo è molto meno efficiente, ma chiaro e comprensibile
1761126023026:overlaps_list <- list()
1761126023028:for (i in seq_len(nrow(variants))) {
1761126023029:var_chr   <- variants$chr[i]
1761126023031:var_start <- variants$start[i]
1761126023032:var_end   <- variants$end[i]
1761126023034:# Trova i geni sullo stesso cromosoma che si sovrappongono a quella variante?????
1761126023035:#???????OVERLAPPING_GENES 0 OBS
1761126023036:overlapping_genes <- subset(genes,
1761126023037:chr == var_chr &
1761126023038:start <= var_end &
1761126023039:end >= var_start)
1761126023040:# Se ci sono geni che si sovrappongono, li aggiungo alla lista
1761126023041:if (nrow(overlapping_genes) > 0) {
1761126023042:tmp <- data.frame(
1761126023044:sample_id = variants$sample_id[i],
1761126023046:gene = overlapping_genes$gene,
1761126023047:chr = var_chr,
1761126023050:pos = var_start,
1761126023051:impact = variants$impact[i],
1761126023052:stringsAsFactors = FALSE
1761126023053:)
1761126023054:overlaps_list[[length(overlaps_list) + 1]] <- tmp
1761126023055:}
1761126023056:}
1761126023846:# Combino tutti i risultati in un unico data.frame
1761126023846:if (length(overlaps_list) > 0) {
1761126023847:overlaps <- do.call(rbind, overlaps_list)
1761126023848:} else {
1761126023848:overlaps <- data.frame()
1761126023850:}
1761126023975:# 4️⃣ Normalizzo la colonna impact a maiuscolo --------------------------------
1761126023976:if (nrow(overlaps) > 0) {
1761126023977:overlaps$impact_upper <- toupper(overlaps$impact)
1761126023978:}
1761126023981:# 5️⃣ Filtro solo le varianti di alto impatto ---------------------------------
1761126023982:high_overlaps <- subset(overlaps, impact_upper == "HIGH")
1761126023985:# 6️⃣ Conteggio delle varianti HIGH per gene e per sample ---------------------
1761126023986:if (nrow(high_overlaps) > 0) {
1761126023986:high_counts_by_gene_sample <- aggregate(
1761126023987:x = list(high_variant_count = high_overlaps$impact_upper),
1761126023988:by = list(gene = high_overlaps$gene, sample_id = high_overlaps$sample_id),
1761126023989:FUN = length
1761126023990:)
1761126023991:} else {
1761126023992:high_counts_by_gene_sample <- data.frame()
1761126023993:}
1761126024004:# 7️⃣ Conteggio totale delle varianti HIGH per gene --------------------------
1761126024005:if (nrow(high_overlaps) > 0) {
1761126024005:high_counts_by_gene <- aggregate(
1761126024006:x = list(total_high_variants = high_overlaps$impact_upper),
1761126024007:by = list(gene = high_overlaps$gene),
1761126024008:FUN = length
1761126024009:)
1761126024010:# Ordina in modo decrescente
1761126024011:high_counts_by_gene <- high_counts_by_gene[order(-high_counts_by_gene$total_high_variants), ]
1761126024012:# Geni con almeno una variante HIGH
1761126024013:genes_with_high <- unique(high_counts_by_gene$gene)
1761126024013:} else {
1761126024014:high_counts_by_gene <- data.frame()
1761126024015:genes_with_high <- character(0)
1761126024019:}
1761126024026:# 8️⃣ Salvo i risultati su file CSV ------------------------------------------
1761126024027:write.csv(high_counts_by_gene_sample, "project_oct25/high_variants_by_gene_sample.csv", row.names = FALSE)
1761126024029:write.csv(high_counts_by_gene, "project_oct25/high_variants_by_gene_total.csv", row.names = FALSE)
1761126024032:write.csv(data.frame(gene = genes_with_high), "project_oct25/genes_with_high_variants.csv", row.names = FALSE)
1761126024035:cat("\nAnalisi completata. File salvati in project_oct25/.\n")
1761126058654:cohortA <- read.csv("project_oct25/cohortA_samples.csv", stringsAsFactors = FALSE)
1761126058658:cohortB <- read.csv("project_oct25/cohortB_samples.csv", stringsAsFactors = FALSE)
1761126058660:counts  <- read.csv("project_oct25/bulk_counts_long.csv", stringsAsFactors = FALSE)
1761126058679:cohortA$cohort <- "A"
1761126058680:cohortB$cohort <- "B"
1761126058682:combined_cohorts <- rbind(cohortA, cohortB)
1761126058684:combined_cohorts <- combined_cohorts[order(combined_cohorts$cohort,
1761126058686:combined_cohorts$condition,
1761126058687:combined_cohorts$sample_id), ]
1761126058690:merged <- merge(counts, combined_cohorts, by = "sample_id", all.x = TRUE)
1761126058737:gene_variance <- aggregate(count ~ gene, data = merged, FUN = var, na.rm = TRUE)
1761126058773:names(gene_variance)[2] <- "variance"
1761126058774:top100_genes <- head(gene_variance[order(-gene_variance$variance), "gene"], 100)
1761126058777:top100_data <- subset(merged, gene %in% top100_genes)
1761126058781:mean_counts <- aggregate(count ~ gene + cohort + condition,
1761126058784:data = top100_data, FUN = mean, na.rm = TRUE)
1761126058838:names(mean_counts)[4] <- "mean_count"
1761126067905:#Goal: Combine cohorts safely.
1761126067907:#Data: cohortA_samples.csv, cohortB_samples.csv
1761126067908:#Tasks:
1761126067910:#• rbindlist(list(A, B), use.names=TRUE, fill=TRUE) and verify column alignment.
1761126067913:#• Order by cohort, condition, sample_id.
1761126067917:#• Join back to bulk_counts_long and compute per-cohort, per-condition mean counts of the top 100 most variable genes.
1761126067921:# Carichiamo la libreria
1761126067923:library(data.table)
1761126067926:# Leggiamo i file, specificando i percorsi
1761126067926:cohortA <- fread("project_oct25/cohortA_samples.csv")
1761126067930:cohortB <- fread("project_oct25/cohortB_samples.csv")
1761126067933:counts  <- fread("project_oct25/bulk_counts_long.csv")
1761126067939:# Aggiungiamo una colonna 'cohort' per tenere traccia della provenienza
1761126067940:cohortA[, cohort := "A"]
1761126067942:cohortB[, cohort := "B"]
1761126067944:# Uniamo le due coorti
1761126067945:# use.names = TRUE --> allinea le colonne con lo stesso nome
1761126067946:# fill = TRUE      --> se mancano colonne in uno dei due file, le crea e le riempie con NA
1761126067947:combined_cohorts <- rbindlist(list(cohortA, cohortB), use.names = TRUE, fill = TRUE)
1761126067948:# Ordiniamo per coorte, condizione e sample_id
1761126067949:setorder(combined_cohorts, cohort, condition, sample_id)
1761126067951:# Uniamo per sample_id
1761126067951:merged_per_sampleid <- merge(counts, combined_cohorts, by = "sample_id", all.x = TRUE)
1761126067956:# PARTE 3: Troviamo i 100 geni più variabili
1761126067957:# Calcoliamo la varianza dei conteggi per ciascun gene
1761126067957:gene_variance <- merged_per_sampleid[, .(variance = var(count, na.rm = TRUE)), by = gene]
1761126067961:# Ordiniamo per varianza decrescente e prendiamo i primi 100
1761126067962:top100_genes <- gene_variance[order(-variance)][1:100, gene]
1761126067964:print(head(top100_genes, 5))
1761126067966:# Calcoliamo la media dei conteggi per coorte e condizione
1761126067966:#           solo per i top 100 geni
1761126067967:top100_data <- merged_per_sampleid[gene %in% top100_genes]
1761126067971:mean_counts <- top100_data[, .(
1761126067972:mean_count = mean(count, na.rm = TRUE)
1761126067972:), by = .(gene, cohort, condition)]
1761126100817:#Final revision
1761126100820:#Goal: Associate cell type to integration clusters taking tract of their belongings to normal or tumor tissue.
1761126100822:#Data:
1761126100824:#annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv contains the following columns:
1761126100826:#• cell = cell id
1761126100830:#• integration_cluster = integration cluster
1761126100832:#nt_combined_clustering.output.csv contains the following columns:
1761126100833:#• cell = cell id
1761126100834:#• cell_type = predicted cell type
1761126100835:#• sample_type = N for normal tissue neat to tumor, and T for tumor tissue
1761126100836:#Per ogni richiesta creerò il codice R semplice (usando data.table e ggplot2 per il plot)
1761126100838:#SETUP PACCHETTI E PERCORSI
1761126100840:# Setup iniziale
1761126100842:library(data.table)   # lavoro tabellare semplice e veloce
1761126100843:library(ggplot2)      # per il plot richiesto
1761126100845:#TASK 1.1
1761126100845:#provide a new file where cell type, cells and integration clusters are combined
1761126100846:#Leggi i due file
1761126100847:integration_dt   <- fread("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")   # colonne attese: cell, integration_cluster
1761126100854:clustering_dt <- fread("project_oct25/nt_combined_clustering.output.csv") # colonne attese: cell, cell_type, sample_type
1761126100867:#Controlliamo i nomi delle colonne #NON RICHIESTO
1761126100868:cat("Colonne in file integrazione:", names(integration_dt), "\n")
1761126100869:cat("Colonne in file clustering: ", names(clustering_dt), "\n")
1761126100870:#Nuova versione di normalizzazione perchè i nomi sono diversi: rimuove anche _X_ o _Y_ in mezzo agli ID
1761126100871:normalize_cell_id <- function(x) {
1761126100871:x <- as.character(x)
1761126100872:x <- trimws(x)                     # toglie spazi iniziali/finali
1761126100873:x <- gsub("_X_", "_", x)           # rimuove sequenze _X_ nel mezzo
1761126100874:x <- gsub("_Y_", "_", x)           # rimuove sequenze _Y_ nel mezzo
1761126100875:x <- gsub("_\\.", ".", x)          # rimuove underscore prima del punto
1761126100875:return(x)
1761126100876:}
1761126100878:# Applichiamo la funzione di normalizzazione
1761126100878:integration_dt[, cell_clean := normalize_cell_id(cell)]
1761126100908:clustering_dt[, cell_clean := normalize_cell_id(cell)]
1761126100933:#Unione (join) sui cell id ma i CELL ID NON SONO SCRITTI NELLO STESSO FORMATO NEI DUE FILE
1761126100934:combined <- merge(integration_dt, clustering_dt, by = "cell_clean", all=FALSE) #all FALSE evita duplicazioni indesiderate
1761126100972:#Salvo il file risultante
1761126100973:#fwrite(combined) NO!!
1761126100974:#TASK 2.1: provide a file where the number of each cell type is indicated for each cluster
1761126100975:#Per ogni integration_cluster contare quante cells di ciascun cell_type ci sono
1761126100976:#(tabella cluster × cell_type con conti).
1761126100977:# 1. Assicuriamoci di usare la tabella combinata
1761126100977:start_point <- copy(combined)
1761126100979:# 2. Conta per cluster x cell_type
1761126100980:counts_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1761126100982:setnames(counts_cluster_celltype, "N", "cell_count")
1761126100983:#fwrite(counts_cluster_celltype) NO!!
1761126100984:#TASK3.1:provide summary table showing cell types associated to integration clusters
1761126100985:#and also their association to normal and tumor tissue
1761126100986:#Costruire una tabella che per ogni (integration_cluster, cell_type, sample_type) riporta:
1761126100986:#cell_count (numero di celle),
1761126100987:#pct_within_cluster = percentuale di quel cell_type dentro il cluster
1761126100987:#(cioè cell_count / total_cells_in_cluster * 100),
1761126100988:#pct_within_celltype = percentuale di quelle celle di quel tipo che sono N o T
1761126100989:#(utile per vedere normal vs tumor per quello specifico cell_type nel cluster).
1761126100990:# 1. Ripartiamo da combined
1761126100991:start_point <- copy(combined)
1761126100993:# 2. Conta righe per (cluster, cell_type, sample_type)
1761126100994:tab_ct_st <- start_point[, .N, by = .(integration_cluster, cell_type, sample_type)]
1761126100996:setnames(tab_ct_st, "N", "cell_count")
1761126100998:# 3. Calcola totale per cluster (per normalizzare dentro il cluster)
1761126100999:totals_cluster <- start_point[, .N, by = integration_cluster]
1761126101001:setnames(totals_cluster, "N", "cluster_total_cells")
1761126101002:# 4. Unisci il totale per cluster
1761126101003:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster", all.x = TRUE)
1761126101007:# 5. Calcolo percentuale dentro cluster (di tutte le celle del cluster)
1761126101007:tab_ct_st[, pct_within_cluster := (cell_count / cluster_total_cells) * 100]
1761126101010:# 6. Calcolo percentuale dentro la coppia (cluster, cell_type) split by sample_type
1761126101010:#    Prima calcolo il totale per (cluster, cell_type) (sommando tutte le sample_type)
1761126101012:totals_cluster_celltype <- start_point[, .N, by = .(integration_cluster, cell_type)]
1761126101014:setnames(totals_cluster_celltype, "N", "cluster_celltype_total")
1761126101016:# 7. Unisco e calcolo la % di sample_type all'interno del (cluster, cell_type)
1761126101017:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype, by = c("integration_cluster", "cell_type"), all.x = TRUE)
1761126101021:tab_ct_st[, pct_within_cluster_celltype := (cell_count / cluster_celltype_total) * 100]
1761126101023:# 8. Riordino colonne per chiarezza e salvo
1761126101024:setcolorder(tab_ct_st, c("integration_cluster", "cell_type", "sample_type",
1761126101024:"cell_count", "cluster_celltype_total", "pct_within_cluster_celltype",
1761126101025:"cluster_total_cells", "pct_within_cluster"))
1761126101026:out3 <- paste0("_summary_cluster_celltype_sampletype.csv")
1761126101026:fwrite(tab_ct_st, out3)
1761126101028:#TASK4.1
1761126101029:#Provide a plot describing the distribution of the cell type in normal/tumor tissue
1761126101029:#given the integration clusters.
1761126101030:# Usiamo il file che hai già creato nel Task 1
1761126101031:# (quello con le colonne: cell_type, integration_cluster, sample_type)
1761126101031:data <- combined
1761126101032:# Contiamo quante celle ci sono per combinazione di cluster, tipo di cellula e tipo di tessuto
1761126101033:counts <- as.data.frame(table(data$integration_cluster, data$cell_type, data$sample_type))
1761126101038:names(counts) <- c("cluster", "cell_type", "tissue", "count")
1761126101039:# Calcoliamo la percentuale di ogni cell_type dentro ciascun cluster e tessuto
1761126101039:# Per farlo, prima troviamo il totale per cluster e tessuto
1761126101040:totals <- aggregate(count ~ cluster + tissue, data = counts, sum)
1761126101043:names(totals)[3] <- "total" #cambia il nome della terza colonna da counts a total
1761126101044:# Ora uniamo le due tabelle
1761126101044:counts2 <- merge(counts, totals, by = c("cluster", "tissue"))
1761126101051:# Calcoliamo la percentuale
1761126101052:counts2$percent <- (counts2$count / counts2$total) * 100
1761126101053:# Facciamo il grafico
1761126101053:ggplot(counts2, aes(x = cluster, y = percent, fill = cell_type)) +
1761126101054:geom_bar(stat = "identity") +
1761126101054:facet_wrap(~ tissue) +
1761126101055:labs(title = "Distribution of cell types in clusters",
1761126101055:x = "Integration cluster",
1761126101056:y = "Cells percentage (%)") +
1761126101056:theme_minimal() +
1761126101057:theme(axis.text.x = element_text(angle = 45, hjust = 1))
1761126102846:#TASK5.1
1761126102847:#Provide a normalized % for the cell types in each of the integration clusters
1761126102848:#for normal and tumor specimen.
1761126102849:# TASK 5.1 — data.table only
1761126102850:# Goal: Provide normalized % for the cell types in each of the integration clusters
1761126102851:# for normal and tumor specimen.
1761126102852:library(data.table)
1761126102854:# Assumiamo di partire da 'combined' (già creato nei task precedenti)
1761126102854:data_dt <- as.data.table(combined)
1761126102856:# Conta quante celle per cluster, tipo cellulare e tessuto
1761126102857:counts <- data_dt[, .N, by = .(cluster = integration_cluster,
1761126102857:cell_type,
1761126102858:tissue = sample_type)]
1761126102861:# Calcola il totale per ogni cluster e tipo di tessuto
1761126102861:totals <- counts[, .(total = sum(N)), by = .(cluster, tissue)]
1761126102864:# Unisci i totali ai conteggi
1761126102864:counts <- merge(counts, totals, by = c("cluster", "tissue"))
1761126102868:# Calcola la percentuale normalizzata
1761126102869:counts[, percent := round((N / total) * 100, 2)]
1761126102871:# Riordina per cluster e (opzionale) per tissue
1761126102871:setorder(counts, cluster, tissue)
1761126119779:integration_dt <- read.csv("project_oct25/annotated_GSM3516673_normal_annotated_GSM3516672_tumor_SeuratIntegration.csv")
1761126119800:clustering_dt  <- read.csv("project_oct25/nt_combined_clustering.output.csv")
1761126119817:normalize_cell_id <- function(x) {
1761126119817:x <- trimws(as.character(x))
1761126119818:x <- gsub("_X_|_Y_", "_", x)
1761126119819:x <- gsub("_\\.", ".", x)
1761126119819:x
1761126119820:}
1761126119821:integration_dt$cell_clean <- normalize_cell_id(integration_dt$cell)
1761126119847:clustering_dt$cell_clean  <- normalize_cell_id(clustering_dt$cell)
1761126119867:combined <- merge(integration_dt, clustering_dt, by = "cell_clean")
1761126119899:counts_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1761126119899:data = combined, FUN = length)
1761126119909:names(counts_cluster_celltype)[3] <- "cell_count"
1761126119911:tab_ct_st <- aggregate(cell_clean ~ integration_cluster + cell_type + sample_type,
1761126119912:data = combined, FUN = length)
1761126119930:names(tab_ct_st)[4] <- "cell_count"
1761126119931:totals_cluster <- aggregate(cell_clean ~ integration_cluster, data = combined, FUN = length)
1761126119938:names(totals_cluster)[2] <- "cluster_total_cells"
1761126119939:tab_ct_st <- merge(tab_ct_st, totals_cluster, by = "integration_cluster")
1761126119942:tab_ct_st$pct_within_cluster <- (tab_ct_st$cell_count / tab_ct_st$cluster_total_cells) * 100
1761126119943:totals_cluster_celltype <- aggregate(cell_clean ~ integration_cluster + cell_type,
1761126119944:data = combined, FUN = length)
1761126119953:names(totals_cluster_celltype)[3] <- "cluster_celltype_total"
1761126119954:tab_ct_st <- merge(tab_ct_st, totals_cluster_celltype,
1761126119955:by = c("integration_cluster", "cell_type"))
1761126119958:tab_ct_st$pct_within_cluster_celltype <- (tab_ct_st$cell_count /
1761126119959:tab_ct_st$cluster_celltype_total) * 100
1761126535723:# ----------------------------------------------------------
1761126535728:# TASK 1 – Merge, filter, summarize, and compute per-condition means
1761126535732:# ----------------------------------------------------------
1761126535734:bulk_counts_summary_df <- function(counts_path, meta_path) {
1761126535735:# 1. Import
1761126535736:counts <- read.csv(counts_path)
1761126535747:meta   <- read.csv(meta_path)
1761126535753:# 2. Join counts + metadata by sample_id
1761126535759:merged_data <- merge(counts, meta, by = "sample_id")
1761126535765:# 3. Filter for treated samples and GENE_00* genes
1761126535769:treated_data <- subset(merged_data,
1761126535771:condition == "treated" & grepl("^GENE_00", gene))
1761126535774:# 4. Compute mean and median per gene
1761126535776:gene_summary <- aggregate(
1761126535777:count ~ gene,
1761126535779:data = treated_data,
1761126535781:FUN  = function(x) c(mean = mean(x), median = median(x))
1761126535784:)
1761126535789:# 5. Simplify format
1761126535793:gene_summary_df <- data.frame(
1761126535796:gene = gene_summary$gene,
1761126535817:mean_count   = gene_summary$count[, "mean"],
1761126535818:median_count = gene_summary$count[, "median"]
1761126535820:)
1761126535854:# 6 Calcolo della media dei conteggi per ciascun gene e condizione
1761126535855:# aggregate() calcola una funzione (mean) per gruppi
1761126535857:gene_condition_means_f <- aggregate(
1761126535859:count ~ gene + condition,   # formula: raggruppa per gene e condition
1761126535860:data = merged_data,         # tabella di partenza
1761126535861:FUN = mean,                 # funzione da applicare
1761126535862:na.rm = TRUE                # ignora eventuali valori mancanti
1761126535863:)
1761126535865:# 7 Ordina i risultati per gene e condition (per leggibilità)
1761126535866:gene_condition_means_f <- gene_condition_means_f[order(gene_condition_means_f$gene,
1761126535867:gene_condition_means_f$condition), ]
1761126535869:}
1761126537750:# ----------------------------------------------------------
1761126537753:# TASK 2 – Add log2(count + 1) and binary flags
1761126537755:# ----------------------------------------------------------
1761126537756:bulk_counts_qc_df <- function(counts_path) {
1761126537758:# 1. Import
1761126537759:counts <- read.csv(counts_path)
1761126537761:# 2. Add log2(count + 1) column
1761126537762:counts$log2_count <- log2(counts$count + 1)
1761126537765:# 3. Add binary flag 'high' (count > 100)
1761126537766:counts$high <- counts$count > 100
1761126537769:# 4. Overwrite 'high' using gene-wise median threshold
1761126537770:#    Qui usiamo tapply() per calcolare la mediana per gene,
1761126537773:#    poi combiniamo i risultati in un vettore logico della stessa lunghezza
1761126537775:medians_by_gene <- tapply(counts$count, counts$gene, median)
1761126537777:counts$high <- counts$count > medians_by_gene[counts$gene]
1761126537782:}
1761126539306:#-----------------------------------------------------------
1761126541500:#-----------------------------------------------------------
1761126541505:#Task 3 non ha la funzione perchè ha senso solo in data.table
1761126541508:#-----------------------------------------------------------
1761126543259:# ----------------------------------------------------------
1761126544007:# ----------------------------------------------------------
1761126544011:# TASK 4 – Filter genes by thresholded normalized expression
1761126544012:# ----------------------------------------------------------
1761126545657:counts <- read.csv(counts_path)
1761126609308:# ----------------------------------------------------------
1761126609312:# TASK 4 – Filter genes by thresholded normalized expression
1761126609325:# ----------------------------------------------------------
1761126609326:annotate_counts_df <- function(counts_path, meta_path) {
1761126615400:# ----------------------------------------------------------
1761126615901:# ----------------------------------------------------------
1761126615906:# TASK 4 – Filter genes by thresholded normalized expression
1761126615907:# ----------------------------------------------------------
1761126616517:counts <- read.csv(counts_path)
1761126618058:meta   <- read.csv(meta_path, stringsAsFactors = FALSE)
1761126618559:# 2. Join
1761126618563:merged_data <- merge(counts, meta, by = "sample_id")
1761126630872:# ----------------------------------------------------------
1761126630875:# TASK 4 – Filter genes by thresholded normalized expression
1761126630877:# ----------------------------------------------------------
1761126630879:annotate_counts_df <- function(counts_path, meta_path) {
1761126630881:counts <- read.csv(counts_path)
1761126630882:meta   <- read.csv(meta_path, stringsAsFactors = FALSE)
1761126630884:# 2. Join
1761126630885:merged_data <- merge(counts, meta, by = "sample_id")
1761126630887:# 3. Total counts per patient
1761126630888:patient_totals <- aggregate(count ~ patient_id, data = merged_data, FUN = sum)
1761126630889:names(patient_totals)[2] <- "total_count"
1761126630891:# 4. Mean count per gene and condition
1761126630892:gene_means <- aggregate(count ~ gene + condition, data = merged_data, FUN = mean)
1761126630893:names(gene_means)[3] <- "mean_count"
1761126630894:# 5. Top 10 genes by condition
1761126630895:conditions <- unique(gene_means$condition)
1761126630896:top10_by_condition <- data.frame()
1761126630899:for (cond in conditions) {
1761126630900:subset_cond <- subset(gene_means, condition == cond)
1761126630901:subset_cond <- subset_cond[order(-subset_cond$mean_count), ]
1761126630902:top10 <- head(subset_cond, 10)
1761126630903:top10_by_condition <- rbind(top10_by_condition, top10)
1761126630904:}
1761126635085:# ----------------------------------------------------------
1761126635087:# TASK 4 – Filter genes by thresholded normalized expression
1761126635088:# ----------------------------------------------------------
1761126635089:annotate_counts_df <- function(counts_path, meta_path) {
1761126635090:counts <- read.csv(counts_path)
1761126635091:meta   <- read.csv(meta_path, stringsAsFactors = FALSE)
1761126635093:# 2. Join
1761126635094:merged_data <- merge(counts, meta, by = "sample_id")
1761126635095:# 3. Total counts per patient
1761126635096:patient_totals <- aggregate(count ~ patient_id, data = merged_data, FUN = sum)
1761126635098:names(patient_totals)[2] <- "total_count"
1761126635101:# 4. Mean count per gene and condition
1761126635103:gene_means <- aggregate(count ~ gene + condition, data = merged_data, FUN = mean)
1761126635103:names(gene_means)[3] <- "mean_count"
1761126635105:# 5. Top 10 genes by condition
1761126635106:conditions <- unique(gene_means$condition)
1761126635107:top10_by_condition <- data.frame()
1761126635109:for (cond in conditions) {
1761126635110:subset_cond <- subset(gene_means, condition == cond)
1761126635111:subset_cond <- subset_cond[order(-subset_cond$mean_count), ]
1761126635112:top10 <- head(subset_cond, 10)
1761126635113:top10_by_condition <- rbind(top10_by_condition, top10)
1761126635114:}
1761126672783:# ----------------------------------------------------------
1761126672787:# TASK 4 – Filter genes by thresholded normalized expression
1761126672789:# ----------------------------------------------------------
1761126672791:annotate_counts_df <- function(counts_path, meta_path) {
1761126672792:counts <- read.csv(counts_path)
1761126672794:meta   <- read.csv(meta_path, stringsAsFactors = FALSE)
1761126672796:# 2. Join
1761126672798:merged_data <- merge(counts, meta, by = "sample_id")
1761126672800:# 3. Total counts per patient
1761126672801:patient_totals <- aggregate(count ~ patient_id, data = merged_data, FUN = sum)
1761126672802:names(patient_totals)[2] <- "total_count"
1761126672805:# 4. Mean count per gene and condition
1761126672807:gene_means <- aggregate(count ~ gene + condition, data = merged_data, FUN = mean)
1761126672810:names(gene_means)[3] <- "mean_count"
1761126672813:# 5. Top 10 genes by condition
1761126672815:conditions <- unique(gene_means$condition)
1761126672819:top10_by_condition <- data.frame()
1761126672824:for (cond in conditions) {
1761126672827:subset_cond <- subset(gene_means, condition == cond)
1761126672828:subset_cond <- subset_cond[order(-subset_cond$mean_count), ]
1761126672829:top10 <- head(subset_cond, 10)
1761126672830:top10_by_condition <- rbind(top10_by_condition, top10)
1761126672832:}
1761126672833:}
1761126673529:# ----------------------------------------------------------
1761126673533:# TASK 5 – Summary table by condition and gene class
1761126673535:# ----------------------------------------------------------
1761126673536:classify_labs_df <- function(counts_path, meta_path) {
1761126673538:counts <- read.csv(counts_path)
1761126673539:meta   <- read.csv(meta_path)
1761126673542:merged <- merge(counts, meta, by = "sample_id")
1761126673545:merged$gene_class <- ifelse(grepl("^GENE_00", merged$gene), "A", "B")
1761126673550:summary_df <- aggregate(count ~ condition + gene_class,
1761126673552:data = merged,
1761126673554:FUN = mean)
1761126673557:return(summary_df)
1761126673560:}
1761126674008:# ----------------------------------------------------------
1761126674012:# TASK 6 – Compute fold change between treated and control
1761126674014:# ----------------------------------------------------------
1761126674017:match_vitals_df <- function(counts_path, meta_path) {
1761126674018:counts <- read.csv(counts_path)
1761126674020:meta   <- read.csv(meta_path)
1761126674023:merged <- merge(counts, meta, by = "sample_id")
1761126674026:means <- aggregate(count ~ gene + condition, data = merged, mean)
1761126674028:spread <- reshape(means, timevar = "condition", idvar = "gene", direction = "wide")
1761126674030:spread$fold_change <- spread$count.treated / spread$count.control
1761126674034:return(spread)
1761126674035:}
1761126686282:annotate_counts_df <- function(counts_path, meta_path) {
1761126686285:counts <- read.csv(counts_path)
1761126686286:meta   <- read.csv(meta_path, stringsAsFactors = FALSE)
1761126686292:# 2. Join
1761126686295:merged_data <- merge(counts, meta, by = "sample_id")
1761126686300:# 3. Total counts per patient
1761126686302:patient_totals <- aggregate(count ~ patient_id, data = merged_data, FUN = sum)
1761126686303:names(patient_totals)[2] <- "total_count"
1761126686305:# 4. Mean count per gene and condition
1761126686307:gene_means <- aggregate(count ~ gene + condition, data = merged_data, FUN = mean)
1761126686308:names(gene_means)[3] <- "mean_count"
1761126686312:# 5. Top 10 genes by condition
1761126686313:conditions <- unique(gene_means$condition)
1761126686315:top10_by_condition <- data.frame()
1761126686317:for (cond in conditions) {
1761126686318:subset_cond <- subset(gene_means, condition == cond)
1761126686319:subset_cond <- subset_cond[order(-subset_cond$mean_count), ]
1761126686320:top10 <- head(subset_cond, 10)
1761126686321:top10_by_condition <- rbind(top10_by_condition, top10)
1761126686323:}
1761126686324:}
1761126706539:# ----------------------------------------------------------
1761126706544:# TASK 4 – Filter genes by thresholded normalized expression
1761126706546:# ----------------------------------------------------------
1761126706549:annotate_counts_df <- function(counts_path, meta_path) {
1761126706550:counts <- read.csv(counts_path)
1761126706552:meta   <- read.csv(meta_path, stringsAsFactors = FALSE)
1761126706558:# 2. Join
1761126706562:merged_data <- merge(counts, meta, by = "sample_id")
1761126706570:# 3. Total counts per patient
1761126706572:patient_totals <- aggregate(count ~ patient_id, data = merged_data, FUN = sum)
1761126706575:names(patient_totals)[2] <- "total_count"
1761126706579:# 4. Mean count per gene and condition
1761126706581:gene_means <- aggregate(count ~ gene + condition, data = merged_data, FUN = mean)
1761126706582:names(gene_means)[3] <- "mean_count"
1761126706585:# 5. Top 10 genes by condition
1761126706587:conditions <- unique(gene_means$condition)
1761126706588:top10_by_condition <- data.frame()
1761126706590:for (cond in conditions) {
1761126706592:subset_cond <- subset(gene_means, condition == cond)
1761126706594:subset_cond <- subset_cond[order(-subset_cond$mean_count), ]
1761126706595:top10 <- head(subset_cond, 10)
1761126706597:top10_by_condition <- rbind(top10_by_condition, top10)}
1761126706599:}
1761126856307:# ----------------------------------------------------------
1761126856311:# TASK 5 – Summary table by condition and gene class
1761126856313:# ----------------------------------------------------------
1761126856316:classify_labs_df <- function(counts_path, meta_path) {
1761126856318:# 2. Keep unique reference intervals
1761126856320:ref_unique <- unique(ref[, c("lab", "lower", "upper")])
1761126856323:# 3. Join
1761126856325:merged_labs <- merge(labs, ref_unique, by = "lab")
1761126856328:# 4. Classify as normal/out_of_range
1761126856331:merged_labs$status <- ifelse(merged_labs$value >= merged_labs$lower &
1761126856335:merged_labs$value <= merged_labs$upper,
1761126856339:"normal", "out_of_range")
1761126856346:# 5. Summaries
1761126856348:abnormal_by_patient <- aggregate(status ~ patient_id, data = merged_labs,
1761126856351:FUN = function(x) {
1761126856353:total <- length(x)
1761126856355:out   <- sum(x == "out_of_range")
1761126856356:c(total_tests = total, out_of_range = out)
1761126856357:})
1761126856360:# split matrix-like column into two numeric columns
1761126856361:abnormal_by_patient$total_tests  <- abnormal_by_patient$status[, "total_tests"]
1761126856363:abnormal_by_patient$out_of_range <- abnormal_by_patient$status[, "out_of_range"]
1761126856365:abnormal_by_patient$status <- NULL
1761126856370:abnormal_by_lab <- aggregate(status ~ lab, data = merged_labs,
1761126856373:FUN = function(x) {
1761126856375:total <- length(x)
1761126856377:out   <- sum(x == "out_of_range")
1761126856378:c(total_tests = total, out_of_range = out)
1761126856379:})
1761126856381:abnormal_by_lab$total_tests  <- abnormal_by_lab$status[, "total_tests"]
1761126856382:abnormal_by_lab$out_of_range <- abnormal_by_lab$status[, "out_of_range"]
1761126856384:abnormal_by_lab$status <- NULL
1761126856386:}
1761126857175:# ----------------------------------------------------------
1761126857182:# TASK 6 – Compute fold change between treated and control
1761126857185:# ----------------------------------------------------------
1761126857187:match_vitals_df <- function(counts_path, meta_path) {
1761126857189:counts <- read.csv(counts_path)
1761126857191:meta   <- read.csv(meta_path)
1761126857197:merged <- merge(counts, meta, by = "sample_id")
1761126857206:means <- aggregate(count ~ gene + condition, data = merged, mean)
1761126857210:spread <- reshape(means, timevar = "condition", idvar = "gene", direction = "wide")
1761126857212:spread$fold_change <- spread$count.treated / spread$count.control
1761126857218:return(spread)
1761126857220:}
1761126917658:# ----------------------------------------------------------
1761126917664:# TASK 5 – Summary table by condition and gene class
1761126917666:# ----------------------------------------------------------
1761126917668:classify_labs_df <- function(labs_path, ref_path) {
1761126917670:# 1. Import
1761126917672:labs <- read.csv(labs_path)
1761126917674:ref  <- read.csv(ref_path)
1761126917678:# 2. Keep unique reference intervals
1761126917681:ref_unique <- unique(ref[, c("lab", "lower", "upper")])
1761126917689:# 3. Join
1761126917693:merged_labs <- merge(labs, ref_unique, by = "lab")
1761126917699:# 4. Classify as normal/out_of_range
1761126917702:merged_labs$status <- ifelse(merged_labs$value >= merged_labs$lower &
1761126917706:merged_labs$value <= merged_labs$upper,
1761126917708:"normal", "out_of_range")
1761126917711:# 5. Summaries
1761126917712:abnormal_by_patient <- aggregate(status ~ patient_id, data = merged_labs,
1761126917714:FUN = function(x) {
1761126917716:total <- length(x)
1761126917718:out   <- sum(x == "out_of_range")
1761126917721:c(total_tests = total, out_of_range = out)
1761126917723:})
1761126917726:# split matrix-like column into two numeric columns
1761126917728:abnormal_by_patient$total_tests  <- abnormal_by_patient$status[, "total_tests"]
1761126917730:abnormal_by_patient$out_of_range <- abnormal_by_patient$status[, "out_of_range"]
1761126917732:abnormal_by_patient$status <- NULL
1761126917734:abnormal_by_lab <- aggregate(status ~ lab, data = merged_labs,
1761126917736:FUN = function(x) {
1761126917738:total <- length(x)
1761126917740:out   <- sum(x == "out_of_range")
1761126917741:c(total_tests = total, out_of_range = out)
1761126917742:})
1761126917744:abnormal_by_lab$total_tests  <- abnormal_by_lab$status[, "total_tests"]
1761126917746:abnormal_by_lab$out_of_range <- abnormal_by_lab$status[, "out_of_range"]
1761126917747:abnormal_by_lab$status <- NULL
1761126917751:}
1761126918501:# ----------------------------------------------------------
1761126918505:# TASK 6 – Compute fold change between treated and control
1761126918510:# ----------------------------------------------------------
1761126918513:match_vitals_df <- function(counts_path, meta_path) {
1761126918517:counts <- read.csv(counts_path)
1761126918521:meta   <- read.csv(meta_path)
1761126918528:merged <- merge(counts, meta, by = "sample_id")
1761126918536:means <- aggregate(count ~ gene + condition, data = merged, mean)
1761126918539:spread <- reshape(means, timevar = "condition", idvar = "gene", direction = "wide")
1761126918542:spread$fold_change <- spread$count.treated / spread$count.control
1761126918547:return(spread)
1761126918548:}
1761126971964:# ----------------------------------------------------------
1761126971970:# TASK 6 – Compute fold change between treated and control
1761126971972:# ----------------------------------------------------------
1761126971974:match_vitals_df <- function(labs_path, vitals_path) {
1761126971976:# 1. Import
1761126971978:labs   <- read.csv(labs_path)
1761126971980:vitals <- read.csv(vitals_path)
1761126971985:# 2. Convert to POSIXct
1761126971990:labs$time_iso   <- as.POSIXct(labs$time_iso)
1761126971997:vitals$time_iso <- as.POSIXct(vitals$time_iso)
1761126972003:# 3. Join nearest HR/SBP manually (loop-based)
1761126972007:nearest_match <- function(lab_df, vitals_df, vital_type) {
1761126972009:vitals_sub <- vitals_df[vitals_df$vital == vital_type, ]
1761126972011:results <- list()
1761126972013:for (i in seq_len(nrow(lab_df))) {
1761126972014:pid <- lab_df$patient_id[i]
1761126972016:time <- lab_df$time_iso[i]
1761126972017:v_sub <- vitals_sub[vitals_sub$patient_id == pid, ]
1761126972019:if (nrow(v_sub) > 0) {
1761126972020:idx <- which.min(abs(difftime(v_sub$time_iso, time, units = "mins")))
1761126972022:results[[i]] <- v_sub[idx, c("value", "time_iso")]
1761126972024:} else {
1761126972027:results[[i]] <- data.frame(value = NA, time_iso = NA)
1761126972030:}
1761126972032:}
1761126972034:out <- do.call(rbind, results)
1761126972036:names(out) <- c(paste0("nearest_", vital_type), paste0(vital_type, "_time"))
1761126972037:return(out)
1761126972038:}
1761126972042:# 4. Attach nearest HR and SBP
1761126972043:hr_data  <- nearest_match(labs, vitals, "HR")
1761126972045:sbp_data <- nearest_match(labs, vitals, "SBP")
1761126972048:labs_with_vitals <- cbind(labs, hr_data, sbp_data)
1761126972049:labs_with_vitals$hr_lag_minutes  <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$HR_time, units = "mins"))
1761126972050:labs_with_vitals$sbp_lag_minutes <- as.numeric(difftime(labs_with_vitals$time_iso, labs_with_vitals$SBP_time, units = "mins"))
1761126972053:# 5. Correlation per patient (CRP only) — robust version in base R
1761126972054:crp_data <- subset(labs_with_vitals, lab == "CRP")
1761126972057:# Split by patient_id
1761126972058:patients_list <- split(crp_data, crp_data$patient_id)
1761126972061:# Function to compute correlation safely
1761126972063:safe_cor <- function(df, col_x = "value", col_y = "nearest_HR") {
1761126972064:if (nrow(df) < 2) return(NA_real_)           # meno di 2 osservazioni -> NA
1761126972065:x <- df[[col_x]]
1761126972067:y <- df[[col_y]]
1761126972068:# keep only pairs non-NA
1761126972069:ok <- !is.na(x) & !is.na(y)
1761126972070:if (sum(ok) < 2) return(NA_real_)            # meno di 2 coppie valide -> NA
1761126972072:return(cor(x[ok], y[ok], use = "complete.obs"))
1761126972073:}
1761126972076:# Calcola correlazione CRP vs HR per ogni paziente
1761126972077:cor_crp_hr <- data.frame(
1761126972079:patient_id = names(patients_list),
1761126972080:correlation_CRP_HR = sapply(patients_list, safe_cor, col_x = "value", col_y = "nearest_HR"),
1761126972081:row.names = NULL,
1761126972083:stringsAsFactors = FALSE
1761126972084:)
1761126972086:# Calcola correlazione CRP vs SBP per ogni paziente
1761126972088:cor_crp_sbp <- data.frame(
1761126972089:patient_id = names(patients_list),
1761126972091:correlation_CRP_SBP = sapply(patients_list, safe_cor, col_x = "value", col_y = "nearest_SBP"),
1761126972092:row.names = NULL,
1761126972093:stringsAsFactors = FALSE
1761126972095:)
1761126972096:}
1761127588809:devtools::document()
1761127597532:devtools::load_all()
1761128209364:devtools::document()
1761128215235:devtools::document()
1761128262239:library(data.table)
1761128262250:# ==========================================================
1761128262252:# 🧩 TASK 1 — Bulk RNA counts summary
1761128262255:# ==========================================================
1761128262262:#' Summarize bulk RNA counts with metadata (data.table version)
1761128262263:#'
1761128262265:#' Merges bulk RNA-seq count data with sample metadata, filters treated samples
1761128262267:#' whose gene names start with "GENE_00", and computes mean/median counts per gene,
1761128262269:#' as well as per-condition mean counts.
1761128262270:#'
1761128262272:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128262274:#' @param meta_path Path to CSV file with columns: sample_id, condition, batch, patient ID, timepoint.
1761128262277:#' @return List with: filtered_data, gene_mean_median, gene_condition_means
1761128262279:#' \itemize{
1761128262280:#'   \item gene_mean_median: Mean and median counts by gene (treated only)
1761128262282:#'   \item gene_condition_means: Mean counts by gene and condition
1761128262283:#' }
1761128262285:#' @export
1761128262287:bulk_counts_summary_dt <- function(counts_path, meta_path) {
1761128262288:bulk_counts <- fread(counts_path)
1761128262290:sample_meta <- fread(meta_path)
1761128262294:setkey(bulk_counts, sample_id)
1761128262296:setkey(sample_meta, sample_id)
1761128262298:join_data <- bulk_counts[sample_meta, nomatch = 0]
1761128262301:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1761128262304:gene_mean_median <- filtered_data[, .(
1761128262306:mean_count   = mean(count),
1761128262307:median_count = median(count)
1761128262312:), by = gene]
1761128262315:gene_condition_means <- bulk_counts[
1761128262317:sample_meta,
1761128262318:on = "sample_id"
1761128262320:][ , .(
1761128262322:mean_count = mean(count)
1761128262323:), by = .(gene, condition) ]
1761128262329:return(list(filtered_data = filtered_data, gene_mean_median = gene_mean_median, gene_condition_means = gene_condition_means))
1761128262332:}
1761128262335:# ==========================================================
1761128262337:# 🧩 TASK 2 — QC-style derived columns
1761128262339:# ==========================================================
1761128262344:#' Add QC-style derived columns (data.table version)
1761128262345:#'
1761128262347:#' Adds log2-transformed counts and a binary \code{high} flag based on gene-wise medians.
1761128262348:#'
1761128262350:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128262352:#' @return Data.table with added columns: log2_count, high.
1761128262354:bulk_counts_qc_dt <- function(counts_path) {
1761128262355:counts <- fread(counts_path)
1761128262357:counts[, log2_count := log2(count)]
1761128262359:counts[, high := count > 100]
1761128262362:counts[, high := count > median(count), by = gene]
1761128262365:return(counts)
1761128262366:}
1761128262370:# ==========================================================
1761128262372:# 🧩 TASK 3 — Subset by gene and sample
1761128262373:# ==========================================================
1761128262378:#' Subset counts data using secondary index
1761128262380:#'
1761128262381:#' Joins metadata and subsets for a specific gene and sample using fast indexing.
1761128262383:#'
1761128262385:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128262387:#' @param meta_path Path to CSV file with columns: sample_id, condition, batch, patient ID, timepoint.
1761128262388:#' @param gene_name Gene name to subset
1761128262390:#' @param sample_chosen Sample ID to subset
1761128262393:#' @return Subset of counts for the given gene and sample.
1761128262395:#' @export
1761128262396:subset_counts_dt <- function(counts_path, meta_path, gene_call, sample_chosen) {
1761128262398:bulk_counts <- fread(counts_path)
1761128262399:sample_meta <- fread(meta_path)
1761128262402:setkey(sample_meta, sample_id)
1761128262405:join_data <- sample_meta[bulk_counts, on = "sample_id"]
1761128262407:time_no_index <- system.time({
1761128262410:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1761128262412:})
1761128262415:setindex(bulk_counts, gene, sample_id)
1761128262418:time_with_index <- system.time({
1761128262419:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1761128262421:})
1761128262424:dt_benchmark <- data.table(
1761128262427:test = c("time_no_index", "time_with_index"),
1761128262429:user = c(time_no_index["user.self"], time_with_index["user.self"]),
1761128262430:system = c(time_no_index["sys.self"], time_with_index["sys.self"]),
1761128262432:elapsed = c(time_no_index["elapsed"], time_with_index["elapsed"])
1761128262433:)
1761128262436:return(dt_benchmark)
1761128262438:}
1761128262440:# ==========================================================
1761128262443:# 🧩 TASK 4 — Annotate counts and summarize
1761128262445:# ==========================================================
1761128262448:#' Annotate counts with metadata and compute summaries
1761128262449:#'
1761128262451:#' Joins counts and metadata, computes per-patient total counts,
1761128262453:#' mean counts per gene and condition, and identifies top 10 genes.
1761128262454:#'
1761128262456:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128262457:#' @param meta_path Path to CSV file with columns: sample_id, condition, batch, patient ID, timepoint.
1761128262459:#' @return List with patient totals, and top10 genes.
1761128262462:annotate_counts_dt <- function(counts_path, meta_path) {
1761128262465:bulk_counts <- fread(counts_path)
1761128262466:sample_meta <- fread(meta_path)
1761128262471:setkey(bulk_counts, sample_id)
1761128262472:setkey(sample_meta, sample_id)
1761128262474:join_data <- bulk_counts[sample_meta, nomatch = 0]
1761128262480:patient_tot <- join_data[, .(total_count = sum(count)), by = patient_id]
1761128262484:gene_means <- join_data[, .(mean_count = mean(count)), by = .(gene, condition)]
1761128262489:top10 <- gene_means[
1761128262490:order(condition, -mean_count)
1761128262494:][, head(.SD, 10), by = condition]
1761128262499:return(list(patient_tot = patient_tot, top10 = top10))
1761128262500:}
1761128262503:# ==========================================================
1761128262505:# 🧩 TASK 5 — Classify lab values
1761128262506:# ==========================================================
1761128262511:#' Classify lab values against reference intervals
1761128262513:#'
1761128262514:#' Joins lab results and reference ranges, classifies as "normal" or "out_of_range",
1761128262516:#' and summarizes abnormalities per patient and per lab.
1761128262517:#'
1761128262519:#' @param labs_path Path to CSV file with columns: patient_id, time_iso, lab, value.
1761128262521:#' @param ref_path Path to CSV file with columns: lab, sex,lower, upper.
1761128262522:#' @return List with merged_labs, abnormal_by_patient, abnormal_by_lab.
1761128262524:classify_labs_dt <- function(labs_path, ref_path) {
1761128262529:labs <- fread(labs_path)
1761128262530:ref  <- fread(ref_path)
1761128262533:ref_unique <- unique(ref[, .(lab, lower, upper)])
1761128262537:merged_labs <- merge(labs, ref_unique, by = "lab")
1761128262540:merged_labs[, status := ifelse(value >= lower & value <= upper, "normal", "out_of_range")]
1761128262545:abnormal_by_patient <- merged_labs[, .(
1761128262547:total_tests = .N,
1761128262549:out_of_range = sum(status == "out_of_range")
1761128262550:), by = patient_id]
1761128262554:abnormal_by_lab <- merged_labs[, .(
1761128262556:total_tests = .N,
1761128262557:out_of_range = sum(status == "out_of_range")
1761128262560:), by = lab]
1761128262564:return(list(merged_labs = merged_labs, abnormal_by_patient = abnormal_by_patient, abnormal_by_lab = abnormal_by_lab))
1761128262565:}
1761128262569:# ==========================================================
1761128262571:# 🧩 TASK 6 — Match vitals to labs
1761128262572:# ==========================================================
1761128262578:#' Nearest-time matching of vitals and labs
1761128262579:#'
1761128262581:#' Matches nearest HR/SBP readings to each lab time and computes correlations.
1761128262582:#'
1761128262584:#' @param labs_path Path to CSV file with columns: patient_id, time_iso, lab, value.
1761128262586:#' @param vitals_path Path to CSV file with columns: time_iso
1761128262588:#' @return List with labs_with_vitals and correlations (CRP vs HR/SBP)
1761128262589:#' @export
1761128262591:match_vitals_dt <- function(labs_path, vitals_path) {
1761128262595:labs <- fread(labs_path)
1761128262597:vitals <- fread(vitals_path)
1761128262600:labs[, time_iso := as.POSIXct(time_iso)]
1761128262602:vitals[, time_iso := as.POSIXct(time_iso)]
1761128262605:setorder(labs, patient_id, time_iso)
1761128262607:setorder(vitals, patient_id, time_iso)
1761128262613:labs[, lab_time := time_iso]
1761128262615:setkey(labs, patient_id, time_iso)
1761128262617:setkey(vitals, patient_id, time_iso)
1761128262625:vitals_hr <- vitals[vital == "HR", .(patient_id, time_iso, value)]
1761128262629:setnames(vitals_hr, "value", "nearest_HR")
1761128262634:vitals_hr[, hr_time := time_iso]
1761128262637:setkey(vitals_hr, patient_id, time_iso)
1761128262644:labs_with_hr <- vitals_hr[labs, roll = "nearest"]
1761128262654:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1761128262669:vitals_sbp <- vitals[vital == "SBP", .(patient_id, time_iso, value)]
1761128262671:setnames(vitals_sbp, "value", "nearest_SBP")
1761128262679:vitals_sbp[, sbp_time := time_iso]
1761128262683:setkey(vitals_sbp, patient_id, time_iso)
1761128262688:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1761128262692:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1761128262703:crp_data <- labs_with_vitals[lab == "CRP"]
1761128262715:cor_crp_hr <- crp_data[!is.na(nearest_HR), .(
1761128262718:correlation_CRP_HR = cor(value, nearest_HR, use = "complete.obs")
1761128262721:), by = patient_id]
1761128262731:cor_crp_sbp <- crp_data[!is.na(nearest_SBP), .(
1761128262734:correlation_CRP_SBP = cor(value, nearest_SBP, use = "complete.obs")
1761128262736:), by = patient_id]
1761128262745:return(list(labs_with_hr = labs_with_hr, labs_with_vitals=labs_with_vitals, cor_crp_hr = cor_hr, cor_crp_sbp = cor_sbp))
1761128262749:}
1761128262767:# ==========================================================
1761128262882:# 🧩 TASK 7 — Top peaks by score
1761128262887:# ==========================================================
1761128262911:#' Extract peaks on chromosome and return top N by score
1761128262913:#'
1761128262916:#' Filters by genomic region and selects top peaks by score.
1761128262920:#'
1761128262922:#' @param peaks_path Path to CSV file with columns:chr, start, end, peak_id, score
1761128262927:#' @param chr_sel selected chromosome string e.g.:"chr2"
1761128262929:#' @param start_min lower bound of range e.g.:2000000
1761128262932:#' @param start_max upper bound of range e.g.:4000000
1761128262935:#' @return Data.table of top peaks
1761128262988:#' @export
1761128262991:top_peaks_dt <- function(peaks_dt, chr_sel, start_min , start_max) {
1761128262999:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1761128263004:subset_peaks <- peaks[chr == chr_sel & start >= start_min & start <= start_max]
1761128263012:subset_peaks <- setorder(subset_peaks, -score)
1761128263017:top50_peaks <- head(subset_peaks, 50)
1761128263051:return(top50_peaks)
1761128263058:}
1761128263065:# ==========================================================
1761128263067:# 🧩 TASK 8 — Gene stats and filtering
1761128263071:# ==========================================================
1761128263078:#' Per-condition robust summary stats and gene filtering
1761128263080:#'
1761128263083:#' Computes mean, median, quartiles by gene and condition,
1761128263089:#' filters genes with treated_mean ≥ 2 × control_mean.
1761128263092:#'
1761128263097:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128263099:#' @param meta_path Path to CSV file with columns: sample_id, condition, batch, patient ID, timepoint.
1761128263105:#' @return List with stats_by_gene_condition and kept_genes
1761128263114:gene_stats_filter_dt <- function(counts_path, meta_path) {
1761128263117:counts <- fread(counts_path)
1761128263120:meta   <- fread(meta_path)
1761128263131:merged <- counts[meta, on = "sample_id"]
1761128263141:stats_by_gene_condition <- merged[, .(
1761128263146:mean_count   = mean(count),
1761128263148:median_count = median(count),
1761128263153:Q1           = quantile(count, 0.25, type = 2),
1761128263155:Q3           = quantile(count, 0.75, type = 2)
1761128263157:), by = .(gene, condition)]
1761128263166:treated_means <- stats_by_gene_condition[condition == "treated", .(gene, treated_mean = mean_count)]
1761128263169:control_means <- stats_by_gene_condition[condition == "control", .(gene, control_mean = mean_count)]
1761128263174:means_wide <- merge(treated_means, control_means, by = "gene", all = FALSE)
1761128263179:kept_genes <- means_wide[treated_mean >= 2 * control_mean]
1761128263184:return(list(stats_by_gene_condition = stats_by_gene_condition, kept_genes = kept_genes))
1761128263186:}
1761128263191:# ==========================================================
1761128263194:# 🧩 TASK 9 — Wide → Long → Wide
1761128263197:# ==========================================================
1761128263201:#' Convert wide counts to long and back, computing mean per condition
1761128263203:#'
1761128263206:#' @param counts_wide_path Path to CSV file with columns genes and samples
1761128263208:#' @return Data.table wide by condition with mean counts
1761128263214:wide_long_wide_dt <- function(counts_wide_path) {
1761128263218:counts_wide <- fread(counts_wide_path)
1761128263222:counts_long <- melt(counts_wide, id.vars = "gene",
1761128263224:variable.name = "sample_id", value.name = "count")
1761128263230:meta <- fread("project_oct25/sample_metadata.csv")
1761128263234:merged <- merge(counts_long, meta, by = "sample_id")
1761128263239:totals_per_sample <- merged[, .(total_count = sum(count)), by = sample_id]
1761128263244:merged <- merge(merged, totals_per_sample, by = "sample_id")
1761128263248:gene_condition_means <- merged[, .(mean_count = mean(count)),
1761128263250:by = .(gene, condition)]
1761128263254:counts_condition_wide <- dcast(gene_condition_means,
1761128263257:gene ~ condition,
1761128263260:value.var = "mean_count")
1761128263263:return(counts_condition_wide)
1761128263265:}
1761128263269:# ==========================================================
1761128263271:# 🧩 TASK 10 — ATAC peaks to genes
1761128263274:# ==========================================================
1761128263281:#' Map ATAC peaks to genes and summarize overlaps
1761128263284:#'
1761128263286:#' Uses genomic overlap to assign peaks to genes and compute overlap statistics.
1761128263288:#'
1761128263291:#' @param peaks_path Path to CSV file with columns: chr, start, end, peak_id, score
1761128263295:#' @param genes_path Path to CSV file with columns: chr, start, end, gene
1761128263297:#' @return List with overlap tables, peaks_per_gene and top 20 genes by overlap
1761128263301:atac_to_gene_dt <- function(peaks_path, genes_path) {
1761128263306:peaks <- fread(peaks_path)
1761128263311:genes <- fread(genes_path)
1761128263316:setkey(peaks, chr, start, end)
1761128263318:setkey(genes, chr, start, end)
1761128263324:overlaps <- foverlaps(peaks, genes,
1761128263328:by.x = c("chr", "start", "end"),
1761128263331:by.y = c("chr", "start", "end"),
1761128263333:type = "any", nomatch = 0L)
1761128263339:overlaps[, overlap_bp := pmin(end, i.end) - pmax(start, i.start)]
1761128263344:overlaps <- overlaps[overlap_bp > 0]
1761128263349:peaks_per_gene <- overlaps[, .N, by = gene]
1761128263353:setnames(peaks_per_gene, "N", "num_peaks")
1761128263361:overlap_sum_per_gene <- overlaps[, .(total_overlap_bp = sum(overlap_bp)), by = gene]
1761128263366:top20_genes <- overlap_sum_per_gene[order(-total_overlap_bp)][1:20]
1761128263370:return(list(overlaps=overlaps, peaks_per_gene=peaks_per_gene, top20_genes=top20_genes))
1761128263373:}
1761128263381:# ==========================================================
1761128263384:# 🧩 TASK 11 — Variants to genes
1761128263388:# ==========================================================
1761128263395:#' Map genetic variants to genes and count HIGH-impact variants
1761128263397:#'
1761128263402:#' @param variants_path  Path to CSV file with columns: sample_id, chr, pos, ref, alt, impact
1761128263405:#' @param genes_path  Path to CSV file with columns: chr, start, end, gene
1761128263408:#' @return List with counts and high-impact genes
1761128263412:#' @export
1761128263415:variants_to_genes_dt <- function(variants_path, genes_path) {
1761128263421:variants <- fread(variants_path)
1761128263424:genes    <- fread(genes_path)
1761128263431:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1761128263435:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1761128263439:setkey(variants, chr, start, end)
1761128263444:setkey(genes,    chr, start, end)
1761128263450:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1761128263455:overlaps[, impact_upper := toupper(impact)]
1761128263462:high_overlaps <- overlaps[impact_upper == "HIGH"]
1761128263470:high_counts_by_gene_sample <- high_overlaps[, .(
1761128263473:high_variant_count = .N
1761128263477:), by = .(gene, sample_id)]
1761128263493:high_counts_by_gene <- high_overlaps[, .(
1761128263500:total_high_variants = .N
1761128263507:), by = gene][order(-total_high_variants)]
1761128263520:genes_with_high <- unique(high_counts_by_gene$gene)
1761128263525:return(list(overlaps=overlaps, genes_with_high = genes_with_high))
1761128263531:}
1761128263541:# ==========================================================
1761128263547:# 🧩 TASK 12 — Combine cohorts
1761128263550:# ==========================================================
1761128263557:#' Combine cohorts safely and compute per-cohort mean counts
1761128263563:#'
1761128263566:#' @param cohortA_path Path to CSV file with columns: sample_id, condition, batch, patient_id, timepoint, cohort
1761128263569:#' @param cohortB_path Path to CSV file with columns: sample_id, condition, batch, patient_id, timepoint, cohort
1761128263572:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128263575:#' @return List with combined cohort info and top genes
1761128263582:combine_cohorts_dt <- function(cohortA_path, cohortB_path, counts_path) {
1761128263589:cohortA <- fread(cohortA_path)
1761128263592:cohortB <- fread(cohortB_path)
1761128263597:counts  <- fread(counts_path)
1761128263603:cohortA[, cohort := "A"]
1761128263606:cohortB[, cohort := "B"]
1761128263614:combined_cohorts <- rbindlist(list(cohortA, cohortB), use.names = TRUE, fill = TRUE)
1761128263621:setorder(combined_cohorts, cohort, condition, sample_id)
1761128263628:merged_per_sampleid <- merge(counts, combined_cohorts, by = "sample_id", all.x = TRUE)
1761128263633:gene_variance <- merged_per_sampleid[, .(variance = var(count, na.rm = TRUE)), by = gene]
1761128263640:top100_genes <- gene_variance[order(-variance)][1:100, gene]
1761128263648:top100_data <- merged_per_sampleid[gene %in% top100_genes]
1761128263656:mean_counts <- top100_data[, .(
1761128263662:mean_count = mean(count, na.rm = TRUE)
1761128263664:), by = .(gene, cohort, condition)]
1761128263672:return(top100_data)
1761128263681:}
1761128263712:# ==========================================================
1761128263720:# 🧩 FINAL REVISION TASKS (1.1 → 5.1)
1761128263729:# ==========================================================
1761128263747:#' Combine integration and clustering data
1761128263753:#'
1761128263760:#' Reads and merges integration and clustering tables by cell ID, ensuring consistent ID formatting.
1761128263774:#'
1761128263782:#' @export
1761128263786:combine_integration_clustering_dt <- function(integration_file, clustering_file) {
1761128263805:int <- fread(integration_file)
1761128263813:clu <- fread(clustering_file)
1761128263818:normalize <- function(x) gsub("_X_|_Y_", "_", trimws(as.character(x)))
1761128263825:int[, cell_clean := normalize(cell)]
1761128263839:clu[, cell_clean := normalize(cell)]
1761128263846:merge(int, clu, by = "cell_clean", all = FALSE)
1761128263853:}
1761128263867:#' Count cells per cluster and cell type
1761128263872:#' @export
1761128263882:count_cells_per_cluster_dt <- function(combined_dt) {
1761128263888:counts <- combined_dt[, .N, by = .(integration_cluster, cell_type)]
1761128263894:setnames(counts, "N", "cell_count")
1761128263899:counts
1761128263904:}
1761128263917:#' Count cells per cluster, cell type, and sample type
1761128263922:#' @export
1761128263930:add_sample_type_dt <- function(combined_dt) {
1761128263938:counts <- combined_dt[, .N, by = .(integration_cluster, cell_type, sample_type)]
1761128263947:setnames(counts, "N", "cell_count")
1761128263952:counts
1761128263962:}
1761128263971:#' Compute total cell counts per cluster and sample type
1761128263978:#' @export
1761128263985:compute_totals_dt <- function(counts_dt) {
1761128263996:counts_dt[, .(total_cells = sum(cell_count)), by = .(integration_cluster, sample_type)]
1761128264003:}
1761128264017:#' Compute normalized percentages per cluster and tissue
1761128264020:#' @export
1761128264024:compute_percentages_dt <- function(counts_dt) {
1761128264028:totals <- counts_dt[, .(total_cells = sum(cell_count)), by = .(integration_cluster, sample_type)]
1761128264032:merged <- merge(counts_dt, totals, by = c("integration_cluster", "sample_type"))
1761128264035:merged[, percent := round((cell_count / total_cells) * 100, 2)]
1761128264038:merged[order(integration_cluster)]
1761128264050:}
1761128278838:devtools::document()
1761128286353:devtools::load_all()
1761128407130:library(data.table)
1761128407147:# ==========================================================
1761128407150:# 🧩 TASK 1 — Bulk RNA counts summary
1761128407153:# ==========================================================
1761128407160:#' Summarize bulk RNA counts with metadata (data.table version)
1761128407165:#'
1761128407168:#' Merges bulk RNA-seq count data with sample metadata, filters treated samples
1761128407170:#' whose gene names start with "GENE_00", and computes mean/median counts per gene,
1761128407174:#' as well as per-condition mean counts.
1761128407177:#'
1761128407180:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128407183:#' @param meta_path Path to CSV file with columns: sample_id, condition, batch, patient ID, timepoint.
1761128407186:#' @return List with: filtered_data, gene_mean_median, gene_condition_means
1761128407188:#' \itemize{
1761128407192:#'   \item gene_mean_median: Mean and median counts by gene (treated only)
1761128407195:#'   \item gene_condition_means: Mean counts by gene and condition
1761128407197:#' }
1761128407200:#' @export
1761128407202:bulk_counts_summary_dt <- function(counts_path, meta_path) {
1761128407204:bulk_counts <- fread(counts_path)
1761128407207:sample_meta <- fread(meta_path)
1761128407213:setkey(bulk_counts, sample_id)
1761128407217:setkey(sample_meta, sample_id)
1761128407222:join_data <- bulk_counts[sample_meta, nomatch = 0]
1761128407230:filtered_data <- join_data[condition == "treated" & grepl("^GENE_00", gene)]
1761128407236:gene_mean_median <- filtered_data[, .(
1761128407239:mean_count   = mean(count),
1761128407243:median_count = median(count)
1761128407246:), by = gene]
1761128407251:gene_condition_means <- bulk_counts[
1761128407254:sample_meta,
1761128407258:on = "sample_id"
1761128407261:][ , .(
1761128407263:mean_count = mean(count)
1761128407266:), by = .(gene, condition) ]
1761128407276:return(list(filtered_data = filtered_data, gene_mean_median = gene_mean_median, gene_condition_means = gene_condition_means))
1761128407280:}
1761128407288:# ==========================================================
1761128407294:# 🧩 TASK 2 — QC-style derived columns
1761128407298:# ==========================================================
1761128407309:#' Add QC-style derived columns (data.table version)
1761128407312:#'
1761128407316:#' Adds log2-transformed counts and a binary \code{high} flag based on gene-wise medians.
1761128407320:#'
1761128407326:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128407329:#' @return Data.table with added columns: log2_count, high.
1761128407333:bulk_counts_qc_dt <- function(counts_path) {
1761128407337:counts <- fread(counts_path)
1761128407344:counts[, log2_count := log2(count)]
1761128407348:counts[, high := count > 100]
1761128407352:counts[, high := count > median(count), by = gene]
1761128407363:return(counts)
1761128407366:}
1761128407379:# ==========================================================
1761128407384:# 🧩 TASK 3 — Subset by gene and sample
1761128407387:# ==========================================================
1761128407396:#' Subset counts data using secondary index
1761128407399:#'
1761128407404:#' Joins metadata and subsets for a specific gene and sample using fast indexing.
1761128407409:#'
1761128407412:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128407416:#' @param meta_path Path to CSV file with columns: sample_id, condition, batch, patient ID, timepoint.
1761128407419:#' @param gene_name Gene name to subset
1761128407432:#' @param sample_chosen Sample ID to subset
1761128407443:#' @return Subset of counts for the given gene and sample.
1761128407447:#' @export
1761128407450:subset_counts_dt <- function(counts_path, meta_path, gene_call, sample_chosen) {
1761128407454:bulk_counts <- fread(counts_path)
1761128407458:sample_meta <- fread(meta_path)
1761128407465:setkey(sample_meta, sample_id)
1761128407471:join_data <- sample_meta[bulk_counts, on = "sample_id"]
1761128407490:time_no_index <- system.time({
1761128407501:subset_no_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1761128407506:})
1761128407514:setindex(bulk_counts, gene, sample_id)
1761128407521:time_with_index <- system.time({
1761128407526:subset_with_index <- bulk_counts[gene == gene_call & sample_id == sample_chosen]
1761128407531:})
1761128407543:dt_benchmark <- data.table(
1761128407547:test = c("time_no_index", "time_with_index"),
1761128407551:user = c(time_no_index["user.self"], time_with_index["user.self"]),
1761128407554:system = c(time_no_index["sys.self"], time_with_index["sys.self"]),
1761128407559:elapsed = c(time_no_index["elapsed"], time_with_index["elapsed"])
1761128407563:)
1761128407576:return(dt_benchmark)
1761128407581:}
1761128407592:# ==========================================================
1761128407597:# 🧩 TASK 4 — Annotate counts and summarize
1761128407602:# ==========================================================
1761128407752:#' Annotate counts with metadata and compute summaries
1761128407760:#'
1761128407766:#' Joins counts and metadata, computes per-patient total counts,
1761128407773:#' mean counts per gene and condition, and identifies top 10 genes.
1761128407780:#'
1761128407786:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128407793:#' @param meta_path Path to CSV file with columns: sample_id, condition, batch, patient ID, timepoint.
1761128407799:#' @return List with patient totals, and top10 genes.
1761128407803:annotate_counts_dt <- function(counts_path, meta_path) {
1761128407812:bulk_counts <- fread(counts_path)
1761128407817:sample_meta <- fread(meta_path)
1761128407832:setkey(bulk_counts, sample_id)
1761128407839:setkey(sample_meta, sample_id)
1761128407846:join_data <- bulk_counts[sample_meta, nomatch = 0]
1761128407869:patient_tot <- join_data[, .(total_count = sum(count)), by = patient_id]
1761128407889:gene_means <- join_data[, .(mean_count = mean(count)), by = .(gene, condition)]
1761128407910:top10 <- gene_means[
1761128407917:order(condition, -mean_count)
1761128407922:][, head(.SD, 10), by = condition]
1761128407935:return(list(patient_tot = patient_tot, top10 = top10))
1761128407943:}
1761128407963:# ==========================================================
1761128407969:# 🧩 TASK 5 — Classify lab values
1761128407977:# ==========================================================
1761128407984:#' Classify lab values against reference intervals
1761128407989:#'
1761128407995:#' Joins lab results and reference ranges, classifies as "normal" or "out_of_range",
1761128407997:#' and summarizes abnormalities per patient and per lab.
1761128408001:#'
1761128408005:#' @param labs_path Path to CSV file with columns: patient_id, time_iso, lab, value.
1761128408011:#' @param ref_path Path to CSV file with columns: lab, sex,lower, upper.
1761128408016:#' @return List with merged_labs, abnormal_by_patient, abnormal_by_lab.
1761128408022:classify_labs_dt <- function(labs_path, ref_path) {
1761128408034:labs <- fread(labs_path)
1761128408039:ref  <- fread(ref_path)
1761128408047:ref_unique <- unique(ref[, .(lab, lower, upper)])
1761128408054:merged_labs <- merge(labs, ref_unique, by = "lab")
1761128408064:merged_labs[, status := ifelse(value >= lower & value <= upper, "normal", "out_of_range")]
1761128408073:abnormal_by_patient <- merged_labs[, .(
1761128408080:total_tests = .N,
1761128408085:out_of_range = sum(status == "out_of_range")
1761128408090:), by = patient_id]
1761128408101:abnormal_by_lab <- merged_labs[, .(
1761128408106:total_tests = .N,
1761128408116:out_of_range = sum(status == "out_of_range")
1761128408122:), by = lab]
1761128408135:return(list(merged_labs = merged_labs, abnormal_by_patient = abnormal_by_patient, abnormal_by_lab = abnormal_by_lab))
1761128408147:}
1761128408176:# ==========================================================
1761128408182:# 🧩 TASK 6 — Match vitals to labs
1761128408191:# ==========================================================
1761128408202:#' Nearest-time matching of vitals and labs
1761128408208:#'
1761128408214:#' Matches nearest HR/SBP readings to each lab time and computes correlations.
1761128408221:#'
1761128408232:#' @param labs_path Path to CSV file with columns: patient_id, time_iso, lab, value.
1761128408239:#' @param vitals_path Path to CSV file with columns: time_iso
1761128408246:#' @return List with labs_with_vitals and correlations (CRP vs HR/SBP)
1761128408249:#' @export
1761128408254:match_vitals_dt <- function(labs_path, vitals_path) {
1761128408262:labs <- fread(labs_path)
1761128408266:vitals <- fread(vitals_path)
1761128408273:labs[, time_iso := as.POSIXct(time_iso)]
1761128408278:vitals[, time_iso := as.POSIXct(time_iso)]
1761128408284:setorder(labs, patient_id, time_iso)
1761128408287:setorder(vitals, patient_id, time_iso)
1761128408299:labs[, lab_time := time_iso]
1761128408302:setkey(labs, patient_id, time_iso)
1761128408305:setkey(vitals, patient_id, time_iso)
1761128408316:vitals_hr <- vitals[vital == "HR", .(patient_id, time_iso, value)]
1761128408319:setnames(vitals_hr, "value", "nearest_HR")
1761128408327:vitals_hr[, hr_time := time_iso]
1761128408331:setkey(vitals_hr, patient_id, time_iso)
1761128408338:labs_with_hr <- vitals_hr[labs, roll = "nearest"]
1761128408347:labs_with_hr[, hr_lag_minutes := as.numeric(difftime(lab_time, hr_time, units = "mins"))]
1761128408365:vitals_sbp <- vitals[vital == "SBP", .(patient_id, time_iso, value)]
1761128408370:setnames(vitals_sbp, "value", "nearest_SBP")
1761128408379:vitals_sbp[, sbp_time := time_iso]
1761128408382:setkey(vitals_sbp, patient_id, time_iso)
1761128408388:labs_with_vitals <- vitals_sbp[labs_with_hr, roll = "nearest"]
1761128408393:labs_with_vitals[, sbp_lag_minutes := as.numeric(difftime(lab_time, sbp_time, units = "mins"))]
1761128408401:crp_data <- labs_with_vitals[lab == "CRP"]
1761128408413:cor_crp_hr <- crp_data[!is.na(nearest_HR), .(
1761128408416:correlation_CRP_HR = cor(value, nearest_HR, use = "complete.obs")
1761128408419:), by = patient_id]
1761128408427:cor_crp_sbp <- crp_data[!is.na(nearest_SBP), .(
1761128408430:correlation_CRP_SBP = cor(value, nearest_SBP, use = "complete.obs")
1761128408433:), by = patient_id]
1761128408439:return(list(labs_with_hr = labs_with_hr, labs_with_vitals=labs_with_vitals, cor_crp_hr = cor_hr, cor_crp_sbp = cor_sbp))
1761128408444:}
1761128408450:# ==========================================================
1761128408453:# 🧩 TASK 7 — Top peaks by score
1761128408456:# ==========================================================
1761128408464:#' Extract peaks on chromosome and return top N by score
1761128408467:#'
1761128408470:#' Filters by genomic region and selects top peaks by score.
1761128408473:#'
1761128408478:#' @param peaks_path Path to CSV file with columns:chr, start, end, peak_id, score
1761128408480:#' @param chr_sel selected chromosome string e.g.:"chr2"
1761128408483:#' @param start_min lower bound of range e.g.:2000000
1761128408486:#' @param start_max upper bound of range e.g.:4000000
1761128408489:#' @return Data.table of top peaks
1761128408493:#' @export
1761128408496:top_peaks_dt <- function(peaks_path, chr_path, start_min , start_max) {
1761128408502:peaks <- fread("project_oct25/atac_peaks.bed.csv")
1761128408540:subset_peaks <- peaks[chr == chr_sel & start >= start_min & start <= start_max]
1761128408586:subset_peaks <- setorder(subset_peaks, -score)
1761128408597:top50_peaks <- head(subset_peaks, 50)
1761128408603:return(top50_peaks)
1761128408607:}
1761128408614:# ==========================================================
1761128408617:# 🧩 TASK 8 — Gene stats and filtering
1761128408621:# ==========================================================
1761128408629:#' Per-condition robust summary stats and gene filtering
1761128408632:#'
1761128408635:#' Computes mean, median, quartiles by gene and condition,
1761128408639:#' filters genes with treated_mean ≥ 2 × control_mean.
1761128408643:#'
1761128408646:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128408649:#' @param meta_path Path to CSV file with columns: sample_id, condition, batch, patient ID, timepoint.
1761128408652:#' @return List with stats_by_gene_condition and kept_genes
1761128408660:gene_stats_filter_dt <- function(counts_path, meta_path) {
1761128408663:counts <- fread(counts_path)
1761128408666:meta   <- fread(meta_path)
1761128408673:merged <- counts[meta, on = "sample_id"]
1761128408681:stats_by_gene_condition <- merged[, .(
1761128408684:mean_count   = mean(count),
1761128408687:median_count = median(count),
1761128408690:Q1           = quantile(count, 0.25, type = 2),
1761128408695:Q3           = quantile(count, 0.75, type = 2)
1761128408698:), by = .(gene, condition)]
1761128408708:treated_means <- stats_by_gene_condition[condition == "treated", .(gene, treated_mean = mean_count)]
1761128408717:control_means <- stats_by_gene_condition[condition == "control", .(gene, control_mean = mean_count)]
1761128408744:means_wide <- merge(treated_means, control_means, by = "gene", all = FALSE)
1761128408750:kept_genes <- means_wide[treated_mean >= 2 * control_mean]
1761128408756:return(list(stats_by_gene_condition = stats_by_gene_condition, kept_genes = kept_genes))
1761128408760:}
1761128408766:# ==========================================================
1761128408768:# 🧩 TASK 9 — Wide → Long → Wide
1761128408772:# ==========================================================
1761128408781:#' Convert wide counts to long and back, computing mean per condition
1761128408786:#'
1761128408836:#' @param counts_wide_path Path to CSV file with columns genes and samples
1761128408841:#' @return Data.table wide by condition with mean counts
1761128408867:wide_long_wide_dt <- function(counts_wide_path, meta_path) {
1761128408879:counts_wide <- fread(counts_wide_path)
1761128408886:counts_long <- melt(counts_wide, id.vars = "gene",
1761128408889:variable.name = "sample_id", value.name = "count")
1761128408905:meta <- fread(meta_path)
1761128408918:merged <- merge(counts_long, meta, by = "sample_id")
1761128408926:totals_per_sample <- merged[, .(total_count = sum(count)), by = sample_id]
1761128408936:merged <- merge(merged, totals_per_sample, by = "sample_id")
1761128408944:gene_condition_means <- merged[, .(mean_count = mean(count)),
1761128408948:by = .(gene, condition)]
1761128408955:counts_condition_wide <- dcast(gene_condition_means,
1761128408961:gene ~ condition,
1761128408963:value.var = "mean_count")
1761128408967:return(counts_condition_wide)
1761128408971:}
1761128408978:# ==========================================================
1761128408982:# 🧩 TASK 10 — ATAC peaks to genes
1761128408985:# ==========================================================
1761128408991:#' Map ATAC peaks to genes and summarize overlaps
1761128408995:#'
1761128408998:#' Uses genomic overlap to assign peaks to genes and compute overlap statistics.
1761128409001:#'
1761128409003:#' @param peaks_path Path to CSV file with columns: chr, start, end, peak_id, score
1761128409006:#' @param genes_path Path to CSV file with columns: chr, start, end, gene
1761128409011:#' @return List with overlap tables, peaks_per_gene and top 20 genes by overlap
1761128409016:atac_to_gene_dt <- function(peaks_path, genes_path) {
1761128409022:peaks <- fread(peaks_path)
1761128409024:genes <- fread(genes_path)
1761128409032:setkey(peaks, chr, start, end)
1761128409035:setkey(genes, chr, start, end)
1761128409040:overlaps <- foverlaps(peaks, genes,
1761128409044:by.x = c("chr", "start", "end"),
1761128409047:by.y = c("chr", "start", "end"),
1761128409050:type = "any", nomatch = 0L)
1761128409056:overlaps[, overlap_bp := pmin(end, i.end) - pmax(start, i.start)]
1761128409063:overlaps <- overlaps[overlap_bp > 0]
1761128409069:peaks_per_gene <- overlaps[, .N, by = gene]
1761128409071:setnames(peaks_per_gene, "N", "num_peaks")
1761128409079:overlap_sum_per_gene <- overlaps[, .(total_overlap_bp = sum(overlap_bp)), by = gene]
1761128409084:top20_genes <- overlap_sum_per_gene[order(-total_overlap_bp)][1:20]
1761128409087:return(list(overlaps=overlaps, peaks_per_gene=peaks_per_gene, top20_genes=top20_genes))
1761128409090:}
1761128409097:# ==========================================================
1761128409100:# 🧩 TASK 11 — Variants to genes
1761128409103:# ==========================================================
1761128409111:#' Map genetic variants to genes and count HIGH-impact variants
1761128409114:#'
1761128409116:#' @param variants_path  Path to CSV file with columns: sample_id, chr, pos, ref, alt, impact
1761128409120:#' @param genes_path  Path to CSV file with columns: chr, start, end, gene
1761128409123:#' @return List with counts and high-impact genes
1761128409128:#' @export
1761128409131:variants_to_genes_dt <- function(variants_path, genes_path) {
1761128409136:variants <- fread(variants_path)
1761128409139:genes    <- fread(genes_path)
1761128409147:variants[, start := pos]  #creo per ogni variante un intervallo 1bp
1761128409150:variants[, end   := pos]  #foverlaps () lavora con intervalli start-end quindi gli servono
1761128409155:setkey(variants, chr, start, end)
1761128409160:setkey(genes,    chr, start, end)
1761128409165:overlaps <- foverlaps(variants, genes, type = "any", nomatch = 0L)
1761128409171:overlaps[, impact_upper := toupper(impact)]
1761128409179:high_overlaps <- overlaps[impact_upper == "HIGH"]
1761128409187:high_counts_by_gene_sample <- high_overlaps[, .(
1761128409190:high_variant_count = .N
1761128409195:), by = .(gene, sample_id)]
1761128409205:high_counts_by_gene <- high_overlaps[, .(
1761128409207:total_high_variants = .N
1761128409212:), by = gene][order(-total_high_variants)]
1761128409221:genes_with_high <- unique(high_counts_by_gene$gene)
1761128409223:return(list(overlaps=overlaps, genes_with_high = genes_with_high))
1761128409228:}
1761128409233:# ==========================================================
1761128409236:# 🧩 TASK 12 — Combine cohorts
1761128409239:# ==========================================================
1761128409246:#' Combine cohorts safely and compute per-cohort mean counts
1761128409249:#'
1761128409252:#' @param cohortA_path Path to CSV file with columns: sample_id, condition, batch, patient_id, timepoint, cohort
1761128409255:#' @param cohortB_path Path to CSV file with columns: sample_id, condition, batch, patient_id, timepoint, cohort
1761128409258:#' @param counts_path Path to CSV file with columns: gene, sample_id, count.
1761128409263:#' @return List with combined cohort info and top genes
1761128409269:combine_cohorts_dt <- function(cohortA_path, cohortB_path, counts_path) {
1761128409274:cohortA <- fread(cohortA_path)
1761128409279:cohortB <- fread(cohortB_path)
1761128409282:counts  <- fread(counts_path)
1761128409288:cohortA[, cohort := "A"]
1761128409291:cohortB[, cohort := "B"]
1761128409298:combined_cohorts <- rbindlist(list(cohortA, cohortB), use.names = TRUE, fill = TRUE)
1761128409304:setorder(combined_cohorts, cohort, condition, sample_id)
1761128409312:merged_per_sampleid <- merge(counts, combined_cohorts, by = "sample_id", all.x = TRUE)
1761128409317:gene_variance <- merged_per_sampleid[, .(variance = var(count, na.rm = TRUE)), by = gene]
1761128409323:top100_genes <- gene_variance[order(-variance)][1:100, gene]
1761128409331:top100_data <- merged_per_sampleid[gene %in% top100_genes]
1761128409337:mean_counts <- top100_data[, .(
1761128409340:mean_count = mean(count, na.rm = TRUE)
1761128409345:), by = .(gene, cohort, condition)]
1761128409351:return(top100_data)
1761128409354:}
1761128427206:devtools::document
1761128433146:devtools::load_all()
1761128439648:devtools::document()
1761128444748:devtools::load_all()
1761128481022:devtools::load_all()
1761128497079:library(data.table)
1761128497096:# ==========================================================
1761128497101:# 🧩 TASK 1 — Bulk RNA counts summary
